{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import ants\n",
    "from typing import Union, List, Tuple\n",
    "import multiprocessing\n",
    "import SimpleITK as sitk\n",
    "from nipype.interfaces.dcm2nii import Dcm2niix\n",
    "import numpy as np\n",
    "from HD_BET.run import run_hd_bet\n",
    "from nipype.interfaces import fsl\n",
    "from intensity_normalization.normalize.zscore import ZScoreNormalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Dicom Tags from Dicom Files\n",
    "\n",
    "https://medium.com/@ashkanpakzad/reading-editing-dicom-metadata-w-python-8204223a59f6\n",
    "\n",
    "https://github.com/pydicom/pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata for each sequence from the first file in each sequence\n",
    "\n",
    "# Get all patients\n",
    "# Get all the sequences\n",
    "# Get the first file for each sequence\n",
    "# Extract Metadata\n",
    "# Save Metadata in the patient folder named {patientID}_{sequence}_meta\n",
    "\n",
    "import pydicom\n",
    "\n",
    "path_to_dicom = \"\"\n",
    "\n",
    "dicomFile = pydicom.dcmread(path_to_dicom)\n",
    "\n",
    "print(dicomFile) # returns list of metadata\n",
    "\n",
    "# extract needed metadata\n",
    "\n",
    "# save metadata somewhere\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 00: Convert Dicom to Nifti Files\n",
    "using Dcm2niix, for more information: https://github.com/rordenlab/dcm2niix\n",
    "\n",
    "Li X, Morgan PS, Ashburner J, Smith J, Rorden C (2016) The first step for neuroimaging data analysis: DICOM to NIfTI conversion. J Neurosci Methods. 264:47-56. doi: 10.1016/j.jneumeth.2016.03.001. PMID: 26945974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_all_patients = \"\"\n",
    "path_to_n30 = \"\"\n",
    "\n",
    "root = path_to_all_patients\n",
    "\n",
    "patientDirs = [\n",
    "    folder for folder in os.listdir(root) if os.path.isdir(os.path.join(root, folder))\n",
    "]\n",
    "\n",
    "for patient in patientDirs:\n",
    "\n",
    "    patientID = patient\n",
    "\n",
    "    sequenceDirs = [\n",
    "        sequenceFolder for sequenceFolder in os.listdir(os.path.join(root, patient)) if os.path.isdir(os.path.join(root, patient, sequenceFolder))\n",
    "    ]\n",
    "\n",
    "    for sequence in sequenceDirs:\n",
    "        # new sequence name: {patientID}_{sequence}_{preprocessingStep}\n",
    "\n",
    "        sequenceType = sequence.split(\"_\")[1]\n",
    "\n",
    "        converter = Dcm2niix()\n",
    "        converter.inputs.source_dir = os.path.join(root, patient, sequence)\n",
    "        converter.inputs.compress = \"y\" # uses compression, \"y\" = yes\n",
    "        converter.inputs.merge_imgs = True\n",
    "        # converter.inputs.compression = 5\n",
    "        converter.inputs.out_filename = f\"{patientID}_{sequenceType}\"\n",
    "        converter.inputs.output_dir = os.path.join(root, patient)\n",
    "        converter.run()\n",
    "\n",
    "\n",
    "# # goes through the list of files/folders at path_to_folder and only adds directories to dirlist\n",
    "# dirlist = [\n",
    "#     item for item in os.listdir(root) if os.path.isdir(os.path.join(root, item))\n",
    "# ]\n",
    "\n",
    "# print(len(dirlist), \"subfolders found\")\n",
    "\n",
    "# for dir in dirlist:\n",
    "#     converter = Dcm2niix()\n",
    "#     converter.inputs.source_dir = os.path.join(root, dir)\n",
    "#     converter.inputs.compress = \"y\"\n",
    "#     converter.inputs.merge_imgs = True\n",
    "#     # converter.inputs.compression = 5\n",
    "#     converter.inputs.out_filename = \"%i_%t_%d_%f_%p_%q_%s_%z\"\n",
    "#     converter.inputs.output_dir = os.path.join(root, dir)\n",
    "#     converter.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 01: Get Caseliste\n",
    "Reads the excel file with all the cases and returns the patient IDs as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"\"\n",
    "\n",
    "cases = pd.read_excel(\n",
    "        os.path.join(path_to_file, \"Cases.xlsx\"),\n",
    "        header=0,\n",
    "        index_col=None,\n",
    "        dtype={\"ID\": str},\n",
    "    )\n",
    "\n",
    "caseList = cases.ID.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 02: Extract Brain\n",
    "applies FSL.Reorient2Std() (requirement for HD-BET) and returns the extracted brain image\n",
    "\n",
    "Brain Extraction using HD-BET, for more information: https://github.com/MIC-DKFZ/HD-BET\n",
    "\n",
    "Isensee F, Schell M, Tursunova I, Brugnara G, Bonekamp D, Neuberger U, Wick A, Schlemmer HP, Heiland S, Wick W, Bendszus M, Maier-Hein KH, Kickingereder P. Automated brain extraction of multi-sequence MRI using artificial neural networks. Hum Brain Mapp. 2019; 1â€“13. https://doi.org/10.1002/hbm.24750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_input_image = \"\"\n",
    "path_to_output_image = \"\"\n",
    "\n",
    "# Alternative: torchio tocanonical\n",
    "reorient = fsl.Reorient2Std()\n",
    "reorient.inputs.in_file = path_to_input_image\n",
    "reorient.inputs.out_file = path_to_output_image\n",
    "reorient.run()\n",
    "\n",
    "run_hd_bet(mri_fnames=path_to_output_image, output_fnames=path_to_output_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 03: Fill Holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_holes(\n",
    "    binary_image: sitk.Image,\n",
    "    radius: int = 3,\n",
    ") -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Fills holes in binary segmentation\n",
    "\n",
    "    Keyword Arguments:\n",
    "    - binary_image: sitk.Image = binary brain segmentation\n",
    "    - radius: int = kernel radius\n",
    "\n",
    "    Returns:\n",
    "    - closed_image: sitk.Image = binary brain segmentation with holes filled\n",
    "    \"\"\"\n",
    "\n",
    "    closing_filter = sitk.BinaryMorphologicalClosingImageFilter()\n",
    "    closing_filter.SetKernelRadius(radius)\n",
    "    closed_image = closing_filter.Execute(binary_image)\n",
    "\n",
    "    return closed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 04: Binary Segment Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_segment_brain(\n",
    "    image: sitk.Image,\n",
    ") -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Returns binary segmentation of brain from brain-extracted scan via otsu thresholding\n",
    "\n",
    "    Keyword Arguments:\n",
    "    - image: sitk.Image = brain-extracted scan\n",
    "\n",
    "    Returns:\n",
    "    - sitk.Image = binary segmentation of brain scan with filled holes\n",
    "    \"\"\"\n",
    "\n",
    "    otsu_filter = sitk.OtsuThresholdImageFilter()\n",
    "    otsu_filter.SetInsideValue(0)\n",
    "    otsu_filter.SetOutsideValue(1)\n",
    "    binary_mask = otsu_filter.Execute(image)\n",
    "\n",
    "    return fill_holes(binary_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 05: Get Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box(\n",
    "    image: sitk.Image,\n",
    ") -> Tuple[int]:\n",
    "    \"\"\"\n",
    "    Returns bounding box of brain-extracted scan\n",
    "\n",
    "    Keyword Arguments:\n",
    "    - image: sitk.Image = brain-extracted scan\n",
    "\n",
    "    Returns\n",
    "    - bounding_box: Tuple(int) = bounding box (startX, startY, startZ, sizeX, sizeY, sizeZ)\n",
    "    \"\"\"\n",
    "\n",
    "    mask_image = binary_segment_brain(image)\n",
    "\n",
    "    lsif = sitk.LabelShapeStatisticsImageFilter()\n",
    "    lsif.Execute(mask_image)\n",
    "    bounding_box = np.array(lsif.GetBoundingBox(1))\n",
    "\n",
    "    return bounding_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 06: Apply Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bounding_box(\n",
    "    image: sitk.Image,\n",
    "    bounding_box: Tuple[int],\n",
    ") -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Returns image, cropped to bounding box\n",
    "\n",
    "    Keyword Arguments:\n",
    "    - image: sitk.Image = image\n",
    "    - bounding_box: Tuple(ing) = bounding box of kind (startX, startY, startZ, sizeX, sizeY, sizeZ)\n",
    "\n",
    "    Returns\n",
    "    - cropped_image: sitk.Image = cropped image\n",
    "    \"\"\"\n",
    "\n",
    "    cropped_image = image[\n",
    "        bounding_box[0] : bounding_box[3] + bounding_box[0],\n",
    "        bounding_box[1] : bounding_box[4] + bounding_box[1],\n",
    "        bounding_box[2] : bounding_box[5] + bounding_box[2],\n",
    "    ]\n",
    "\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 07: Apply Bias Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bias_correction(\n",
    "    image: sitk.Image,\n",
    ") -> sitk.Image:\n",
    "    \"\"\"applies N4 bias field correction to image but keeps background at zero\n",
    "\n",
    "    Keyword Arguments:\n",
    "    image: sitk.Image = image to apply bias correction to\n",
    "\n",
    "    Returns:\n",
    "    image_corrected_masked: sitk.Image = N4 bias field corrected image\n",
    "    \"\"\"\n",
    "\n",
    "    mask_image = binary_segment_brain(image)\n",
    "    corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    image_corrected = corrector.Execute(image, mask_image)\n",
    "\n",
    "    mask_filter = sitk.MaskImageFilter()\n",
    "    mask_filter.SetOutsideValue(0)\n",
    "    image_corrected_masked = mask_filter.Execute(image_corrected, mask_image)\n",
    "\n",
    "    return image_corrected_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 08: Coregister Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coregister_antspy(\n",
    "    fixed_path: Union[str, pathlib.Path],\n",
    "    moving_path: Union[str, pathlib.Path],\n",
    "    out_path: Union[str, pathlib.Path],\n",
    "    num_threads=N_PROC,\n",
    ") -> ants.core.ants_image.ANTsImage:\n",
    "    \"\"\"\n",
    "    Coregister moving image to fixed image. Return warped image and save to disk.\n",
    "\n",
    "    Keyword Arguments:\n",
    "    fixed_path: path to fixed image\n",
    "    moving_path: path to moving image\n",
    "    out_path: path to save warped image to\n",
    "    num_threads: number of threads\n",
    "    \"\"\"\n",
    "\n",
    "    os.environ[\"ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS\"] = str(num_threads)\n",
    "\n",
    "    res = ants.registration(\n",
    "        fixed=ants.image_read(fixed_path),\n",
    "        moving=ants.image_read(moving_path),\n",
    "        type_of_transform=\"antsRegistrationSyNQuick[s]\",  # or \"SyNRA\"\n",
    "        initial_transform=None,\n",
    "        outprefix=\"\",\n",
    "        mask=None,\n",
    "        moving_mask=None,\n",
    "        mask_all_stages=False,\n",
    "        grad_step=0.2,\n",
    "        flow_sigma=3,\n",
    "        total_sigma=0,\n",
    "        aff_metric=\"mattes\",\n",
    "        aff_sampling=32,\n",
    "        aff_random_sampling_rate=0.2,\n",
    "        syn_metric=\"mattes\",\n",
    "        syn_sampling=32,\n",
    "        reg_iterations=(40, 20, 0),\n",
    "        aff_iterations=(2100, 1200, 1200, 10),\n",
    "        aff_shrink_factors=(6, 4, 2, 1),\n",
    "        aff_smoothing_sigmas=(3, 2, 1, 0),\n",
    "        write_composite_transform=False,\n",
    "        random_seed=None,\n",
    "        verbose=False,\n",
    "        multivariate_extras=None,\n",
    "        restrict_transformation=None,\n",
    "        smoothing_in_mm=False,\n",
    "    )\n",
    "\n",
    "    warped_moving = res[\"warpedmovout\"]\n",
    "\n",
    "    ants.image_write(warped_moving, out_path)\n",
    "\n",
    "    return warped_moving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 09: Resample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(\n",
    "    itk_image: sitk.Image,\n",
    "    out_spacing: Tuple[float, ...],\n",
    "    is_mask: bool,\n",
    ") -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Resamples sitk image to expected output spacing\n",
    "\n",
    "    Keyword Arguments:\n",
    "    itk_image: sitk.Image\n",
    "    out_spacing: Tuple\n",
    "    is_mask: bool = True if input image is label mask -> NN-interpolation\n",
    "\n",
    "    Returns\n",
    "    output_image: sitk.Image = image resampled to out_spacing\n",
    "    \"\"\"\n",
    "\n",
    "    original_spacing = itk_image.GetSpacing()\n",
    "    original_size = itk_image.GetSize()\n",
    "\n",
    "    out_size = [\n",
    "        int(round(osz * osp / nsp))\n",
    "        for osz, osp, nsp in zip(original_size, original_spacing, out_spacing)\n",
    "    ]\n",
    "\n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    resample.SetOutputSpacing(out_spacing)\n",
    "    resample.SetSize(out_size)\n",
    "    resample.SetOutputDirection(itk_image.GetDirection())\n",
    "    resample.SetOutputOrigin(itk_image.GetOrigin())\n",
    "    resample.SetTransform(sitk.Transform())\n",
    "    resample.SetDefaultPixelValue(0)\n",
    "\n",
    "    if is_mask:\n",
    "        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "\n",
    "    else:\n",
    "        resample.SetInterpolator(\n",
    "            sitk.sitkBSpline\n",
    "        )  # sitk.sitkLinear sitk.sitkNearestNeighbor\n",
    "\n",
    "    output_image = resample.Execute(itk_image)\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Z-Score Normalize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_normalize(image: sitk.Image) -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Applies z score normalization to brain scan using a brain mask\n",
    "\n",
    "    Keyword Arguments:\n",
    "    image: sitk.Image = input brain scan\n",
    "\n",
    "    Returns:\n",
    "    normalized_brain_image: sitk.Image = normalized brain scan\n",
    "    \"\"\"\n",
    "\n",
    "    brain_mask = binary_segment_brain(image)\n",
    "\n",
    "    normalizer = ZScoreNormalize()\n",
    "    normalized_brain_array = normalizer(\n",
    "        sitk.GetArrayFromImage(image),\n",
    "        sitk.GetArrayFromImage(brain_mask),\n",
    "    )\n",
    "\n",
    "    normalized_brain_image = sitk.GetImageFromArray(normalized_brain_array)\n",
    "    normalized_brain_image.CopyInformation(image)\n",
    "\n",
    "    return normalized_brain_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
