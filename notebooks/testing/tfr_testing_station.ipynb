{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecord Testing Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm hoping to gain more insight into TFRecord and how to properly use them, 'cause right now, it doesn't seem to really work out that well and I don't know why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tfr = Path(\"/Volumes/BrainMets/Rgb_Brain_Mets/brain_mets_classification/derivatives/TFRecords/patient_data_2classes.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    \"image\": tf.io.FixedLenFeature([155, 240, 240, 4], tf.float32), # formerly: [149, 185, 155, 4]\n",
    "    \"sex\": tf.io.FixedLenFeature([2], tf.int64, default_value=[0,0]),\n",
    "    \"age\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"primary\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "}\n",
    "\n",
    "data = tf.data.TFRecordDataset([path_to_tfr], compression_type=\"GZIP\")\n",
    "\n",
    "def parse_record(record):\n",
    "    return tf.io.parse_single_example(record, feature_description)\n",
    "\n",
    "data = data.map(parse_record)\n",
    "\n",
    "data = data.shuffle(buffer_size=1000)\n",
    "\n",
    "data = data.batch(4)\n",
    "\n",
    "data = data.prefetch(buffer_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 12:40:11.397293: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:21: Filling up shuffle buffer (this may take a while): 26 of 1000\n",
      "2024-06-04 12:40:31.353378: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:21: Filling up shuffle buffer (this may take a while): 76 of 1000\n",
      "2024-06-04 12:40:41.463648: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:21: Filling up shuffle buffer (this may take a while): 102 of 1000\n",
      "2024-06-04 12:41:01.113769: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:21: Filling up shuffle buffer (this may take a while): 152 of 1000\n",
      "2024-06-04 12:41:11.370729: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:21: Filling up shuffle buffer (this may take a while): 177 of 1000\n",
      "2024-06-04 12:41:31.277364: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:21: Filling up shuffle buffer (this may take a while): 226 of 1000\n",
      "2024-06-04 12:41:51.312407: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:21: Filling up shuffle buffer (this may take a while): 275 of 1000\n",
      "2024-06-04 12:42:11.245254: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:21: Filling up shuffle buffer (this may take a while): 324 of 1000\n",
      "2024-06-04 12:42:21.464135: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:21: Filling up shuffle buffer (this may take a while): 349 of 1000\n",
      "2024-06-04 12:42:41.221905: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:21: Filling up shuffle buffer (this may take a while): 398 of 1000\n",
      "2024-06-04 12:43:01.498412: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:21: Filling up shuffle buffer (this may take a while): 448 of 1000\n",
      "2024-06-04 12:43:19.322681: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "[68 63 56 66]\n",
      "[0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "for record in data.take(1):\n",
    "    print(record[\"sex\"].numpy())\n",
    "    print(record[\"age\"].numpy())\n",
    "    print(record[\"primary\"].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "[71 30 58 66 25 47]\n",
      "[1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "trainig_fold_paths = [\n",
    "    \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Data.tmp/3D_CNN_whole/fold_2.tfrecord\",\n",
    "    \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Data.tmp/3D_CNN_whole/fold_3.tfrecord\"\n",
    "]\n",
    "\n",
    "val_fold_path = \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Data.tmp/3D_CNN_whole/fold_1.tfrecord\"\n",
    "\n",
    "test_fold_path = \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Data.tmp/3D_CNN_whole/fold_0.tfrecord\"\n",
    "\n",
    "feature_description = {\n",
    "    \"image\": tf.io.FixedLenFeature([155, 240, 240, 4], tf.float32), # formerly: [149, 185, 155, 4]\n",
    "    \"sex\": tf.io.FixedLenFeature([2], tf.int64, default_value=[0,0]),\n",
    "    \"age\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"primary\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "}\n",
    "\n",
    "data = tf.data.TFRecordDataset([trainig_fold_paths], compression_type=\"GZIP\")\n",
    "\n",
    "def parse_record(record):\n",
    "    return tf.io.parse_single_example(record, feature_description)\n",
    "\n",
    "data = data.map(parse_record)\n",
    "\n",
    "data = data.shuffle(buffer_size=1000)\n",
    "\n",
    "data = data.batch(10)\n",
    "\n",
    "data = data.prefetch(buffer_size=1)\n",
    "\n",
    "for record in data.take(1):\n",
    "    print(record[\"sex\"].numpy())\n",
    "    print(record[\"age\"].numpy())\n",
    "    print(record[\"primary\"].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT attempt at k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write(): incompatible function arguments. The following argument types are supported:\n    1. (self: tensorflow.python.lib.io._pywrap_record_io.RecordWriter, record: str) -> None\n\nInvoked with: <tensorflow.python.lib.io.tf_record.TFRecordWriter object at 0x30fe0bfb0>, <_TakeDataset element_spec={'age': TensorSpec(shape=(), dtype=tf.int64, name=None), 'image': TensorSpec(shape=(155, 240, 240, 4), dtype=tf.float32, name=None), 'primary': TensorSpec(shape=(), dtype=tf.int64, name=None), 'sex': TensorSpec(shape=(2,), dtype=tf.int64, name=None)}>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m     shuffled_dataset \u001b[38;5;241m=\u001b[39m shuffled_dataset\u001b[38;5;241m.\u001b[39mskip(fold_size)\n\u001b[1;32m     40\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/LennartPhilipp/Desktop/Uni/Prowiss/Data.tmp/3D_CNN_whole/fold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tfrecord\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[43mwrite_tfrecord\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 31\u001b[0m, in \u001b[0;36mwrite_tfrecord\u001b[0;34m(file_path, dataset)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_tfrecord\u001b[39m(file_path, dataset):\n\u001b[1;32m     30\u001b[0m     writer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mTFRecordWriter(file_path)\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/lib/io/tf_record.py:309\u001b[0m, in \u001b[0;36mTFRecordWriter.write\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, record):\n\u001b[1;32m    304\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Write a string record to the file.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m    record: str\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTFRecordWriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: write(): incompatible function arguments. The following argument types are supported:\n    1. (self: tensorflow.python.lib.io._pywrap_record_io.RecordWriter, record: str) -> None\n\nInvoked with: <tensorflow.python.lib.io.tf_record.TFRecordWriter object at 0x30fe0bfb0>, <_TakeDataset element_spec={'age': TensorSpec(shape=(), dtype=tf.int64, name=None), 'image': TensorSpec(shape=(155, 240, 240, 4), dtype=tf.float32, name=None), 'primary': TensorSpec(shape=(), dtype=tf.int64, name=None), 'sex': TensorSpec(shape=(2,), dtype=tf.int64, name=None)}>"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define the feature description\n",
    "feature_description = {\n",
    "    \"image\": tf.io.FixedLenFeature([155, 240, 240, 4], tf.float32),\n",
    "    \"sex\": tf.io.FixedLenFeature([2], tf.int64, default_value=[0,0]),\n",
    "    \"age\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"primary\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "}\n",
    "\n",
    "# Parse a single record\n",
    "def parse_record(record):\n",
    "    return tf.io.parse_single_example(record, feature_description)\n",
    "\n",
    "# Load the dataset\n",
    "raw_dataset = tf.data.TFRecordDataset([path_to_tfr], compression_type=\"GZIP\")\n",
    "\n",
    "# Parse the dataset\n",
    "parsed_dataset = raw_dataset.map(parse_record)\n",
    "\n",
    "# Shuffle the dataset (streaming)\n",
    "shuffled_dataset = parsed_dataset.shuffle(buffer_size=10000)\n",
    "\n",
    "# Define the number of folds\n",
    "k = 10\n",
    "fold_size = 48  # Example fold size; adjust based on your dataset and memory constraints\n",
    "\n",
    "# Function to write a dataset to a TFRecord file\n",
    "def write_tfrecord(file_path, dataset):\n",
    "    writer = tf.io.TFRecordWriter(file_path)\n",
    "    writer.write(dataset)\n",
    "\n",
    "# Create and save each fold\n",
    "for fold_idx in range(k):\n",
    "    if fold_idx == k - 1:\n",
    "        fold_dataset = shuffled_dataset.take(fold_size + (len(shuffled_dataset) % fold_size))\n",
    "    else:\n",
    "        fold_dataset = shuffled_dataset.take(fold_size)\n",
    "        shuffled_dataset = shuffled_dataset.skip(fold_size)\n",
    "    file_path = f\"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Data.tmp/3D_CNN_whole/fold_{fold_idx}.tfrecord\"\n",
    "    write_tfrecord(file_path, fold_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# List of all fold files\n",
    "fold_files = glob.glob(\"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Data.tmp/3D_CNN_whole/fold_*.tfrecord\")\n",
    "\n",
    "# Function to create a dataset from a list of TFRecord files\n",
    "def create_dataset_from_tfrecord(files):\n",
    "    raw_dataset = tf.data.TFRecordDataset(files, compression_type=\"GZIP\")\n",
    "    return raw_dataset.map(parse_record)\n",
    "\n",
    "# Create k-fold datasets\n",
    "def create_k_fold_datasets(fold_files, k):\n",
    "    for i in range(k):\n",
    "        val_files = [fold_files[i]]\n",
    "        train_files = [f for j, f in enumerate(fold_files) if j != i]\n",
    "        \n",
    "        train_dataset = create_dataset_from_tfrecord(train_files)\n",
    "        val_dataset = create_dataset_from_tfrecord(val_files)\n",
    "        \n",
    "        train_dataset = train_dataset.batch(4).prefetch(buffer_size=1)\n",
    "        val_dataset = val_dataset.batch(4).prefetch(buffer_size=1)\n",
    "        \n",
    "        yield train_dataset, val_dataset\n",
    "\n",
    "# Create the k-fold datasets\n",
    "k_fold_datasets = create_k_fold_datasets(fold_files, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_idx, (train_dataset, val_dataset) in enumerate(k_fold_datasets):\n",
    "    print(f\"Training fold {fold_idx + 1}/{k}\")\n",
    "    \n",
    "    # Define your model\n",
    "    model = create_model()  # Replace with your model creation function\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_dataset, epochs=10, validation_data=val_dataset)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset)\n",
    "    print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_mets_env",
   "language": "python",
   "name": "brain_mets_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
