{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing all at once\n",
    "This notebook is meant to run the preprocessing code found in the scripts directory all at once\\\n",
    "If you'd rather run the code step by step go to the `02_preprocessing_step_by_step.ipynb` file\\\n",
    "The preprocesing steps include\n",
    "1. reorient images\n",
    "2. extract brain using [HD-BET](https://github.com/MIC-DKFZ/HD-BET)\n",
    "3. N4 bias correction\n",
    "4. Coregister images\n",
    "5. Resample images\n",
    "6. Z-score normalize images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification\")\n",
    "#sys.path.append(r\"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/HD-BET/HD_BET\")\n",
    "import brain_mets_classification.config as config\n",
    "import brain_mets_classification.custom_funcs as funcs\n",
    "import brain_mets_classification.preprocessing_funcs as preprocessing\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import ants\n",
    "from typing import Union, List, Tuple\n",
    "import multiprocessing\n",
    "import SimpleITK as sitk\n",
    "from nipype.interfaces.dcm2nii import Dcm2niix\n",
    "import numpy as np\n",
    "from nipype.interfaces import fsl\n",
    "from intensity_normalization.normalize.zscore import ZScoreNormalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PROC = multiprocessing.cpu_count() - 1\n",
    "\n",
    "def extract_brain(path_to_input_image: Union[str, pathlib.Path],\n",
    "                  path_to_output_image: Union[str, pathlib.Path],\n",
    "                  device: str):\n",
    "    \"\"\"\n",
    "    runs the hd-bet brain extraction on the input image and returns the extracted brain\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    path_to_input_image: Union[str, pathlib.Path] = file path to input image (brain scan)\n",
    "    path_to_output_image: Union[str, pathlib.Path] = location to store brain extracted image\n",
    "    device: str = either \"cpu\" or \"gpu\", if you're running this on a macbook, choose \"cpu\"\n",
    "    \"\"\"\n",
    "\n",
    "    # os.system(f\"hd-bet -i {path_to_input_image} -o {path_to_output_extractedImage} -device cpu -mode fast -tta 0\")\n",
    "    if device == \"cpu\":\n",
    "        subprocess.call([\"hd-bet\", \"-i\", f\"{path_to_input_image}\", \"-o\", f\"{path_to_output_image}\", \"-device\", \"cpu\", \"-mode\", \"fast\", \"-tta\", \"0\"], stdout=open(os.devnull, \"w\"), stderr=subprocess.STDOUT)\n",
    "    elif device == \"gpu\":\n",
    "        subprocess.call([\"hd-bet\", \"-i\", f\"{path_to_input_image}\", \"-o\", f\"{path_to_output_image}\"], stdout=open(os.devnull, \"w\"), stderr=subprocess.STDOUT)\n",
    "    else:\n",
    "        raise Exception(\"Wrong device input for the extract_brain method, please use either \\\"cpu\\\" or \\\"gpu\\\"\")\n",
    "\n",
    "\n",
    "def fill_holes(\n",
    "    binary_image: sitk.Image,\n",
    "    radius: int = 3,\n",
    ") -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Fills holes in binary segmentation\n",
    "\n",
    "    Keyword Arguments:\n",
    "    - binary_image: sitk.Image = binary brain segmentation\n",
    "    - radius: int = kernel radius\n",
    "\n",
    "    Returns:\n",
    "    - closed_image: sitk.Image = binary brain segmentation with holes filled\n",
    "    \"\"\"\n",
    "\n",
    "    closing_filter = sitk.BinaryMorphologicalClosingImageFilter()\n",
    "    closing_filter.SetKernelRadius(radius)\n",
    "    closed_image = closing_filter.Execute(binary_image)\n",
    "\n",
    "    return closed_image\n",
    "\n",
    "\n",
    "def binary_segment_brain(\n",
    "    image: sitk.Image,\n",
    ") -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Returns binary segmentation of brain from brain-extracted scan via otsu thresholding\n",
    "\n",
    "    Keyword Arguments:\n",
    "    - image: sitk.Image = brain-extracted scan\n",
    "\n",
    "    Returns:\n",
    "    - sitk.Image = binary segmentation of brain scan with filled holes\n",
    "    \"\"\"\n",
    "\n",
    "    otsu_filter = sitk.OtsuThresholdImageFilter()\n",
    "    otsu_filter.SetInsideValue(0)\n",
    "    otsu_filter.SetOutsideValue(1)\n",
    "    binary_mask = otsu_filter.Execute(image)\n",
    "\n",
    "    return fill_holes(binary_mask)\n",
    "\n",
    "\n",
    "def get_bounding_box(\n",
    "    image: sitk.Image,\n",
    ") -> Tuple[int]:\n",
    "    \"\"\"\n",
    "    Returns bounding box of brain-extracted scan\n",
    "\n",
    "    Keyword Arguments:\n",
    "    - image: sitk.Image = brain-extracted scan\n",
    "\n",
    "    Returns\n",
    "    - bounding_box: Tuple(int) = bounding box (startX, startY, startZ, sizeX, sizeY, sizeZ)\n",
    "    \"\"\"\n",
    "\n",
    "    mask_image = binary_segment_brain(image)\n",
    "\n",
    "    lsif = sitk.LabelShapeStatisticsImageFilter()\n",
    "    lsif.Execute(mask_image)\n",
    "    bounding_box = np.array(lsif.GetBoundingBox(1))\n",
    "\n",
    "    return bounding_box\n",
    "\n",
    "\n",
    "def apply_bounding_box(\n",
    "    image: sitk.Image,\n",
    "    bounding_box: Tuple[int],\n",
    ") -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Returns image, cropped to bounding box\n",
    "\n",
    "    Keyword Arguments:\n",
    "    - image: sitk.Image = image\n",
    "    - bounding_box: Tuple(ing) = bounding box of kind (startX, startY, startZ, sizeX, sizeY, sizeZ)\n",
    "\n",
    "    Returns\n",
    "    - cropped_image: sitk.Image = cropped image\n",
    "    \"\"\"\n",
    "\n",
    "    cropped_image = image[\n",
    "        bounding_box[0] : bounding_box[3] + bounding_box[0],\n",
    "        bounding_box[1] : bounding_box[4] + bounding_box[1],\n",
    "        bounding_box[2] : bounding_box[5] + bounding_box[2],\n",
    "    ]\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "\n",
    "def apply_bias_correction(\n",
    "    image: sitk.Image,\n",
    ") -> sitk.Image:\n",
    "    \"\"\"applies N4 bias field correction to image but keeps background at zero\n",
    "\n",
    "    Keyword Arguments:\n",
    "    image: sitk.Image = image to apply bias correction to\n",
    "\n",
    "    Returns:\n",
    "    image_corrected_masked: sitk.Image = N4 bias field corrected image\n",
    "    \"\"\"\n",
    "\n",
    "    mask_image = binary_segment_brain(image)\n",
    "    float_image = sitk.Cast(image, sitk.sitkFloat32) # apparently n4biasfieldcorrectionimagefilter doesn't take int16, that's why i added this line\n",
    "    corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    image_corrected = corrector.Execute(float_image, mask_image)\n",
    "\n",
    "    mask_filter = sitk.MaskImageFilter()\n",
    "    mask_filter.SetOutsideValue(0)\n",
    "    image_corrected_masked = mask_filter.Execute(image_corrected, mask_image)\n",
    "\n",
    "    return image_corrected_masked\n",
    "\n",
    "\n",
    "def coregister_antspy(\n",
    "    fixed_path: Union[str, pathlib.Path],\n",
    "    moving_path: Union[str, pathlib.Path],\n",
    "    out_path: Union[str, pathlib.Path],\n",
    "    num_threads=N_PROC,\n",
    ") -> ants.core.ants_image.ANTsImage:\n",
    "    \"\"\"\n",
    "    Coregister moving image to fixed image. Return warped image and save to disk.\n",
    "\n",
    "    Keyword Arguments:\n",
    "    fixed_path: path to fixed image\n",
    "    moving_path: path to moving image\n",
    "    out_path: path to save warped image to\n",
    "    num_threads: number of threads\n",
    "    \"\"\"\n",
    "\n",
    "    os.environ[\"ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS\"] = str(num_threads)\n",
    "\n",
    "    res = ants.registration(\n",
    "        fixed=ants.image_read(fixed_path),\n",
    "        moving=ants.image_read(moving_path),\n",
    "        type_of_transform=\"antsRegistrationSyNQuick[s]\",  # or \"SyNRA\"\n",
    "        initial_transform=None,\n",
    "        outprefix=\"\",\n",
    "        mask=None,\n",
    "        moving_mask=None,\n",
    "        mask_all_stages=False,\n",
    "        grad_step=0.2,\n",
    "        flow_sigma=3,\n",
    "        total_sigma=0,\n",
    "        aff_metric=\"mattes\",\n",
    "        aff_sampling=32,\n",
    "        aff_random_sampling_rate=0.2,\n",
    "        syn_metric=\"mattes\",\n",
    "        syn_sampling=32,\n",
    "        reg_iterations=(40, 20, 0),\n",
    "        aff_iterations=(2100, 1200, 1200, 10),\n",
    "        aff_shrink_factors=(6, 4, 2, 1),\n",
    "        aff_smoothing_sigmas=(3, 2, 1, 0),\n",
    "        write_composite_transform=False,\n",
    "        random_seed=None,\n",
    "        verbose=False,\n",
    "        multivariate_extras=None,\n",
    "        restrict_transformation=None,\n",
    "        smoothing_in_mm=False,\n",
    "    )\n",
    "\n",
    "    warped_moving = res[\"warpedmovout\"]\n",
    "\n",
    "    ants.image_write(warped_moving, out_path)\n",
    "\n",
    "    return warped_moving\n",
    "\n",
    "\n",
    "def resample(\n",
    "    itk_image: sitk.Image,\n",
    "    out_spacing: Tuple[float, ...],\n",
    "    is_mask: bool,\n",
    ") -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Resamples sitk image to expected output spacing\n",
    "\n",
    "    Keyword Arguments:\n",
    "    itk_image: sitk.Image\n",
    "    out_spacing: Tuple\n",
    "    is_mask: bool = True if input image is label mask -> NN-interpolation\n",
    "\n",
    "    Returns\n",
    "    output_image: sitk.Image = image resampled to out_spacing\n",
    "    \"\"\"\n",
    "\n",
    "    original_spacing = itk_image.GetSpacing()\n",
    "    original_size = itk_image.GetSize()\n",
    "\n",
    "    out_size = [\n",
    "        int(round(osz * osp / nsp))\n",
    "        for osz, osp, nsp in zip(original_size, original_spacing, out_spacing)\n",
    "    ]\n",
    "\n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    resample.SetOutputSpacing(out_spacing)\n",
    "    resample.SetSize(out_size)\n",
    "    resample.SetOutputDirection(itk_image.GetDirection())\n",
    "    resample.SetOutputOrigin(itk_image.GetOrigin())\n",
    "    resample.SetTransform(sitk.Transform())\n",
    "    resample.SetDefaultPixelValue(0)\n",
    "\n",
    "    if is_mask:\n",
    "        resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "\n",
    "    else:\n",
    "        resample.SetInterpolator(\n",
    "            sitk.sitkBSpline\n",
    "        )  # sitk.sitkLinear sitk.sitkNearestNeighbor\n",
    "\n",
    "    output_image = resample.Execute(itk_image)\n",
    "\n",
    "    return output_image\n",
    "\n",
    "\n",
    "def zscore_normalize(image: sitk.Image) -> sitk.Image:\n",
    "    \"\"\"\n",
    "    Applies z score normalization to brain scan using a brain mask\n",
    "\n",
    "    Keyword Arguments:\n",
    "    image: sitk.Image = input brain scan\n",
    "\n",
    "    Returns:\n",
    "    normalized_brain_image: sitk.Image = normalized brain scan\n",
    "    \"\"\"\n",
    "\n",
    "    brain_mask = binary_segment_brain(image)\n",
    "\n",
    "    normalizer = ZScoreNormalize()\n",
    "    normalized_brain_array = normalizer(\n",
    "        sitk.GetArrayFromImage(image),\n",
    "        sitk.GetArrayFromImage(brain_mask),\n",
    "    )\n",
    "\n",
    "    normalized_brain_image = sitk.GetImageFromArray(normalized_brain_array)\n",
    "    normalized_brain_image.CopyInformation(image)\n",
    "\n",
    "    return normalized_brain_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run preprocessing\n",
    "Input arguments:\\\n",
    "path_to_patients: str,\\\n",
    "path_to_output: str,\n",
    "\n",
    "The `path_to_patients` variable should lead to a directory, where all the patients directories can be found, in which all the sequences are storted in one \"anat\" directory full of nifti files\n",
    "\n",
    "`path_to_output`should lead to a directory where a new \"preprocessed\" folder gets created where all the patient files are then stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_patients = \"/Volumes/BrainMets/Rgb_Brain_Mets/brain_mets_classification/rawdata\"\n",
    "path_to_output = \"/Volumes/BrainMets/Rgb_Brain_Mets/brain_mets_classification/derivatives\"\n",
    "\n",
    "N_PROC = multiprocessing.cpu_count() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-01890298_T1w.nii.gz: Starting reorientation\n",
      "240128-15:29:20,934 nipype.interface WARNING:\n",
      "\t FSLOUTPUTTYPE environment variable is not set. Setting FSLOUTPUTTYPE=NIFTI\n",
      "sub-01890298_T1w.nii.gz: Finished reorientation\n",
      "sub-01890298 T1w: Starting brain extraction\n",
      "sub-01890298 T1w: Finished brain extraction\n",
      "sub-01890298_T1c.nii.gz: Starting reorientation\n",
      "240128-15:29:31,812 nipype.interface WARNING:\n",
      "\t FSLOUTPUTTYPE environment variable is not set. Setting FSLOUTPUTTYPE=NIFTI\n",
      "sub-01890298_T1c.nii.gz: Finished reorientation\n",
      "sub-01890298 T1c: Starting brain extraction\n",
      "sub-01890298 T1c: Finished brain extraction\n",
      "sub-01890298_T2w.nii.gz: Starting reorientation\n",
      "240128-15:29:42,578 nipype.interface WARNING:\n",
      "\t FSLOUTPUTTYPE environment variable is not set. Setting FSLOUTPUTTYPE=NIFTI\n",
      "sub-01890298_T2w.nii.gz: Finished reorientation\n",
      "sub-01890298 T2w: Starting brain extraction\n",
      "sub-01890298 T2w: Finished brain extraction\n",
      "sub-01890298_FLAIR.nii.gz: Starting reorientation\n",
      "240128-15:29:56,452 nipype.interface WARNING:\n",
      "\t FSLOUTPUTTYPE environment variable is not set. Setting FSLOUTPUTTYPE=NIFTI\n",
      "sub-01890298_FLAIR.nii.gz: Finished reorientation\n",
      "sub-01890298 FLAIR: Starting brain extraction\n",
      "sub-01890298 FLAIR: Finished brain extraction\n",
      "sub-01890298_T1w_brainextracted.nii.gz: Starting bounding box\n",
      "sub-01890298_T1w_brainextracted.nii.gz: Finished bounding box\n",
      "sub-01890298_T1w_brainextracted.nii.gz: Starting n4 bias correction\n",
      "sub-01890298_T1w_brainextracted.nii.gz: Finished n4 bias correction\n",
      "sub-01890298_T1c_brainextracted.nii.gz: Starting bounding box\n",
      "sub-01890298_T1c_brainextracted.nii.gz: Finished bounding box\n",
      "sub-01890298_T1c_brainextracted.nii.gz: Starting n4 bias correction\n",
      "sub-01890298_T1c_brainextracted.nii.gz: Finished n4 bias correction\n",
      "sub-01890298_T2w_brainextracted.nii.gz: Starting bounding box\n",
      "sub-01890298_T2w_brainextracted.nii.gz: Finished bounding box\n",
      "sub-01890298_T2w_brainextracted.nii.gz: Starting n4 bias correction\n",
      "sub-01890298_T2w_brainextracted.nii.gz: Finished n4 bias correction\n",
      "sub-01890298_FLAIR_brainextracted.nii.gz: Starting bounding box\n",
      "sub-01890298_FLAIR_brainextracted.nii.gz: Finished bounding box\n",
      "sub-01890298_FLAIR_brainextracted.nii.gz: Starting n4 bias correction\n",
      "sub-01890298_FLAIR_brainextracted.nii.gz: Finished n4 bias correction\n",
      "sub-01890298 T1w: Starting coregistration of sequence\n",
      "sub-01890298 T1w: Finished coregistration of sequence\n",
      "sub-01890298 T1w: Stating resampling of images\n",
      "sub-01890298 T1w: Finished resampling of images\n",
      "sub-01890298 T1w: Starting z score normalization of sequence\n",
      "sub-01890298 T1w: Starting z score normalization of sequence\n",
      "sub-01890298 T1c: Starting coregistration of sequence\n",
      "sub-01890298 T1c: Finished coregistration of sequence\n",
      "sub-01890298 T1c: Stating resampling of images\n",
      "sub-01890298 T1c: Finished resampling of images\n",
      "sub-01890298 T1c: Starting z score normalization of sequence\n",
      "sub-01890298 T1c: Starting z score normalization of sequence\n",
      "sub-01890298 T2w: Starting coregistration of sequence\n",
      "sub-01890298 T2w: Finished coregistration of sequence\n",
      "sub-01890298 T2w: Stating resampling of images\n",
      "sub-01890298 T2w: Finished resampling of images\n",
      "sub-01890298 T2w: Starting z score normalization of sequence\n",
      "sub-01890298 T2w: Starting z score normalization of sequence\n",
      "sub-01890298 FLAIR: Starting coregistration of sequence\n",
      "sub-01890298 FLAIR: Finished coregistration of sequence\n",
      "sub-01890298 FLAIR: Stating resampling of images\n",
      "sub-01890298 FLAIR: Finished resampling of images\n",
      "sub-01890298 FLAIR: Starting z score normalization of sequence\n",
      "sub-01890298 FLAIR: Starting z score normalization of sequence\n",
      "Finished patient sub-01890298\n",
      "file to remove: sub-01890298_T1w_reoriented.nii\n",
      "file to remove: sub-01890298_T1w_brainextracted.nii_mask.nii.gz\n",
      "file to remove: sub-01890298_T1w_brainextracted.nii.gz\n",
      "file to remove: sub-01890298_T1c_reoriented.nii\n",
      "file to remove: sub-01890298_T1c_brainextracted.nii_mask.nii.gz\n",
      "file to remove: sub-01890298_T1c_brainextracted.nii.gz\n",
      "file to remove: sub-01890298_T2w_reoriented.nii\n",
      "file to remove: sub-01890298_T2w_brainextracted.nii_mask.nii.gz\n",
      "file to remove: sub-01890298_T2w_brainextracted.nii.gz\n",
      "file to remove: sub-01890298_FLAIR_reoriented.nii\n",
      "file to remove: sub-01890298_FLAIR_brainextracted.nii_mask.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/465 [01:35<12:19:44, 95.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file to remove: sub-01890298_FLAIR_brainextracted.nii.gz\n",
      "file to remove: sub-01890298_T1w_n4biascorrected.nii.gz\n",
      "file to remove: sub-01890298_T1c_n4biascorrected.nii.gz\n",
      "file to remove: sub-01890298_T2w_n4biascorrected.nii.gz\n",
      "file to remove: sub-01890298_FLAIR_n4biascorrected.nii.gz\n",
      "file to remove: sub-01890298_T1w_coregistered.nii.gz\n",
      "file to remove: sub-01890298_T1c_coregistered.nii.gz\n",
      "file to remove: sub-01890298_T2w_coregistered.nii.gz\n",
      "file to remove: sub-01890298_FLAIR_coregistered.nii.gz\n",
      "Cleaned up unnecessary files\n",
      "sub-01935938_T1w.nii.gz: Starting reorientation\n",
      "240128-15:30:56,591 nipype.interface WARNING:\n",
      "\t FSLOUTPUTTYPE environment variable is not set. Setting FSLOUTPUTTYPE=NIFTI\n",
      "sub-01935938_T1w.nii.gz: Finished reorientation\n",
      "sub-01935938 T1w: Starting brain extraction\n",
      "sub-01935938 T1w: Finished brain extraction\n",
      "sub-01935938_T1c.nii.gz: Starting reorientation\n",
      "240128-15:31:08,181 nipype.interface WARNING:\n",
      "\t FSLOUTPUTTYPE environment variable is not set. Setting FSLOUTPUTTYPE=NIFTI\n",
      "sub-01935938_T1c.nii.gz: Finished reorientation\n",
      "sub-01935938 T1c: Starting brain extraction\n",
      "sub-01935938 T1c: Finished brain extraction\n",
      "sub-01935938_T2w.nii.gz: Starting reorientation\n",
      "240128-15:31:19,500 nipype.interface WARNING:\n",
      "\t FSLOUTPUTTYPE environment variable is not set. Setting FSLOUTPUTTYPE=NIFTI\n",
      "sub-01935938_T2w.nii.gz: Finished reorientation\n",
      "sub-01935938 T2w: Starting brain extraction\n",
      "sub-01935938 T2w: Finished brain extraction\n",
      "sub-01935938_FLAIR.nii.gz: Starting reorientation\n",
      "240128-15:31:33,345 nipype.interface WARNING:\n",
      "\t FSLOUTPUTTYPE environment variable is not set. Setting FSLOUTPUTTYPE=NIFTI\n",
      "sub-01935938_FLAIR.nii.gz: Finished reorientation\n",
      "sub-01935938 FLAIR: Starting brain extraction\n",
      "sub-01935938 FLAIR: Finished brain extraction\n",
      "sub-01935938_T1w_brainextracted.nii.gz: Starting bounding box\n",
      "sub-01935938_T1w_brainextracted.nii.gz: Finished bounding box\n",
      "sub-01935938_T1w_brainextracted.nii.gz: Starting n4 bias correction\n",
      "sub-01935938_T1w_brainextracted.nii.gz: Finished n4 bias correction\n",
      "sub-01935938_T1c_brainextracted.nii.gz: Starting bounding box\n",
      "sub-01935938_T1c_brainextracted.nii.gz: Finished bounding box\n",
      "sub-01935938_T1c_brainextracted.nii.gz: Starting n4 bias correction\n",
      "sub-01935938_T1c_brainextracted.nii.gz: Finished n4 bias correction\n",
      "sub-01935938_T2w_brainextracted.nii.gz: Starting bounding box\n",
      "sub-01935938_T2w_brainextracted.nii.gz: Finished bounding box\n",
      "sub-01935938_T2w_brainextracted.nii.gz: Starting n4 bias correction\n",
      "sub-01935938_T2w_brainextracted.nii.gz: Finished n4 bias correction\n",
      "sub-01935938_FLAIR_brainextracted.nii.gz: Starting bounding box\n",
      "sub-01935938_FLAIR_brainextracted.nii.gz: Finished bounding box\n",
      "sub-01935938_FLAIR_brainextracted.nii.gz: Starting n4 bias correction\n",
      "sub-01935938_FLAIR_brainextracted.nii.gz: Finished n4 bias correction\n",
      "sub-01935938 T1w: Starting coregistration of sequence\n",
      "sub-01935938 T1w: Finished coregistration of sequence\n",
      "sub-01935938 T1w: Stating resampling of images\n",
      "sub-01935938 T1w: Finished resampling of images\n",
      "sub-01935938 T1w: Starting z score normalization of sequence\n",
      "sub-01935938 T1w: Starting z score normalization of sequence\n",
      "sub-01935938 T1c: Starting coregistration of sequence\n",
      "sub-01935938 T1c: Finished coregistration of sequence\n",
      "sub-01935938 T1c: Stating resampling of images\n",
      "sub-01935938 T1c: Finished resampling of images\n",
      "sub-01935938 T1c: Starting z score normalization of sequence\n",
      "sub-01935938 T1c: Starting z score normalization of sequence\n",
      "sub-01935938 T2w: Starting coregistration of sequence\n",
      "sub-01935938 T2w: Finished coregistration of sequence\n",
      "sub-01935938 T2w: Stating resampling of images\n",
      "sub-01935938 T2w: Finished resampling of images\n",
      "sub-01935938 T2w: Starting z score normalization of sequence\n",
      "sub-01935938 T2w: Starting z score normalization of sequence\n",
      "sub-01935938 FLAIR: Starting coregistration of sequence\n",
      "sub-01935938 FLAIR: Finished coregistration of sequence\n",
      "sub-01935938 FLAIR: Stating resampling of images\n",
      "sub-01935938 FLAIR: Finished resampling of images\n",
      "sub-01935938 FLAIR: Starting z score normalization of sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/465 [03:12<12:24:58, 96.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-01935938 FLAIR: Starting z score normalization of sequence\n",
      "Finished patient sub-01935938\n",
      "file to remove: sub-01935938_T1w_reoriented.nii\n",
      "file to remove: sub-01935938_T1w_brainextracted.nii_mask.nii.gz\n",
      "file to remove: sub-01935938_T1w_brainextracted.nii.gz\n",
      "file to remove: sub-01935938_T1c_reoriented.nii\n",
      "file to remove: sub-01935938_T1c_brainextracted.nii_mask.nii.gz\n",
      "file to remove: sub-01935938_T1c_brainextracted.nii.gz\n",
      "file to remove: sub-01935938_T2w_reoriented.nii\n",
      "file to remove: sub-01935938_T2w_brainextracted.nii_mask.nii.gz\n",
      "file to remove: sub-01935938_T2w_brainextracted.nii.gz\n",
      "file to remove: sub-01935938_FLAIR_reoriented.nii\n",
      "file to remove: sub-01935938_FLAIR_brainextracted.nii_mask.nii.gz\n",
      "file to remove: sub-01935938_FLAIR_brainextracted.nii.gz\n",
      "file to remove: sub-01935938_T1w_n4biascorrected.nii.gz\n",
      "file to remove: sub-01935938_T1c_n4biascorrected.nii.gz\n",
      "file to remove: sub-01935938_T2w_n4biascorrected.nii.gz\n",
      "file to remove: sub-01935938_FLAIR_n4biascorrected.nii.gz\n",
      "file to remove: sub-01935938_T1w_coregistered.nii.gz\n",
      "file to remove: sub-01935938_T1c_coregistered.nii.gz\n",
      "file to remove: sub-01935938_T2w_coregistered.nii.gz\n",
      "file to remove: sub-01935938_FLAIR_coregistered.nii.gz\n",
      "Cleaned up unnecessary files\n",
      "sub-01199093_T1w.nii.gz: Starting reorientation\n",
      "240128-15:32:33,751 nipype.interface WARNING:\n",
      "\t FSLOUTPUTTYPE environment variable is not set. Setting FSLOUTPUTTYPE=NIFTI\n",
      "sub-01199093_T1w.nii.gz: Finished reorientation\n",
      "sub-01199093 T1w: Starting brain extraction\n",
      "sub-01199093 T1w: Finished brain extraction\n",
      "sub-01199093_T1c.nii.gz: Starting reorientation\n",
      "240128-15:32:48,27 nipype.interface WARNING:\n",
      "\t FSLOUTPUTTYPE environment variable is not set. Setting FSLOUTPUTTYPE=NIFTI\n",
      "sub-01199093_T1c.nii.gz: Finished reorientation\n",
      "sub-01199093 T1c: Starting brain extraction\n",
      "sub-01199093 T1c: Finished brain extraction\n",
      "sub-01199093_T2w.nii.gz: Starting reorientation\n",
      "240128-15:33:02,35 nipype.interface WARNING:\n",
      "\t FSLOUTPUTTYPE environment variable is not set. Setting FSLOUTPUTTYPE=NIFTI\n",
      "sub-01199093_T2w.nii.gz: Finished reorientation\n",
      "sub-01199093 T2w: Starting brain extraction\n",
      "sub-01199093 T2w: Finished brain extraction\n",
      "sub-01199093_FLAIR.nii.gz: Starting reorientation\n",
      "240128-15:33:16,29 nipype.interface WARNING:\n",
      "\t FSLOUTPUTTYPE environment variable is not set. Setting FSLOUTPUTTYPE=NIFTI\n",
      "sub-01199093_FLAIR.nii.gz: Finished reorientation\n",
      "sub-01199093 FLAIR: Starting brain extraction\n",
      "sub-01199093 FLAIR: Finished brain extraction\n",
      "sub-01199093_T1w_brainextracted.nii.gz: Starting bounding box\n",
      "sub-01199093_T1w_brainextracted.nii.gz: Finished bounding box\n",
      "sub-01199093_T1w_brainextracted.nii.gz: Starting n4 bias correction\n",
      "sub-01199093_T1w_brainextracted.nii.gz: Finished n4 bias correction\n",
      "sub-01199093_T1c_brainextracted.nii.gz: Starting bounding box\n",
      "sub-01199093_T1c_brainextracted.nii.gz: Finished bounding box\n",
      "sub-01199093_T1c_brainextracted.nii.gz: Starting n4 bias correction\n",
      "sub-01199093_T1c_brainextracted.nii.gz: Finished n4 bias correction\n",
      "sub-01199093_T2w_brainextracted.nii.gz: Starting bounding box\n",
      "sub-01199093_T2w_brainextracted.nii.gz: Finished bounding box\n",
      "sub-01199093_T2w_brainextracted.nii.gz: Starting n4 bias correction\n",
      "sub-01199093_T2w_brainextracted.nii.gz: Finished n4 bias correction\n",
      "sub-01199093_FLAIR_brainextracted.nii.gz: Starting bounding box\n",
      "sub-01199093_FLAIR_brainextracted.nii.gz: Finished bounding box\n",
      "sub-01199093_FLAIR_brainextracted.nii.gz: Starting n4 bias correction\n",
      "sub-01199093_FLAIR_brainextracted.nii.gz: Finished n4 bias correction\n",
      "sub-01199093 T1w: Starting coregistration of sequence\n",
      "sub-01199093 T1w: Finished coregistration of sequence\n",
      "sub-01199093 T1w: Stating resampling of images\n",
      "sub-01199093 T1w: Finished resampling of images\n",
      "sub-01199093 T1w: Starting z score normalization of sequence\n",
      "sub-01199093 T1w: Starting z score normalization of sequence\n",
      "sub-01199093 T1c: Starting coregistration of sequence\n",
      "sub-01199093 T1c: Finished coregistration of sequence\n",
      "sub-01199093 T1c: Stating resampling of images\n",
      "sub-01199093 T1c: Finished resampling of images\n",
      "sub-01199093 T1c: Starting z score normalization of sequence\n",
      "sub-01199093 T1c: Starting z score normalization of sequence\n",
      "sub-01199093 T2w: Starting coregistration of sequence\n",
      "sub-01199093 T2w: Finished coregistration of sequence\n",
      "sub-01199093 T2w: Stating resampling of images\n",
      "sub-01199093 T2w: Finished resampling of images\n",
      "sub-01199093 T2w: Starting z score normalization of sequence\n",
      "sub-01199093 T2w: Starting z score normalization of sequence\n",
      "sub-01199093 FLAIR: Starting coregistration of sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/465 [06:49<26:18:50, 204.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 108\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT1CE\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m n4correctedFile:\n\u001b[1;32m    105\u001b[0m     \n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# coregister images\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatientID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequenceType\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Starting coregistration of sequence\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m     \u001b[43mcoregister_antspy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_preprocessed_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatientID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferenceSequenceForCoregistration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmoving_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_preprocessed_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatientID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn4correctedFile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcoregistered_out_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mN_PROC\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatientID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequenceType\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Finished coregistration of sequence\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[7], line 155\u001b[0m, in \u001b[0;36mcoregister_antspy\u001b[0;34m(fixed_path, moving_path, out_path, num_threads)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03mCoregister moving image to fixed image. Return warped image and save to disk.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03mnum_threads: number of threads\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    153\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(num_threads)\n\u001b[0;32m--> 155\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmoving\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmoving_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_of_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mantsRegistrationSyNQuick[s]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or \"SyNRA\"\u001b[39;49;00m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmoving_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_all_stages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflow_sigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_sigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43maff_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmattes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43maff_sampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43maff_random_sampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43msyn_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmattes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43msyn_sampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreg_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43maff_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43maff_shrink_factors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43maff_smoothing_sigmas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_composite_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultivariate_extras\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestrict_transformation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43msmoothing_in_mm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m warped_moving \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarpedmovout\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    186\u001b[0m ants\u001b[38;5;241m.\u001b[39mimage_write(warped_moving, out_path)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/ants/registration/interface.py:1346\u001b[0m, in \u001b[0;36mregistration\u001b[0;34m(fixed, moving, type_of_transform, initial_transform, outprefix, mask, moving_mask, mask_all_stages, grad_step, flow_sigma, total_sigma, aff_metric, aff_sampling, aff_random_sampling_rate, syn_metric, syn_sampling, reg_iterations, aff_iterations, aff_shrink_factors, aff_smoothing_sigmas, write_composite_transform, random_seed, verbose, multivariate_extras, restrict_transformation, smoothing_in_mm, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mantsRegistration \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(processed_args))\n\u001b[0;32m-> 1346\u001b[0m reg_exit \u001b[38;5;241m=\u001b[39m \u001b[43mlibfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (reg_exit \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegistration failed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreg_exit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create folder at path to output called Rgb_Brain_Mets_preprocessed\n",
    "now = datetime.now()\n",
    "timeFormatted = now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "path_to_preprocessed_files = f\"{path_to_output}/preprocessed_{timeFormatted}\"\n",
    "os.mkdir(path_to_preprocessed_files)\n",
    "\n",
    "filetypes_to_remove = [\"reoriented\", \"brainextracted\", \"n4biascorrected\", \"coregistered\"]\n",
    "\n",
    "# gets only the folders at path and puts them in an array \n",
    "patient_folders = [\n",
    "    folder for folder in os.listdir(path_to_patients) if os.path.isdir(os.path.join(path_to_patients, folder))\n",
    "]\n",
    "\n",
    "for patient in tqdm(patient_folders):\n",
    "\n",
    "     # ignores the ds_folders\n",
    "    if config.dsStore in patient:\n",
    "        continue\n",
    "    \n",
    "    patientID = patient\n",
    "\n",
    "    # create folder for patient in path_to_preprocessed_files\n",
    "    funcs.createFolderForPatient(path_to_preprocessed_files, patientID)\n",
    "\n",
    "    # get the different sequences for each patient and put them in an array\n",
    "    niftiSequences = [\n",
    "        sequence for sequence in os.listdir(os.path.join(path_to_patients, patient, \"anat\")) if \".nii\" in sequence\n",
    "    ]\n",
    "\n",
    "    if len(niftiSequences) < 4:\n",
    "        print(f\"Warning: too few nifti files found ({len(niftiSequences)})\")\n",
    "\n",
    "    # loop through the nifit sequences\n",
    "    for niftiSequence in niftiSequences:\n",
    "\n",
    "        # reorient images\n",
    "        print(f\"{niftiSequence}: Starting reorientation\")\n",
    "        sequenceType = (niftiSequence.split(\"_\")[1]).split(\".\")[0]\n",
    "        path_to_input_image = os.path.join(path_to_patients, patient, \"anat\", niftiSequence)\n",
    "        #path_to_output_reorientedImage = f\"{path_to_patients}/{patient}/{patientID}_{sequenceType}_reoriented.nii\"\n",
    "        path_to_output_reorientedImage = f\"{path_to_preprocessed_files}/{patientID}/{patientID}_{sequenceType}_reoriented.nii\"\n",
    "        preprocessing.reorient_brain(\n",
    "            path_to_input_image = path_to_input_image,\n",
    "            path_to_output_image = path_to_output_reorientedImage\n",
    "        )\n",
    "        print(f\"{niftiSequence}: Finished reorientation\")\n",
    "\n",
    "        # use brain extraction\n",
    "        print(f\"{patientID} {sequenceType}: Starting brain extraction\")\n",
    "        path_to_output_extractedImage = f\"{path_to_preprocessed_files}/{patientID}/{patientID}_{sequenceType}_brainextracted.nii\"\n",
    "        extract_brain(\n",
    "            path_to_input_image = path_to_input_image,\n",
    "            path_to_output_image = path_to_output_extractedImage,\n",
    "            device = \"cpu\")\n",
    "        print(f\"{patientID} {sequenceType}: Finished brain extraction\")\n",
    "    \n",
    "    # get the brain extracted files\n",
    "    brainExtractedFiles = [\n",
    "        sequence for sequence in os.listdir(os.path.join(path_to_preprocessed_files, patientID)) if (\"brainextracted\" in sequence and \"mask\" not in sequence)\n",
    "    ]\n",
    "\n",
    "    if len(brainExtractedFiles) < 4:\n",
    "        print(f\"Warning: too few brain extracted files found ({len(brainExtractedFiles)})\")\n",
    "\n",
    "    # loop through the nifit sequences\n",
    "    for brainExtractedSequence in brainExtractedFiles:\n",
    "        print(f\"{brainExtractedSequence}: Starting bounding box\")\n",
    "\n",
    "        input_image = sitk.ReadImage(os.path.join(path_to_preprocessed_files, patientID, brainExtractedSequence), imageIO=\"NiftiImageIO\")\n",
    "\n",
    "        # get and apply a bounding box both to the brain as well as the mask\n",
    "        croppedImage = apply_bounding_box(\n",
    "            image = input_image,\n",
    "            bounding_box = get_bounding_box(image = input_image))\n",
    "        print(f\"{brainExtractedSequence}: Finished bounding box\")\n",
    "\n",
    "        # n4 bias correction\n",
    "        print(f\"{brainExtractedSequence}: Starting n4 bias correction\")\n",
    "        n4correctedImage = apply_bias_correction(image = croppedImage)\n",
    "        print(f\"{brainExtractedSequence}: Finished n4 bias correction\")\n",
    "\n",
    "        # save image\n",
    "        sequenceType = (brainExtractedSequence.split(\"_\")[1]).split(\".\")[0]\n",
    "        path_to_output_image = f\"{path_to_preprocessed_files}/{patientID}/{patientID}_{sequenceType}_n4biascorrected.nii.gz\"\n",
    "        sitk.WriteImage(n4correctedImage, path_to_output_image, imageIO = \"NiftiImageIO\")\n",
    "\n",
    "\n",
    "    n4correctedFiles = [\n",
    "        sequence for sequence in os.listdir(os.path.join(path_to_preprocessed_files, patient)) if (\"_n4biascorrected\" in sequence)\n",
    "    ]\n",
    "\n",
    "    if len(n4correctedFiles) < 4:\n",
    "        print(f\"Warning: too few brain n4biascorrected files found ({len(n4correctedFiles)})\")\n",
    "\n",
    "    # the T1CE sequence was arbitrarily chosen as a reference sequence for the coregistration\n",
    "    referenceSequenceForCoregistration = [reference for reference in n4correctedFiles if \"T1c\" in reference][0]\n",
    "\n",
    "    for n4correctedFile in n4correctedFiles:\n",
    "        \n",
    "        sequenceType = (n4correctedFile.split(\"_\")[1]).split(\".\")[0]\n",
    "        coregistered_out_path = f\"{path_to_preprocessed_files}/{patientID}/{patientID}_{sequenceType}_coregistered.nii.gz\"\n",
    "\n",
    "        # skip coregistration for the reference Sequence \n",
    "        if \"T1CE\" not in n4correctedFile:\n",
    "            \n",
    "            # coregister images\n",
    "            print(f\"{patientID} {sequenceType}: Starting coregistration of sequence\")\n",
    "            coregister_antspy(\n",
    "                fixed_path = os.path.join(path_to_preprocessed_files, patientID, referenceSequenceForCoregistration),\n",
    "                moving_path = os.path.join(path_to_preprocessed_files, patientID, n4correctedFile),\n",
    "                out_path = coregistered_out_path,\n",
    "                num_threads = N_PROC)\n",
    "            print(f\"{patientID} {sequenceType}: Finished coregistration of sequence\")\n",
    "        else:\n",
    "            coregistered_out_path = f\"{path_to_preprocessed_files}/{patientID}/{n4correctedFile}\"\n",
    "\n",
    "        coregistered_image = sitk.ReadImage(coregistered_out_path, imageIO=\"NiftiImageIO\")\n",
    "\n",
    "\n",
    "        # resample images\n",
    "        print(f\"{patientID} {sequenceType}: Stating resampling of images\")\n",
    "        resampled_image = resample(\n",
    "            itk_image = coregistered_image,\n",
    "            out_spacing = (1,1,1),\n",
    "            is_mask = False\n",
    "        )\n",
    "        print(f\"{patientID} {sequenceType}: Finished resampling of images\")\n",
    "\n",
    "        # z score normalize images\n",
    "        print(f\"{patientID} {sequenceType}: Starting z score normalization of sequence\")\n",
    "        z_normalized_image = zscore_normalize(resampled_image)\n",
    "        print(f\"{patientID} {sequenceType}: Starting z score normalization of sequence\")\n",
    "\n",
    "        # save z_normalized_image in the finished preprocessing folder\n",
    "        sitk.WriteImage(z_normalized_image, f\"{path_to_preprocessed_files}/{patientID}/{patientID}_{sequenceType}_preprocessed.nii.gz\", imageIO = \"NiftiImageIO\")\n",
    "\n",
    "    print(f\"Finished patient {patientID}\")\n",
    "    \n",
    "    patientFiles = os.listdir(os.path.join(path_to_preprocessed_files, patientID))\n",
    "\n",
    "    for file in patientFiles:\n",
    "        if any(fileType in file for fileType in filetypes_to_remove):\n",
    "            print(f\"file to remove: {file}\")\n",
    "            os.remove(os.path.join(path_to_preprocessed_files, patientID, file))\n",
    "\n",
    "    # clean up created files (nifti files and brain extracted images)\n",
    "    print(\"Cleaned up unnecessary files\")\n",
    "\n",
    "print(\"Finished preprocessing images\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".brain_mets_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
