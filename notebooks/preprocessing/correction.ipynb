{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correction\n",
    "I found some patients where I have to redo the preprocessing and segemntation because the wrong images were chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from nipype.interfaces.dcm2nii import Dcm2niix\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_output = Path(\"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24\")\n",
    "path_to_dicom_files = Path(\"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24/DICOM_files\")\n",
    "path_to_nifti_files = \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24/Nifti_files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICOM to NIFTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240726-10:35:53,621 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.621233:Chris Rorden's dcm2niiX version v1.0.20220505  Clang15.0.0 ARM (64-bit MacOS)\n",
      "240726-10:35:53,622 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.621233:Found 24 DICOM file(s)\n",
      "240726-10:35:53,622 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.621233:Warning: Weird CSA 'ProtocolSliceNumber' (System/Miscellaneous/ImageNumbering reversed): VALIDATE SLICETIMING AND BVECS\n",
      "240726-10:35:53,622 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.621233:Warning: Assuming mosaics saved in reverse order due to 'sSliceArray.ucImageNumb'\n",
      "240726-10:35:53,623 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.621233:Convert 24 DICOM as /Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24/Nifti_files/01852952/01852952_T1 (240x320x24x1)\n",
      "240726-10:35:53,714 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.714546:Compress: \"/opt/homebrew/bin/pigz\" -b 960 -n -f -6 \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24/Nifti_files/01852952/01852952_T1.nii\"\n",
      "240726-10:35:53,715 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.714546:Conversion required 0.115866 seconds (0.014235 for core code).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240726-10:35:53,824 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.824485:Chris Rorden's dcm2niiX version v1.0.20220505  Clang15.0.0 ARM (64-bit MacOS)\n",
      "240726-10:35:53,825 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.824485:Found 24 DICOM file(s)\n",
      "240726-10:35:53,825 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.824485:Warning: Weird CSA 'ProtocolSliceNumber' (System/Miscellaneous/ImageNumbering reversed): VALIDATE SLICETIMING AND BVECS\n",
      "240726-10:35:53,825 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.824485:Warning: Assuming mosaics saved in reverse order due to 'sSliceArray.ucImageNumb'\n",
      "240726-10:35:53,826 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.824485:Convert 24 DICOM as /Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24/Nifti_files/01852952/01852952_T1C (240x320x24x1)\n",
      "240726-10:35:53,882 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.882321:Compress: \"/opt/homebrew/bin/pigz\" -b 960 -n -f -6 \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24/Nifti_files/01852952/01852952_T1C.nii\"\n",
      "240726-10:35:53,882 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.882321:Conversion required 0.084467 seconds (0.010676 for core code).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240726-10:35:53,985 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.985836:Chris Rorden's dcm2niiX version v1.0.20220505  Clang15.0.0 ARM (64-bit MacOS)\n",
      "240726-10:35:53,986 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.985836:Found 24 DICOM file(s)\n",
      "240726-10:35:53,987 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.985836:Warning: Weird CSA 'ProtocolSliceNumber' (System/Miscellaneous/ImageNumbering reversed): VALIDATE SLICETIMING AND BVECS\n",
      "240726-10:35:53,987 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.985836:Warning: Assuming mosaics saved in reverse order due to 'sSliceArray.ucImageNumb'\n",
      "240726-10:35:53,987 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:53.985836:Convert 24 DICOM as /Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24/Nifti_files/01852952/01852952_T2 (384x384x24x1)\n",
      "240726-10:35:54,78 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:54.078806:Compress: \"/opt/homebrew/bin/pigz\" -b 960 -n -f -6 \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24/Nifti_files/01852952/01852952_T2.nii\"\n",
      "240726-10:35:54,79 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:54.078806:Conversion required 0.114420 seconds (0.012342 for core code).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240726-10:35:54,171 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:54.171199:Chris Rorden's dcm2niiX version v1.0.20220505  Clang15.0.0 ARM (64-bit MacOS)\n",
      "240726-10:35:54,172 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:54.171199:Found 24 DICOM file(s)\n",
      "240726-10:35:54,172 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:54.171199:Warning: Weird CSA 'ProtocolSliceNumber' (System/Miscellaneous/ImageNumbering reversed): VALIDATE SLICETIMING AND BVECS\n",
      "240726-10:35:54,172 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:54.171199:Warning: Assuming mosaics saved in reverse order due to 'sSliceArray.ucImageNumb'\n",
      "240726-10:35:54,172 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:54.171199:Convert 24 DICOM as /Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24/Nifti_files/01852952/01852952_FLAIR (320x320x24x1)\n",
      "240726-10:35:54,230 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:54.230324:Compress: \"/opt/homebrew/bin/pigz\" -b 960 -n -f -6 \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24/Nifti_files/01852952/01852952_FLAIR.nii\"\n",
      "240726-10:35:54,230 nipype.interface INFO:\n",
      "\t stdout 2024-07-26T10:35:54.230324:Conversion required 0.078720 seconds (0.009918 for core code).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "patients = [patient for patient in os.listdir(path_to_dicom_files) if os.path.isdir(os.path.join(path_to_dicom_files, patient))]\n",
    "\n",
    "for patient in tqdm(patients):\n",
    "\n",
    "    os.makedirs(os.path.join(path_to_nifti_files, patient), exist_ok=True)\n",
    "\n",
    "    # example patient name: 12345678\n",
    "    patientID = patient\n",
    "\n",
    "    path_to_patient = path_to_dicom_files / patient\n",
    "\n",
    "    # gets only the folders at path and puts them in an array \n",
    "    sequences = [\n",
    "        folder for folder in os.listdir(path_to_patient) if os.path.isdir(os.path.join(path_to_patient, folder))\n",
    "    ]\n",
    "\n",
    "    for sequence in tqdm(sequences):\n",
    "\n",
    "        # example sequence name: 12345678_T1_0_SEQUENCENAME\n",
    "        sequenceType = sequence.split(\"_\")[1]\n",
    "\n",
    "        # new sequence name: {patientID}_{sequence}_{preprocessingStep}\n",
    "        converter = Dcm2niix()\n",
    "        converter.inputs.source_dir = os.path.join(path_to_dicom_files, patient, sequence)\n",
    "        converter.inputs.compress = \"y\" # uses compression, \"y\" = yes\n",
    "        converter.inputs.merge_imgs = True\n",
    "        # converter.inputs.compression = 5\n",
    "        converter.inputs.out_filename = f\"{patientID}_{sequenceType}\"\n",
    "        converter.inputs.output_dir = os.path.join(path_to_nifti_files, patient)\n",
    "        converter.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/brainles_preprocessing/registration/__init__.py:13: UserWarning:\n",
      "\n",
      "eReg package not found. If you want to use it, please install it using 'pip install brainles_preprocessing[ereg]'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from auxiliary.normalization.percentile_normalizer import PercentileNormalizer\n",
    "from auxiliary.turbopath import turbopath\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from brainles_preprocessing.brain_extraction import HDBetExtractor\n",
    "from brainles_preprocessing.modality import Modality\n",
    "from brainles_preprocessing.preprocessor import Preprocessor\n",
    "from brainles_preprocessing.registration import (ANTsRegistrator)\n",
    "\n",
    "from intensity_normalization.normalize.zscore import ZScoreNormalize\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_directory = path_to_nifti_files\n",
    "\n",
    "output_folder_keywords = \"preprocessed_n4_brainlesion_percentile\"\n",
    "n4_norm_folder = \"n4_normalized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyException(Exception):\n",
    "    def __init__(self, message, *args):\n",
    "        self.message = message # without this you may get DeprecationWarning\n",
    "        # Special attribute you desire with your Error, \n",
    "        # perhaps the value that caused the error?:\n",
    "        # allow users initialize misc. arguments as any other builtin Error\n",
    "        super(MyException, self).__init__(message, *args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize():\n",
    "\n",
    "    now = datetime.now()\n",
    "    timeFormatted = now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    path_to_preprocessed_files = f\"{path_to_output}/preprocessed_n4_brainlesion_percentile_{timeFormatted}\"\n",
    "\n",
    "    preprocessed_folder_exists = False\n",
    "\n",
    "    for file in os.listdir(path_to_output):\n",
    "        if \"n4_brainlesion_percentile\" in file:\n",
    "            path_to_preprocessed_files = f\"{path_to_output}/{file}\"\n",
    "            preprocessed_folder_exists = True\n",
    "    \n",
    "    if preprocessed_folder_exists == False:\n",
    "        os.mkdir(path_to_preprocessed_files)\n",
    "\n",
    "    #os.makedirs(path_to_preprocessed_files, exist_ok=True)\n",
    "\n",
    "    patients = [patient for patient in os.listdir(patients_directory) if os.path.isdir(os.path.join(patients_directory, patient))]\n",
    "    print(f\"found {len(patients)} patients\")\n",
    "\n",
    "    for patient in tqdm(patients):\n",
    "        print(f\"currently normalizing patient {patient}\")\n",
    "\n",
    "        path_to_patient_files = Path(patients_directory) / Path(patient)\n",
    "\n",
    "        raw_files = [file for file in os.listdir(path_to_patient_files) if \".nii.gz\" in file]\n",
    "\n",
    "        # create subfolder for each patient\n",
    "        path_to_normalized_folder = Path(path_to_preprocessed_files) / Path(patient) / \"n4_normalized\"\n",
    "        os.makedirs(path_to_normalized_folder, exist_ok=True)\n",
    "\n",
    "        for raw_file in raw_files:\n",
    "\n",
    "            if raw_file.startswith(\".\"):\n",
    "                continue\n",
    "\n",
    "            sequence_type = raw_file.split(\"_\")[1].split(\".nii\")[0]\n",
    "            file_name = patient + \"_n4_normalized_\" + sequence_type + \".nii.gz\"\n",
    "            path_to_normalized_file = path_to_normalized_folder / Path(file_name)\n",
    "\n",
    "            # print(f\"starting z_score bias correction for {raw_file}\")\n",
    "\n",
    "            path_to_file = Path(path_to_patient_files) / raw_file\n",
    "            sitk_image = sitk.ReadImage(path_to_file)\n",
    "            sitk_image = sitk.Cast(sitk_image, sitk.sitkFloat32)\n",
    "            # z_score_normalized_image = z_score_normalize(path_to_file)\n",
    "\n",
    "            # print(f\"finished z_score bias correction for {raw_file}\")\n",
    "\n",
    "            print(f\"starting n4 bias correction for {raw_file}\")\n",
    "\n",
    "            n4_bias_correction(sitk_image, path_to_normalized_file)\n",
    "            \n",
    "            print(f\"finished n4 bias correction for {raw_file}\")\n",
    "\n",
    "def n4_bias_correction(image, path_to_output):\n",
    "    \"\"\"\n",
    "    Applies N4 bias field correction to the given image and saves the corrected image to the specified output path.\n",
    "\n",
    "    Parameters:\n",
    "        image (sitk.Image): The input image to be corrected.\n",
    "        path_to_output (str or pathlib.Path): The path to save the corrected image.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    image_corrected = corrector.Execute(image)\n",
    "\n",
    "    sitk.WriteImage(image_corrected, str(path_to_output))\n",
    "\n",
    "def run_preprocessing():\n",
    "    patients_to_preprocesse = [\"01852952\"]\n",
    "\n",
    "    print(f\"amount of patients to preprocess: {len(patients_to_preprocesse)}\")\n",
    "\n",
    "    # on Lennart's Mac Book:\n",
    "    #patients_directory = \"/Users/LennartPhilipp/Desktop/testing_data/raw_data\"\n",
    "\n",
    "    # with docker\n",
    "    #patients_directory = \"/data\"\n",
    "\n",
    "    # on Lennart's Mac Book:\n",
    "    #path_to_output = \"/Users/LennartPhilipp/Desktop/testing_data/derivatives\"\n",
    "\n",
    "    # with docker\n",
    "    #path_to_output = \"/output\"\n",
    "\n",
    "\n",
    "    path_to_preprocessed_files = \"\"\n",
    "    preprocessed_folder_exists = False\n",
    "\n",
    "    for file in os.listdir(path_to_output):\n",
    "        if output_folder_keywords in file:\n",
    "            path_to_preprocessed_files = f\"{path_to_output}/{file}\"\n",
    "            preprocessed_folder_exists = True\n",
    "    \n",
    "    if preprocessed_folder_exists == False:\n",
    "        raise MyException(\"preprocessed folder doesn't exist\")\n",
    "    \n",
    "    data_dir = turbopath(path_to_preprocessed_files)\n",
    "\n",
    "    patients = data_dir.dirs()\n",
    "\n",
    "    for patient in tqdm(patients):\n",
    "\n",
    "        if patient.name not in patients_to_preprocesse:\n",
    "            print(f\"skipping patient: {patient.name}\")\n",
    "            continue\n",
    "        print(\"processing: \", patient.name)\n",
    "        preprocessed_folder = [folder for folder in patient.dirs() if n4_norm_folder in folder.name][0]\n",
    "        preprocess_exam_in_brats_style(inputDir = preprocessed_folder,\n",
    "                                       patID = patient.name,\n",
    "                                       outputDir = path_to_preprocessed_files)\n",
    "\n",
    "    print(\"*** finished preprocessing ***\")\n",
    "\n",
    "def preprocess_exam_in_brats_style(inputDir: str, patID: str, outputDir: str) -> None:\n",
    "    \"\"\"\n",
    "    Perform BRATS (Brain Tumor Segmentation) style preprocessing on MRI exam data.\n",
    "\n",
    "    Args:\n",
    "        inputDir (str): Path to the directory containing raw MRI files for an exam.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If any error occurs during the preprocessing.\n",
    "\n",
    "    Example:\n",
    "        brat_style_preprocess_exam(\"/path/to/exam_directory\")\n",
    "\n",
    "    This function preprocesses MRI exam data following the BRATS style, which includes the following steps:\n",
    "    1. Normalization using a percentile normalizer.\n",
    "    2. Registration and correction using NiftyReg.\n",
    "    3. Brain extraction using HDBet.\n",
    "\n",
    "    The processed data is saved in a structured directory within the input directory.\n",
    "\n",
    "    Args:\n",
    "        inputDir (str): Path to the directory containing raw MRI files for an exam.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # create subfolder for each patient\n",
    "    # check if patient directory already exists\n",
    "    pat_directory = f\"{outputDir}/{patID}\"\n",
    "    if patID not in os.listdir(outputDir):\n",
    "        # if not create new directory for patient\n",
    "        os.mkdir(pat_directory)\n",
    "    else:\n",
    "        print(\"Warning: patient directory already exists\")\n",
    "\n",
    "    inputDir = turbopath(inputDir)\n",
    "    outputDir = turbopath(outputDir)\n",
    "    print(\"*** start ***\")\n",
    "    brainles_dir = pat_directory\n",
    "    raw_bet_dir = turbopath(pat_directory) / \"raw_bet\"\n",
    "\n",
    "    t1_file = inputDir / patID + \"_n4_normalized_\" + \"T1w.nii.gz\"\n",
    "    t1c_file = inputDir / patID + \"_n4_normalized_\" + \"T1c.nii.gz\"\n",
    "    t2_file = inputDir / patID + \"_n4_normalized_\" + \"T2w.nii.gz\"\n",
    "    flair_file = inputDir / patID + \"_n4_normalized_\" + \"FLAIR.nii.gz\"\n",
    "    \n",
    "    \n",
    "    # normalizer\n",
    "    percentile_normalizer = PercentileNormalizer(\n",
    "        lower_percentile=0.1,\n",
    "        upper_percentile=99.9,\n",
    "        lower_limit=0,\n",
    "        upper_limit=1,\n",
    "    )\n",
    "    # define modalities\n",
    "    center = Modality(\n",
    "        modality_name=\"t1c\",\n",
    "        input_path=t1c_file,\n",
    "        raw_bet_output_path=raw_bet_dir / patID\n",
    "        + \"_t1c_bet_normalized.nii.gz\",\n",
    "        atlas_correction=True,\n",
    "        #normalizer=percentile_normalizer,\n",
    "    )\n",
    "\n",
    "    moving_modalities = [\n",
    "        Modality(\n",
    "            modality_name=\"t1\",\n",
    "            input_path=t1_file,\n",
    "            raw_bet_output_path=raw_bet_dir / patID\n",
    "            + \"_t1_bet_raw.nii.gz\",\n",
    "            atlas_correction=True,\n",
    "            #normalizer=percentile_normalizer,\n",
    "        ),\n",
    "        Modality(\n",
    "            modality_name=\"t2\",\n",
    "            input_path=t2_file,\n",
    "            raw_bet_output_path=raw_bet_dir / patID\n",
    "            + \"_t2_bet_raw.nii.gz\",\n",
    "            atlas_correction=True,\n",
    "            #normalizer=percentile_normalizer,\n",
    "        ),\n",
    "        Modality(\n",
    "            modality_name=\"flair\",\n",
    "            input_path=flair_file,\n",
    "            raw_bet_output_path=raw_bet_dir / patID\n",
    "            + \"_fla_bet_raw.nii.gz\",\n",
    "            atlas_correction=True,\n",
    "            #normalizer=percentile_normalizer,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    print(\"preparing preprocessor\")\n",
    "\n",
    "    preprocessor = Preprocessor(\n",
    "        center_modality=center,\n",
    "        moving_modalities=moving_modalities,\n",
    "        registrator=ANTsRegistrator(), # previously NiftRegRegistrator()\n",
    "        brain_extractor=HDBetExtractor(),\n",
    "        use_gpu=True,\n",
    "    )\n",
    "\n",
    "    preprocessor.run(\n",
    "        save_dir_coregistration=brainles_dir + \"/co-registration\",\n",
    "        save_dir_atlas_registration=brainles_dir + \"/atlas-registration\",\n",
    "        save_dir_atlas_correction=brainles_dir + \"/atlas-correction\",\n",
    "        save_dir_brain_extraction=brainles_dir + \"/brain-extraction\",\n",
    "    )\n",
    "\n",
    "    print(f\"finished preprocessing for {patID}\")\n",
    "\n",
    "\n",
    "def perc_normalize_and_save():\n",
    "    \"\"\"\n",
    "    Performs percentile normalization and saving of preprocessed files.\n",
    "\n",
    "    This function iterates through the files in the specified output directory. If a file contains the string\n",
    "    \"z_score_n4_brainlesion_percentile\", the path to that file is stored in the `path_to_preprocessed` variable.\n",
    "    If no such file is found, a `MyException` is raised.\n",
    "\n",
    "    Next, the function finds all patient directories in the `path_to_preprocessed` directory and stores their names\n",
    "    in the `patients` list.\n",
    "\n",
    "    Then, for each patient, the function prints the current patient being normalized and retrieves the paths to the\n",
    "    `raw_bet` directory and all files in that directory with the extension \".nii.gz\". For each file, the function\n",
    "    prints the start of the n4 bias correction process and retrieves the sequence type from the file name.\n",
    "\n",
    "    The function then reads the mask image from the `brain-extraction` directory and casts it to `sitk.sitkUInt8`.\n",
    "\n",
    "    Next, the function reads the image from the current file and performs percentile normalization on the image array.\n",
    "    \"\"\"\n",
    "\n",
    "    perc_norm_failures = [\"01852952\"]\n",
    "\n",
    "    for file in os.listdir(path_to_output):\n",
    "        if \"n4_brainlesion_percentile\" in file:\n",
    "            path_to_preprocessed = f\"{path_to_output}/{file}\"\n",
    "    \n",
    "    if path_to_preprocessed == \"\":\n",
    "        raise MyException(\"Could not find preprocessed data in output folder\")\n",
    "    \n",
    "    # find patient files to normalize\n",
    "    patients = [patient for patient in os.listdir(path_to_preprocessed) if os.path.isdir(os.path.join(path_to_preprocessed, patient))]\n",
    "\n",
    "\n",
    "    # loop through all preprocessed patients\n",
    "    for patient in tqdm(patients):\n",
    "        if patient not in perc_norm_failures:\n",
    "            print(f\"skipping patient {patient}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"currently percentile normalizing patient {patient}\")\n",
    "\n",
    "        path_to_patient = Path(path_to_preprocessed) / Path(patient)\n",
    "        path_to_raw_bet = path_to_patient / \"raw_bet\"\n",
    "\n",
    "        raw_bet_files = [file for file in os.listdir(path_to_raw_bet) if \".nii.gz\" in file]\n",
    "        # loop through all raw_bet files\n",
    "        for file in raw_bet_files:\n",
    "\n",
    "            if file.startswith(\".\"):\n",
    "                continue\n",
    "\n",
    "            path_to_file = Path(path_to_raw_bet) / file\n",
    "\n",
    "            sequence_type = file.split(\"_\")[1]\n",
    "\n",
    "            path_to_mask_image = path_to_patient / \"brain-extraction\" / \"atlas_bet_t1c_mask.nii.gz\"\n",
    "            mask_image = sitk.ReadImage(str(path_to_mask_image), imageIO=\"NiftiImageIO\")\n",
    "            mask_image = sitk.Cast(mask_image, sitk.sitkUInt8)\n",
    "\n",
    "            # n4 bias correct files\n",
    "            image = sitk.ReadImage(str(path_to_file), imageIO=\"NiftiImageIO\")\n",
    "\n",
    "            # percentile normalize\n",
    "            print(f\"starting percentile normalization {file}\")\n",
    "            percentile_normalized_image = percentile_normalize(\n",
    "                sitk.GetArrayFromImage(image),\n",
    "                lower_percentile=0.1,\n",
    "                upper_percentile=99.9,\n",
    "                lower_limit=0,\n",
    "                upper_limit=1,\n",
    "            )\n",
    "\n",
    "            print(f\"successfully percentile normalized {file}\")\n",
    "            print()\n",
    "\n",
    "            # create new n4 corrected directory\n",
    "            path_to_normalized = path_to_patient / \"perc_normalized\"\n",
    "            Path(path_to_normalized).mkdir(exist_ok=True)\n",
    "\n",
    "            # save in new directory\n",
    "            normalized_file_name = f\"{patient}_{sequence_type}_perc_normalized.nii.gz\"\n",
    "            path_to_percentile_corrected_file = path_to_normalized / normalized_file_name\n",
    "            sitk.WriteImage(sitk.GetImageFromArray(percentile_normalized_image), str(path_to_percentile_corrected_file))\n",
    "        \n",
    "        print(f\"finished normalizing patient {patient}\")\n",
    "\n",
    "def percentile_normalize(image: np.ndarray, lower_percentile: float = 0.0, upper_percentile: float = 100.0, lower_limit: float = 0, upper_limit: float = 1):\n",
    "    \"\"\"\n",
    "    Normalizes an image using percentile-based mapping.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): The input image.\n",
    "        lower_percentile (float, optional): The lower percentile for mapping. Defaults to 0.0.\n",
    "        upper_percentile (float, optional): The upper percentile for mapping. Defaults to 100.0.\n",
    "        lower_limit (float, optional): The lower limit for normalized values. Defaults to 0.\n",
    "        upper_limit (float, optional): The upper limit for normalized values. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The percentile-normalized image.\n",
    "\n",
    "    Description:\n",
    "        This function takes an image as input and normalizes it using percentile-based mapping. It calculates the lower\n",
    "        and upper values of the image based on the provided percentiles. The normalized image is then calculated by\n",
    "        subtracting the lower value from each pixel value, dividing the result by the difference between the upper and\n",
    "        lower values, and clipping the values between 0 and 1. Finally, the normalized image is scaled to the specified\n",
    "        lower limit and upper limit.\n",
    "\n",
    "    Example:\n",
    "        >>> image = np.array([10, 20, 30, 40, 50])\n",
    "        >>> percentile_normalize(image, lower_percentile=10, upper_percentile=90)\n",
    "        array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444])\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    lower_value = np.percentile(image, lower_percentile)\n",
    "    upper_value = np.percentile(image, upper_percentile)\n",
    "\n",
    "    normalized_image = np.clip(\n",
    "        (image - lower_value) / (upper_value - lower_value), 0, 1\n",
    "    )\n",
    "    normalized_image = (\n",
    "        normalized_image * (upper_limit - lower_limit) + lower_limit\n",
    "    )\n",
    "\n",
    "    normalized_upper_value = np.percentile(normalized_image, upper_percentile)\n",
    "    normalized_lower_value = np.percentile(normalized_image, lower_percentile)\n",
    "\n",
    "    if normalized_upper_value != 1 or normalized_lower_value != 0:\n",
    "        print(f\"Percentile normalization failed. Upper value: {normalized_upper_value}, lower value: {normalized_lower_value}\")\n",
    "\n",
    "    return normalized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Preprocessing started at 26/07/2024 11:20:23 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently percentile normalizing patient 01852952\n",
      "starting percentile normalization 01852952_t2_bet_raw.nii.gz\n",
      "successfully percentile normalized 01852952_t2_bet_raw.nii.gz\n",
      "\n",
      "starting percentile normalization 01852952_t1c_bet_normalized.nii.gz\n",
      "successfully percentile normalized 01852952_t1c_bet_normalized.nii.gz\n",
      "\n",
      "starting percentile normalization 01852952_t1_bet_raw.nii.gz\n",
      "successfully percentile normalized 01852952_t1_bet_raw.nii.gz\n",
      "\n",
      "starting percentile normalization 01852952_fla_bet_raw.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully percentile normalized 01852952_fla_bet_raw.nii.gz\n",
      "\n",
      "finished normalizing patient 01852952\n",
      "\n",
      "*** Preprocessing finished at 26/07/2024 11:20:24 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Preprocessing started at \" + datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\") + \" ***\")\n",
    "\n",
    "normalize()\n",
    "run_preprocessing()\n",
    "perc_normalize_and_save()\n",
    "\n",
    "print()\n",
    "print(\"*** Preprocessing finished at \" + datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\") + \" ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainles_aurora.inferer import AuroraInferer, AuroraInfererConfig\n",
    "from brainles_aurora.inferer.constants import Device\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_preprocessed = \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24/preprocessed_n4_brainlesion_percentile_20240726-105347\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_segmentation():\n",
    "\n",
    "    list_of_error_patients = []\n",
    "\n",
    "    # We first need to create an instance of the AuroraInfererConfig class,\n",
    "    # which will hold the configuration for the inferer.\n",
    "    # We can then create an instance of the AuroraInferer class, which will be used to perform the inference.\n",
    "\n",
    "    config = AuroraInfererConfig(\n",
    "        tta=True,\n",
    "        # we disable test time augmentations for a quick demo\n",
    "        # should be set to True for better results\n",
    "        sliding_window_batch_size=4,\n",
    "        # The batch size used for the sliding window inference\n",
    "        # decrease if you run out of memory\n",
    "        # warning: too small batches might lead to unstable results\n",
    "\n",
    "        #cuda_devices = \"0\",  # optional, if you have multiple GPUs you can specify which one to use\n",
    "        #device = Device.GPU,  # uncomment this line to force-use CPU\n",
    "    )   \n",
    "    \n",
    "    # create folder at path to output\n",
    "    now = datetime.now()\n",
    "    timeFormatted = now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    path_to_segmented_files = f\"{path_to_output}/segmented_AURORA_n4_{timeFormatted}\"\n",
    "\n",
    "    preprocessed_folder_exists = False\n",
    "\n",
    "    for file in os.listdir(path_to_output):\n",
    "        if \"AURORA_n4\" in file:\n",
    "            path_to_segmented_files = f\"{path_to_output}/{file}\"\n",
    "            preprocessed_folder_exists = True\n",
    "    \n",
    "    if not preprocessed_folder_exists:\n",
    "        os.mkdir(path_to_segmented_files)\n",
    "    \n",
    "    # get list of all patients\n",
    "    patients = [f for f in os.listdir(path_to_preprocessed) if os.path.isdir(os.path.join(path_to_preprocessed, f))]\n",
    "\n",
    "    for patient in tqdm(patients):\n",
    "        \n",
    "        # # ignore already segmented patients\n",
    "        # if patient not in missing_segmentation_patients:\n",
    "        #     continue\n",
    "\n",
    "        print(\"segmenting: \", patient)\n",
    "        print(\"getting files for \", patient)\n",
    "        path_to_preprocessed_patient_files = Path(path_to_preprocessed) / Path(patient) / Path(\"perc_normalized\")\n",
    "        if not path_to_preprocessed_patient_files.exists():\n",
    "            print(f\"WARNING: {path_to_preprocessed_patient_files} doesn't exist\")\n",
    "            list_of_error_patients.append(patient)\n",
    "            continue\n",
    "        path_to_t1 = Path(\"\")\n",
    "        path_to_t1c = Path(\"\")\n",
    "        path_to_t2 = Path(\"\")\n",
    "        path_to_flair = Path(\"\")\n",
    "        files = os.listdir(path_to_preprocessed_patient_files)\n",
    "        for f in files:\n",
    "            \n",
    "            # ignore any . files\n",
    "            if str(f).startswith(\".\"):\n",
    "                continue\n",
    "\n",
    "            if \"_t1_\" in f:\n",
    "                path_to_t1 = path_to_preprocessed_patient_files / f\n",
    "                print(\"Check t1\")\n",
    "            elif \"_t1c_\" in f:\n",
    "                path_to_t1c = path_to_preprocessed_patient_files / f\n",
    "                print(\"Check t1c\")\n",
    "            elif \"_t2_\" in f:\n",
    "                path_to_t2 = path_to_preprocessed_patient_files / f\n",
    "                print(\"Check t2\")\n",
    "            elif \"_fla_\" in f:\n",
    "                path_to_flair = path_to_preprocessed_patient_files / f\n",
    "                print(\"Check flair\")\n",
    "            else:\n",
    "                print(f\"ignoring the following file: {f}\")\n",
    "        \n",
    "        # Instantiate the AuroraInferer\n",
    "        inferer = AuroraInferer()\n",
    "\n",
    "        inferer = AuroraInferer(config=config)\n",
    "\n",
    "        _ = inferer.infer(\n",
    "            t1=str(path_to_t1),\n",
    "            t1c=str(path_to_t1c),\n",
    "            t2=str(path_to_t2),\n",
    "            fla=str(path_to_flair),\n",
    "            segmentation_file=f\"{path_to_segmented_files}/{patient}/{patient}_multi-modal_segmentation.nii.gz\",\n",
    "            # The unbinarized network outputs for the whole tumor channel (edema + enhancing tumor core + necrosis) channel\n",
    "            whole_tumor_unbinarized_floats_file=f\"{path_to_segmented_files}/{patient}/{patient}_whole_tumor_unbinarized_floats.nii.gz\",\n",
    "            # The unbinarized network outputs for the metastasis (tumor core) channel\n",
    "            metastasis_unbinarized_floats_file=f\"{path_to_segmented_files}/{patient}/{patient}_metastasis_unbinarized_floats.nii.gz\",\n",
    "            log_file=f\"{path_to_segmented_files}/{patient}/{patient}_custom_logfile.log\",\n",
    "        )\n",
    "\n",
    "    print(\"ERROR PATIENTS:\")\n",
    "    for error_patient in list_of_error_patients:\n",
    "        print(error_patient)\n",
    "\n",
    "\n",
    "\n",
    "#!!!!! no files found for sub-02036251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Starting segmentation at 26/07/2024 11:25:54 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmenting:  01852952\n",
      "getting files for  01852952\n",
      "Check t1\n",
      "Check flair\n",
      "Check t1c\n",
      "Check t2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO     | inferer         | L115  ] | 2024-07-26T11:25:54+0200: Initialized AuroraInferer with config: AuroraInfererConfig(log_level=20, device=<Device.AUTO: 'auto'>, cuda_devices='0', tta=True, sliding_window_batch_size=1, workers=0, threshold=0.5, sliding_window_overlap=0.5, crop_size=(192, 192, 32), model_selection=<ModelSelection.BEST: 'best'>)\n",
      "[INFO     | inferer         | L148  ] | 2024-07-26T11:25:54+0200: Set torch device: cpu\n",
      "[INFO     | inferer         | L115  ] | 2024-07-26T11:25:54+0200: Initialized AuroraInferer with config: AuroraInfererConfig(log_level=20, device=<Device.AUTO: 'auto'>, cuda_devices='0', tta=True, sliding_window_batch_size=4, workers=0, threshold=0.5, sliding_window_overlap=0.5, crop_size=(192, 192, 32), model_selection=<ModelSelection.BEST: 'best'>)\n",
      "[INFO     | inferer         | L148  ] | 2024-07-26T11:25:54+0200: Set torch device: cpu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────── </span>Thank you for using <span style=\"font-weight: bold\">AURORA</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────── \u001b[0mThank you for using \u001b[1mAURORA\u001b[0m\u001b[92m ────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                         Please support our development by citing the papers listed here:                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                         Please support our development by citing the papers listed here:                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                           <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/BrainLesion/AURORA#citation</span> -- Thank you!                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                           \u001b[4;94mhttps://github.com/BrainLesion/AURORA#citation\u001b[0m -- Thank you!                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO     | inferer         | L191  ] | 2024-07-26T11:25:54+0200: Infer with config: AuroraInfererConfig(log_level=20, device=<Device.AUTO: 'auto'>, cuda_devices='0', tta=True, sliding_window_batch_size=4, workers=0, threshold=0.5, sliding_window_overlap=0.5, crop_size=(192, 192, 32), model_selection=<ModelSelection.BEST: 'best'>) and device: cpu\n",
      "[INFO     | data            | L138  ] | 2024-07-26T11:25:54+0200: Successfully validated input images (received 4). Input mode: DataMode.NIFTI_FILE\n",
      "[INFO     | data            | L160  ] | 2024-07-26T11:25:54+0200: Received files: T1: True, T1C: True, T2: True, FLAIR: True\n",
      "[INFO     | data            | L169  ] | 2024-07-26T11:25:54+0200: Inference mode: InferenceMode.T1_T1C_T2_FLA\n",
      "[INFO     | model           | L58   ] | 2024-07-26T11:25:54+0200: No loaded compatible model found (Switching from None to InferenceMode.T1_T1C_T2_FLA). Loading Model and weights...\n",
      "[INFO     | model           | L63   ] | 2024-07-26T11:25:54+0200: Successfully loaded model.\n",
      "[INFO     | inferer         | L206  ] | 2024-07-26T11:25:54+0200: Setting up Dataloader\n",
      "[INFO     | inferer         | L216  ] | 2024-07-26T11:25:54+0200: Running inference on device := cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (32, 32, 64, 128, 256, 32).\n",
      "before: /Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/brainles_aurora/weights/InferenceMode.T1_T1C_T2_FLA_ModelSelection.BEST.tar\n",
      "after: /Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/brainles_aurora/weights/t1-t1c-t2-fla_best.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO     | model           | L210  ] | 2024-07-26T11:31:23+0200: Applying test time augmentations\n",
      "[INFO     | model           | L214  ] | 2024-07-26T14:10:55+0200: Post-processing data\n",
      "[INFO     | model           | L218  ] | 2024-07-26T14:10:56+0200: Returning post-processed data as Dict of Numpy arrays\n",
      "[INFO     | inferer         | L218  ] | 2024-07-26T14:10:56+0200: Finished inference\n",
      "[INFO     | inferer         | L222  ] | 2024-07-26T14:10:56+0200: Saving post-processed data as NIfTI files\n",
      "[INFO     | data            | L263  ] | 2024-07-26T14:10:56+0200: Saved Output.SEGMENTATION to /Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24/segmented_AURORA_n4_20240726-112554/01852952/01852952_multi-modal_segmentation.nii.gz\n",
      "[INFO     | data            | L263  ] | 2024-07-26T14:10:56+0200: Saved Output.WHOLE_NETWORK to /Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24/segmented_AURORA_n4_20240726-112554/01852952/01852952_whole_tumor_unbinarized_floats.nii.gz\n",
      "[INFO     | data            | L263  ] | 2024-07-26T14:10:56+0200: Saved Output.METASTASIS_NETWORK to /Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/patient_correction_24_07_24/segmented_AURORA_n4_20240726-112554/01852952/01852952_metastasis_unbinarized_floats.nii.gz\n",
      "[INFO     | inferer         | L226  ] | 2024-07-26T14:10:56+0200: ============================ Finished inference run ============================\n",
      "100%|██████████| 1/1 [2:45:02<00:00, 9902.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR PATIENTS:\n",
      "*** Finished segmentation at 26/07/2024 14:10:56 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Starting segmentation at \" + datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\") + \" ***\")\n",
    "run_segmentation()\n",
    "print(\"*** Finished segmentation at \" + datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\") + \" ***\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_mets_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
