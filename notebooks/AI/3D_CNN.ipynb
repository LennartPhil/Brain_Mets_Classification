{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification\")\n",
    "\n",
    "import brain_mets_classification.custom_funcs as funcs\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training\n",
    "To-do:\n",
    "- load nifti files\n",
    "- rotate images by 90 degrees\n",
    "- rescale the values to be between -1 and 1\n",
    "- compress all 4 sequences into one array (while using the different sequences as different \"colors\")\n",
    "- add data augmentation\n",
    "- one hot encode sex\n",
    "- preload images\n",
    "- separate images into train and test set (maybe 90:10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAVE: remove patient sub-01383503 from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_preprocessed_images: Path = Path(\"/Volumes/BrainMets/Rgb_Brain_Mets/brain_mets_classification/derivatives/preprocessed_20240131-135755\")\n",
    "\n",
    "def load_patient(patientID):\n",
    "    \"\"\"loads the images for a specific patient\"\"\"\n",
    "    images = []\n",
    "    # get all four sequences\n",
    "    patient_path = Path(patientID)\n",
    "    image_names = os.listdir(path_to_preprocessed_images / patient_path)\n",
    "    \n",
    "    # load them\n",
    "    for name in image_names:\n",
    "        path_to_image = path_to_preprocessed_images / patient_path / Path(name)\n",
    "        image = nib.load(path_to_image)\n",
    "        data = image.get_fdata()\n",
    "        tensor = tf.convert_to_tensor(data, dtype = float)\n",
    "        images.append(data)\n",
    "    \n",
    "    if len(images) != 4:\n",
    "        print(f\"Warning: either too many or too few images for {patientID} (#{len(images)})\")\n",
    "    \n",
    "    # return four images as array\n",
    "    return images\n",
    "\n",
    "def rotate_90_deg(images):\n",
    "    \"\"\"rotates images by 90 degrees\"\"\"\n",
    "    # rotate images\n",
    "    rotated_images = []\n",
    "    for image in images:\n",
    "        rotated_images.append(ndimage.rotate(image, angle = 90))\n",
    "\n",
    "    # return back\n",
    "    return rotated_images\n",
    "\n",
    "@tf.py_function(Tout=tf.float32)\n",
    "def pad_images(images, target_shape = (155,185,149)): # for further information why this specific values is used please take a look at dataset_analysis.ipynb\n",
    "    \"\"\"adds \\\"zero\\\" padding to the images, the value of a corner of the image gets used to padding\"\"\"\n",
    "    padded_images = []\n",
    "\n",
    "    # get value to use for padding\n",
    "    for image in images:\n",
    "        # gets value of an image corner\n",
    "        min_value = image[:,:,0][0][0]\n",
    "\n",
    "        # Calculate the padding amounts for each dimension\n",
    "        current_shape = image.shape\n",
    "        pad_widths = []\n",
    "\n",
    "        for target_dim, current_dim in zip(target_shape, current_shape):\n",
    "            total_padding = max(0, target_dim - current_dim)\n",
    "            padding_before = total_padding // 2\n",
    "            padding_after = total_padding - padding_before\n",
    "            pad_widths.append((padding_before, padding_after))\n",
    "        \n",
    "        # pad the image\n",
    "        padded_image = tf.pad(tensor = image,\n",
    "               paddings = pad_widths,\n",
    "               mode = \"CONSTANT\",\n",
    "               constant_values = int(min_value))\n",
    "        \n",
    "        padded_images.append(padded_image)\n",
    "\n",
    "    # return images\n",
    "    return padded_images\n",
    "\n",
    "@tf.py_function(Tout=tf.float32)\n",
    "def rescale_images(images):\n",
    "    \"\"\"rescales the values for each image pixel (or voxel) to be between -1 and 1\"\"\"\n",
    "    # rescale images\n",
    "    # return images\n",
    "    pass\n",
    "\n",
    "@tf.py_function(Tout=tf.float32)\n",
    "def merge_images(images):\n",
    "    \"\"\"merge images so that the fourth dimension used for the different sequences\"\"\"\n",
    "    # merge image\n",
    "    # return array\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-09 12:04:26.218129: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: ValueError: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: shape=(155, 185, 149), dtype=float64, numpy=\n",
      "array([[[-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        ...,\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.]],\n",
      "\n",
      "       [[-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        ...,\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.]],\n",
      "\n",
      "       [[-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        ...,\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        ...,\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.]],\n",
      "\n",
      "       [[-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        ...,\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.]],\n",
      "\n",
      "       [[-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        ...,\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.]]])>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 162, in _call\n",
      "    outputs = [\n",
      "              ^\n",
      "\n",
      "  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in <listcomp>\n",
      "    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 130, in _convert\n",
      "    return ops.convert_to_tensor(value, dtype=dtype)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\", line 696, in convert_to_tensor\n",
      "    return tensor_conversion_registry.convert(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 209, in convert\n",
      "    return overload(dtype, name)  #  pylint: disable=not-callable\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\", line 591, in __tf_tensor__\n",
      "    return super().__tf_tensor__(dtype, name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/framework/tensor.py\", line 762, in __tf_tensor__\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: shape=(155, 185, 149), dtype=float64, numpy=\n",
      "array([[[-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        ...,\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.]],\n",
      "\n",
      "       [[-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        ...,\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.]],\n",
      "\n",
      "       [[-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        ...,\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        ...,\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.]],\n",
      "\n",
      "       [[-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        ...,\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.]],\n",
      "\n",
      "       [[-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        ...,\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.],\n",
      "        [-3., -3., -3., ..., -3., -3., -3.]]])>\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__EagerPyFunc_Tin_1_Tout_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: shape=(155, 185, 149), dtype=float64, numpy=\narray([[[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       ...,\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]]])>\nTraceback (most recent call last):\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 162, in _call\n    outputs = [\n              ^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in <listcomp>\n    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 130, in _convert\n    return ops.convert_to_tensor(value, dtype=dtype)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\", line 696, in convert_to_tensor\n    return tensor_conversion_registry.convert(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 209, in convert\n    return overload(dtype, name)  #  pylint: disable=not-callable\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\", line 591, in __tf_tensor__\n    return super().__tf_tensor__(dtype, name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/framework/tensor.py\", line 762, in __tf_tensor__\n    raise ValueError(\n\nValueError: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: shape=(155, 185, 149), dtype=float64, numpy=\narray([[[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       ...,\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]]])>\n\n [Op:EagerPyFunc]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m patient_images \u001b[38;5;241m=\u001b[39m rotate_90_deg(\u001b[43mpad_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_patient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msub-02063373\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(patient_images[\u001b[38;5;241m0\u001b[39m][:,:,\u001b[38;5;241m90\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferno\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(patient_images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py:444\u001b[0m, in \u001b[0;36m_check_args_and_maybe_make_decorator.<locals>.py_function_decorator.<locals>.py_function_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fun)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpy_function_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 444\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscript_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__EagerPyFunc_Tin_1_Tout_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: shape=(155, 185, 149), dtype=float64, numpy=\narray([[[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       ...,\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]]])>\nTraceback (most recent call last):\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 162, in _call\n    outputs = [\n              ^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 163, in <listcomp>\n    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 130, in _convert\n    return ops.convert_to_tensor(value, dtype=dtype)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\", line 696, in convert_to_tensor\n    return tensor_conversion_registry.convert(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 209, in convert\n    return overload(dtype, name)  #  pylint: disable=not-callable\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\", line 591, in __tf_tensor__\n    return super().__tf_tensor__(dtype, name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/.brain_mets_env/lib/python3.11/site-packages/tensorflow/python/framework/tensor.py\", line 762, in __tf_tensor__\n    raise ValueError(\n\nValueError: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: shape=(155, 185, 149), dtype=float64, numpy=\narray([[[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       ...,\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]],\n\n       [[-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        ...,\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.],\n        [-3., -3., -3., ..., -3., -3., -3.]]])>\n\n [Op:EagerPyFunc]"
     ]
    }
   ],
   "source": [
    "patient_images = rotate_90_deg(pad_images(load_patient(\"sub-02063373\")))\n",
    "\n",
    "plt.imshow(patient_images[0][:,:,90], cmap=\"inferno\")\n",
    "\n",
    "print(patient_images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AI architecture\n",
    "To-do:\n",
    "- custom loss (dice loss) or mutli-class loss https://medium.com/@zergtant/use-weighted-loss-function-to-solve-imbalanced-data-classification-problems-749237f38b75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".brain_mets_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
