{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import math\n",
    "\n",
    "from time import strftime\n",
    "\n",
    "#from tensorflow.train import BytesList, FloatList, Int64List\n",
    "#from tensorflow.train import Feature, Features, Example\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification\")\n",
    "\n",
    "import brain_mets_classification.custom_funcs as funcs\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data from TFRecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_tfr = \"/Volumes/BrainMets/Rgb_Brain_Mets/brain_mets_classification/derivatives/TFRecords/patient_data_2classes.tfrecord\"\n",
    "path_to_tfr = \"/Volumes/BrainMets/Rgb_Brain_Mets/brain_mets_classification/derivatives/TFRecords/testing_patient_data_2classes.tfrecord\"\n",
    "\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 4\n",
      "Validation size: 2\n",
      "Testing size: 2\n"
     ]
    }
   ],
   "source": [
    "feature_description = {\n",
    "    \"image\": tf.io.FixedLenFeature([149, 185, 155, 4], tf.float32),\n",
    "    \"sex\": tf.io.FixedLenFeature([2], tf.int64, default_value=[0,0]),\n",
    "    \"age\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"primary\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "}\n",
    "\n",
    "def parse(serialize_patient, augment = False):\n",
    "    example = tf.io.parse_single_example(serialize_patient, feature_description)\n",
    "    # input = [example[\"image\"], example[\"sex\"], example[\"age\"]]\n",
    "    # label = example[\"primary\"]\n",
    "    image = example[\"image\"]\n",
    "    image = tf.reshape(image, [149, 185, 155, 4])\n",
    "\n",
    "    if augment:\n",
    "        pass\n",
    "\n",
    "    return image, example[\"sex\"], example[\"age\"], example[\"primary\"]\n",
    "\n",
    "dataset = tf.data.TFRecordDataset([path_to_tfr], compression_type=\"GZIP\")\n",
    "parsed_dataset = dataset.map(lambda x: parse(x, augment = False))\n",
    "\n",
    "# Display brain slice\n",
    "# numpy_image = parsed_dataset.get_single_element()[0].numpy()\n",
    "# plt.imshow(numpy_image[80,:,:,0], cmap = \"inferno\")\n",
    "\n",
    "# split dataset into train, validation and test\n",
    "\n",
    "#########################################################\n",
    "\n",
    "#Calculate sizes for train, validation, and test sets\n",
    "# total_samples = sum(1 for _ in parsed_dataset)\n",
    "# train_size = int(0.8 * total_samples)\n",
    "# val_size = int(0.1 * total_samples)\n",
    "# test_size = total_samples - train_size - val_size\n",
    "total_samples = sum(1 for _ in parsed_dataset)\n",
    "train_size = int(0.5 * total_samples)\n",
    "val_size = int(0.25 * total_samples)\n",
    "test_size = total_samples - train_size - val_size\n",
    "\n",
    "print(f\"Training size: {train_size}\")\n",
    "print(f\"Validation size: {val_size}\")\n",
    "print(f\"Testing size: {test_size}\")\n",
    "\n",
    "# Shuffle and split dataset\n",
    "dataset = parsed_dataset.shuffle(buffer_size=200)\n",
    "train_dataset = dataset.take(train_size).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "remainder_dataset = dataset.skip(train_size).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "val_dataset = remainder_dataset.take(val_size).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "test_dataset = remainder_dataset.skip(val_size).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "\n",
    "# Example usage of datasets\n",
    "# print(\"Train dataset size:\", sum(1 for _ in train_dataset))\n",
    "# print(\"Validation dataset size:\", sum(1 for _ in val_dataset))\n",
    "# print(\"Test dataset size:\", sum(1 for _ in test_dataset))\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# train_images = tf.Variable(initial_value=tf.zeros((149, 185, 155, 4)), trainable=False)\n",
    "# train_ages = tf.Variable(initial_value=tf.zeros((0,), dtype=tf.float32), trainable=False)\n",
    "# train_sexes = tf.Variable(initial_value=tf.zeros((0,), dtype=tf.int64), trainable=False)\n",
    "# train_primaries = tf.Variable(initial_value=tf.zeros((0,), dtype=tf.int64), trainable=False)\n",
    "\n",
    "def split_dataset(dataset):\n",
    "    images = []\n",
    "    ages = []\n",
    "    sexes = []\n",
    "    primaries = []\n",
    "    for image, sex, age, primary in dataset:\n",
    "        images.append(image)\n",
    "        ages.append(age)\n",
    "        sexes.append(sex)\n",
    "        primaries.append(primary)\n",
    "    return tf.stack(images), tf.stack(sexes), tf.stack(ages), tf.stack(primaries)\n",
    "\n",
    "train_images, train_sex, train_ages, train_primaries = split_dataset(train_dataset)\n",
    "val_images, val_sex, val_ages, val_primaries = split_dataset(val_dataset)\n",
    "test_images, test_sex, test_ages, test_primaries = split_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 149, 185, 155, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write simple CNN and then go from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_callback = \"/Volumes/BrainMets/Rgb_Brain_Mets/brain_mets_classification/derivatives/logs/callback\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Callbacks and building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checkpoint (= safe best model\\)\n",
    "- Early Stopping\\\n",
    "- Tensorboard (not currently working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir(root_logdir=\"/Volumes/BrainMets/Rgb_Brain_Mets/brain_mets_classification/derivatives/logs/tensorboard\"):\n",
    "    return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath = path_to_callback,\n",
    "                                                   monitor = \"val_accuracy\",\n",
    "                                                   mode = \"max\",\n",
    "                                                   save_best_only = True,\n",
    "                                                   save_weights_only = True)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                     restore_best_weights = True)\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir = run_logdir,\n",
    "                                                histogram_freq = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1Cycle Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tf.keras.backend\n",
    "\n",
    "class ExponentialLearningRate(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.sum_of_epoch_losses = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        mean_epoch_loss = logs[\"loss\"]  # the epoch's mean loss so far \n",
    "        new_sum_of_epoch_losses = mean_epoch_loss * (batch + 1)\n",
    "        batch_loss = new_sum_of_epoch_losses - self.sum_of_epoch_losses\n",
    "        self.sum_of_epoch_losses = new_sum_of_epoch_losses\n",
    "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
    "        self.losses.append(batch_loss)\n",
    "        K.set_value(self.model.optimizer.learning_rate,\n",
    "                    self.model.optimizer.learning_rate * self.factor)\n",
    "        \n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=1e-4,\n",
    "                       max_rate=1):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
    "    factor = (max_rate / min_rate) ** (1 / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
    "    K.set_value(model.optimizer.learning_rate, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses, \"b\")\n",
    "    plt.gca().set_xscale('log')\n",
    "    max_loss = losses[0] + min(losses)\n",
    "    plt.hlines(min(losses), min(rates), max(rates), color=\"k\")\n",
    "    plt.axis([min(rates), max(rates), 0, max_loss])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid()\n",
    "\n",
    "# USAGE:\n",
    "# batch_size = 128\n",
    "# rates, losses = find_learning_rate(model, X_train, y_train, epochs=1,\n",
    "#                                    batch_size=batch_size)\n",
    "# plot_lr_vs_loss(rates, losses)\n",
    "\n",
    "# 1CycleScheduler\n",
    "#https://arxiv.org/abs/1803.09820\n",
    "\n",
    "class OneCycleScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_lr=1e-3, start_lr=None,\n",
    "                 last_iterations=None, last_lr=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_lr = max_lr\n",
    "        self.start_lr = start_lr or max_lr / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_lr = last_lr or self.start_lr / 1000\n",
    "        self.iteration = 0\n",
    "\n",
    "    def _interpolate(self, iter1, iter2, lr1, lr2):\n",
    "        return (lr2 - lr1) * (self.iteration - iter1) / (iter2 - iter1) + lr1\n",
    "\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            lr = self._interpolate(0, self.half_iteration, self.start_lr,\n",
    "                                   self.max_lr)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            lr = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                   self.max_lr, self.start_lr)\n",
    "        else:\n",
    "            lr = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                   self.start_lr, self.last_lr)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, lr)\n",
    "\n",
    "# USAGE\n",
    "# n_epochs = 25\n",
    "# onecycle = OneCycleScheduler(math.ceil(len(X_train) / batch_size) * n_epochs,\n",
    "#                              max_lr=0.1)\n",
    "# history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "#                     validation_data=(X_valid, y_valid),\n",
    "#                     callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializers, Optimizers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "intializer = tf.keras.initializers.HeNormal()\n",
    "activation_func = \"mish\"\n",
    "#optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-3) # this is a placeholder, chagne to Nestorev oder AdamW\n",
    "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCDropout\n",
    "# https://arxiv.org/abs/1506.02142\n",
    "\n",
    "class MCDropout(tf.keras.layers.Dropout):\n",
    "    def call(self, inputs, training=False):\n",
    "        return super().call(inputs, training=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNeXt Blocks\n",
    "original ResNeXt paper: https://arxiv.org/abs/1611.05431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new attempt of the ResNeXt architecture for 3d, based on https://github.com/titu1994/Keras-ResNeXt/blob/master/resnext.py\n",
    "\n",
    "kernel_initializer = \"he_normal\"\n",
    "activation_func = \"relu\"\n",
    "\n",
    "def __initial_conv_block(input, weight_decay = 5e-4):\n",
    "    ''' Adds an initial convolution block, with batch normalization and relu activation\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        weight_decay: weight decay factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "\n",
    "    x = tf.keras.layers.Conv3D(filters = 64,\n",
    "                               kernel_size = 3,\n",
    "                               padding = \"same\",\n",
    "                               kernel_initializer = kernel_initializer,\n",
    "                               kernel_regularizer = tf.keras.regularizers.l2(weight_decay))(input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(activation_func)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def __grouped_convolution_block(input, grouped_channels, cardinality, strides, weight_decay = 5e-4):\n",
    "    ''' Adds a grouped convolution block. It is an equivalent block from the paper\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        grouped_channels: grouped number of filters\n",
    "        cardinality: cardinality factor describing the number of groups\n",
    "        strides: performs strided convolution for downscaling if > 1\n",
    "        weight_decay: weight decay term\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "\n",
    "    group_list = []\n",
    "\n",
    "    if cardinality == 1:\n",
    "        # with cardinality 1, it is a standard convolution\n",
    "        x = tf.keras.layers.Conv3D(filters = grouped_channels,\n",
    "                                   kernel_size = 3,\n",
    "                                   padding = \"same\",\n",
    "                                   use_bias = False,\n",
    "                                   strides = (strides, strides, strides),\n",
    "                                   kernel_initializer = kernel_initializer,\n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2(weight_decay))(input)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(activation_func)(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    # cardinality loop\n",
    "    for c in range(cardinality):\n",
    "        x = tf.keras.layers.Lambda(lambda x: x[:, :, :, :, c * grouped_channels : (c + 1) * grouped_channels])(input)\n",
    "\n",
    "        x = tf.keras.layers.Conv3D(filters = grouped_channels,\n",
    "                                   kernel_size = 3,\n",
    "                                   padding = \"same\",\n",
    "                                   use_bias = False,\n",
    "                                   strides = (strides, strides, strides),\n",
    "                                   kernel_initializer = kernel_initializer,\n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2(weight_decay))(x)\n",
    "        \n",
    "        group_list.append(x)\n",
    "    \n",
    "    group_merge = tf.keras.layers.Concatenate(axis=-1)(group_list)\n",
    "    x = tf.keras.layers.BatchNormalization()(group_merge)\n",
    "    x = tf.keras.layers.Activation(activation_func)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# def __bottleneck_block(input, filters = 64, cardinality = 8, strides = 1, weight_decay = 5e-4):\n",
    "    ''' Adds a bottleneck block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        cardinality: cardinality factor described number of\n",
    "            grouped convolutions\n",
    "        strides: performs strided convolution for downsampling if > 1\n",
    "        weight_decay: weight decay factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "\n",
    "    init = input\n",
    "\n",
    "    grouped_channels = int(filters / cardinality)\n",
    "    if init.shape[-1] != 2 * filters:\n",
    "        init = tf.keras.layers.Conv3D(filters = filters * 2,\n",
    "                                        kernel_size = 1,\n",
    "                                        padding = \"same\",\n",
    "                                        strides = strides,\n",
    "                                        use_bias = False,\n",
    "                                        kernel_initializer = kernel_initializer,\n",
    "                                        kernel_regularizer = tf.keras.regularizers.l2(weight_decay))(init)\n",
    "        init = tf.keras.layers.BatchNormalization()(init)\n",
    "\n",
    "    # main path\n",
    "    x = tf.keras.layers.Conv3D(filters = filters,\n",
    "                               kernel_size = 1,\n",
    "                               padding = \"same\",\n",
    "                               strides = strides,\n",
    "                               use_bias = False,\n",
    "                               kernel_initializer = kernel_initializer,\n",
    "                               kernel_regularizer = tf.keras.regularizers.l2(weight_decay))(init)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(activation_func)(x)\n",
    "\n",
    "    x = __grouped_convolution_block(x,\n",
    "                                    grouped_channels = grouped_channels,\n",
    "                                    cardinality = cardinality,\n",
    "                                    strides = strides,\n",
    "                                    weight_decay = weight_decay)\n",
    "    \n",
    "    x = tf.keras.layers.Conv3D(filters = filters * 2,\n",
    "                               kernel_size = 1,\n",
    "                               padding = \"same\",\n",
    "                               use_bias = False,\n",
    "                               kernel_initializer = kernel_initializer,\n",
    "                               kernel_regularizer = tf.keras.regularizers.l2(weight_decay))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    print(init.shape)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = tf.keras.layers.add([init, x])\n",
    "    x = tf.keras.layers.Activation(activation_func)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def __bottleneck_block(input, filters, cardinality, strides, weight_decay):\n",
    "    init = input\n",
    "\n",
    "    # Determine if the shortcut path needs a convolution for matching dimensions\n",
    "    needs_conv = strides > 1 or input.shape[-1] != filters * 2\n",
    "\n",
    "    grouped_channels = filters // cardinality\n",
    "    \n",
    "    if needs_conv:\n",
    "        # Apply convolution to shortcut path to match the main path's dimensions\n",
    "        init = tf.keras.layers.Conv3D(filters * 2, 1, strides=strides, padding=\"same\", use_bias=False,\n",
    "                                      kernel_initializer=kernel_initializer,\n",
    "                                      kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(init)\n",
    "        init = tf.keras.layers.BatchNormalization()(init)\n",
    "\n",
    "    # Main path\n",
    "    x = tf.keras.layers.Conv3D(filters, 1, padding=\"same\", use_bias=False,\n",
    "                               kernel_initializer=kernel_initializer,\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(activation_func)(x)\n",
    "\n",
    "    x = __grouped_convolution_block(x, grouped_channels, cardinality, strides, weight_decay)\n",
    "\n",
    "    x = tf.keras.layers.Conv3D(filters * 2, 1, padding=\"same\", use_bias=False,\n",
    "                               kernel_initializer=kernel_initializer,\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    # Addition - ensuring init and x have compatible shapes\n",
    "    x = tf.keras.layers.Add()([init, x])\n",
    "    x = tf.keras.layers.Activation(activation_func)(x)\n",
    "\n",
    "    return x\n",
    " \n",
    "\n",
    "def create_res_next(nb_classes, img_input, depth = 29, cardinality = 8, width = 4,\n",
    "                      weight_decay = 5e-4, pooling = None):\n",
    "    ''' Creates a ResNeXt model with specified parameters\n",
    "    Args:\n",
    "        nb_classes: Number of output classes\n",
    "        img_input: Input tensor or layer\n",
    "        include_top: Flag to include the last dense layer\n",
    "        depth: Depth of the network. Can be an positive integer or a list\n",
    "               Compute N = (n - 2) / 9.\n",
    "               For a depth of 56, n = 56, N = (56 - 2) / 9 = 6\n",
    "               For a depth of 101, n = 101, N = (101 - 2) / 9 = 11\n",
    "        cardinality: the size of the set of transformations.\n",
    "               Increasing cardinality improves classification accuracy,\n",
    "        width: Width of the network.\n",
    "        weight_decay: weight_decay (l2 norm)\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "    Returns: a Keras Model\n",
    "    '''\n",
    "\n",
    "    if type(depth) is list or type(depth) is tuple:\n",
    "        # if a list is provided, defer to user how many blocks are present\n",
    "        N = list(depth)\n",
    "    else:\n",
    "        # otherwise, default to 3 blocks each of default number of group convolution blocks\n",
    "        N = [(depth - 2) // 9 for _ in range(3)]\n",
    "    \n",
    "    filters = cardinality * width\n",
    "    filters_list = []\n",
    "\n",
    "    for _ in range(len(N)):\n",
    "        filters_list.append(filters)\n",
    "        filters *= 2\n",
    "    \n",
    "    x = __initial_conv_block(img_input, weight_decay)\n",
    "\n",
    "    # block 1 (no pooling)\n",
    "    for _ in range(N[0]):\n",
    "        x = __bottleneck_block(x, filters_list[0], cardinality, strides=1, weight_decay=weight_decay)\n",
    "    \n",
    "    N = N[1:] # remove the first block from block definition list\n",
    "    filters_list = filters_list[1:] # remove the first filter from the filter list\n",
    "\n",
    "    # block 2 to N\n",
    "    for block_idx, n_i in enumerate(N):\n",
    "        for i in range(n_i):\n",
    "            if i == 0:\n",
    "                x = __bottleneck_block(x, filters_list[block_idx], cardinality, strides = 2, weight_decay=weight_decay)\n",
    "            else:\n",
    "                x = __bottleneck_block(x, filters_list[block_idx], cardinality, strides = 1, weight_decay=weight_decay)\n",
    "        \n",
    "    if pooling == \"avg\":\n",
    "        x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "    elif pooling == \"max\":\n",
    "        x = tf.keras.layers.GlobalMaxPooling3D()(x)\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'random_brightness_1' (type RandomBrightness).\n\nExpected the input image to be rank 3 or 4. Got inputs.shape = (None, 149, 185, 155, 4)\n\nCall arguments received by layer 'random_brightness_1' (type RandomBrightness):\n  • inputs=tf.Tensor(shape=(None, 149, 185, 155, 4), dtype=float32)\n  • training=True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m age_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39mtrain_ages\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m      6\u001b[0m sex_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39mtrain_sex\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m----> 8\u001b[0m augmented_images \u001b[38;5;241m=\u001b[39m \u001b[43mdata_augmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m output_tensor \u001b[38;5;241m=\u001b[39m create_res_next(nb_classes \u001b[38;5;241m=\u001b[39m nb_classes,\n\u001b[1;32m     11\u001b[0m                                   img_input \u001b[38;5;241m=\u001b[39m augmented_images,\n\u001b[1;32m     12\u001b[0m                                   depth \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m                                   weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5e-4\u001b[39m,\n\u001b[1;32m     16\u001b[0m                                   pooling \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m flattened_images \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten()(output_tensor)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/layers/preprocessing/image_preprocessing.py:1483\u001b[0m, in \u001b[0;36mRandomBrightness._brightness_adjust\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m   1481\u001b[0m     rgb_delta_shape \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mshape(images)[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1482\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1483\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected the input image to be rank 3 or 4. Got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1485\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs.shape = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimages\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1486\u001b[0m     )\n\u001b[1;32m   1487\u001b[0m rgb_delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_generator\u001b[38;5;241m.\u001b[39mrandom_uniform(\n\u001b[1;32m   1488\u001b[0m     shape\u001b[38;5;241m=\u001b[39mrgb_delta_shape,\n\u001b[1;32m   1489\u001b[0m     minval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_factor[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1490\u001b[0m     maxval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_factor[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   1491\u001b[0m )\n\u001b[1;32m   1492\u001b[0m rgb_delta \u001b[38;5;241m=\u001b[39m rgb_delta \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value_range[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value_range[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'random_brightness_1' (type RandomBrightness).\n\nExpected the input image to be rank 3 or 4. Got inputs.shape = (None, 149, 185, 155, 4)\n\nCall arguments received by layer 'random_brightness_1' (type RandomBrightness):\n  • inputs=tf.Tensor(shape=(None, 149, 185, 155, 4), dtype=float32)\n  • training=True"
     ]
    }
   ],
   "source": [
    "input_shape = (149,185,155,4)\n",
    "nb_classes = 2\n",
    "\n",
    "img_input = tf.keras.layers.Input(shape=input_shape)\n",
    "age_input = tf.keras.layers.Input(shape=train_ages.shape[1:])\n",
    "sex_input = tf.keras.layers.Input(shape=train_sex.shape[1:])\n",
    "\n",
    "augmented_images = data_augmentation(img_input)\n",
    "\n",
    "output_tensor = create_res_next(nb_classes = nb_classes,\n",
    "                                  img_input = augmented_images,\n",
    "                                  depth = [3,4,6,3],\n",
    "                                  cardinality = 32,\n",
    "                                  width = 4,\n",
    "                                  weight_decay = 5e-4,\n",
    "                                  pooling = \"avg\")\n",
    "\n",
    "flattened_images = tf.keras.layers.Flatten()(output_tensor)\n",
    "flattened_sex_input = tf.keras.layers.Flatten()(sex_input)\n",
    "# EDIT START\n",
    "age_input_reshaped = tf.keras.layers.Reshape((1,))(age_input)  # Reshape age_input to have 2 dimensions\n",
    "# EDIT END\n",
    "concatenated_inputs = tf.keras.layers.Concatenate()([flattened_images, age_input_reshaped, flattened_sex_input])\n",
    "\n",
    "x = MCDropout(0.4)(concatenated_inputs)\n",
    "x = tf.keras.layers.Dense(200, activation=\"mish\")(x)\n",
    "x = MCDropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(200, activation=\"mish\")(x)\n",
    "x = MCDropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(200, activation=\"mish\")(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[img_input, age_input, sex_input], outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input = [train_images, train_ages, train_sex]\n",
    "\n",
    "rates, losses = find_learning_rate(model= model,\n",
    "                                   X = training_input,\n",
    "                                   y = train_primaries,\n",
    "                                   epochs=1,\n",
    "                                   batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(training_input, train_primaries,\n",
    "                    epochs=20, batch_size=1,\n",
    "                    validation_data=(val_images, val_primaries),\n",
    "                    callbacks = [checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation\n",
    "consider adding Random Brightness and Random Contrast later, as that might create problems with the different sequences\\\n",
    "Elastic Deformation: https://github.com/gvtulder/elasticdeform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular Tensorflow Data Augmentation\n",
    "Unfortunately this won't work on our 5D tensors :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(mode = \"horizontal\"),\n",
    "    tf.keras.layers.RandomBrightness(factor = (-0.2, 0.5), value_range=(0, 1)), # consider adding later\n",
    "    tf.keras.layers.RandomContrast(0.5), # consider adding later\n",
    "    tf.keras.layers.RandomRotation(factor = (-0.07, 0.07), fill_mode = \"nearest\"),\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor = 0.025,\n",
    "        width_factor = 0.05,\n",
    "        fill_mode = \"nearest\"\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voumentations 3D\n",
    "Github: https://github.com/ZFTurbo/volumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from volumentations import *\n",
    "\n",
    "def get_augmentation():\n",
    "    return Compose([Rotate((-15, 15), (0, 0), (0, 0), p=0.5),\n",
    "                    Flip(0, p=0.5),\n",
    "                    Flip(1, p=0.5),\n",
    "                    Flip(2, p=0.5),\n",
    "                    ElasticTransform((0, 0.25), interpolation=2, p=0.1),\n",
    "                    GaussianNoise(var_limit=(0, 5), p=0.2),\n",
    "                    RandomGamma(gamma_limit=(0.5, 1.5), p=0.2)], p=1.0)\n",
    "\n",
    "def augmentor(img):\n",
    "    aug = get_augmentation()\n",
    "    data = {'image': img}\n",
    "    aug_data = aug(**data)\n",
    "    img = aug_data['image']\n",
    "    return np.ndarray.astype(img , np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 149, 185, 155,    0         \n",
      "                             4)]                                 \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 149, 185, 155, 4   16        \n",
      " chNormalization)            )                                   \n",
      "                                                                 \n",
      " conv3d_4 (Conv3D)           (None, 72, 90, 75, 64)    87872     \n",
      "                                                                 \n",
      " max_pooling3d_4 (MaxPoolin  (None, 36, 45, 37, 64)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_5 (Conv3D)           (None, 15, 20, 16, 64)    1404992   \n",
      "                                                                 \n",
      " max_pooling3d_5 (MaxPoolin  (None, 7, 10, 8, 64)      0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 7, 10, 8, 100)     6500      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 7, 10, 8, 100)     0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 7, 10, 8, 100)     10100     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 7, 10, 8, 100)     0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 7, 10, 8, 2)       202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1509682 (5.76 MB)\n",
      "Trainable params: 1509674 (5.76 MB)\n",
      "Non-trainable params: 8 (32.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loss: categorical crossentropy\n",
    "# set class weight for underrepresented classes\n",
    "\n",
    "batch_norm_layer = tf.keras.layers.BatchNormalization()\n",
    "conv_1_layer = tf.keras.layers.Conv3D(filters = 64, kernel_size = 7, input_shape = [149, 185, 155, 4], strides=(2,2,2), activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "max_pool_1_layer = tf.keras.layers.MaxPooling3D(pool_size = (2,2,2))\n",
    "conv_2_layer = tf.keras.layers.Conv3D(filters = 64, kernel_size = 7, strides=(2,2,2), activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "max_pool_2_layer = tf.keras.layers.MaxPooling3D(pool_size = (2,2,2))\n",
    "dense_1_layer = tf.keras.layers.Dense(100, activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "dropout_1_layer = tf.keras.layers.Dropout(0.5)\n",
    "dense_2_layer = tf.keras.layers.Dense(100, activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "dropout_2_layer = tf.keras.layers.Dropout(0.5)\n",
    "output_layer = tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    "\n",
    "# Define inputs\n",
    "input_image = tf.keras.layers.Input(shape=train_images.shape[1:])\n",
    "\n",
    "# concatenate input sex and input age\n",
    "\n",
    "batch_norm = batch_norm_layer(input_image)\n",
    "conv_1 = conv_1_layer(batch_norm)\n",
    "max_pool_1 = max_pool_1_layer(conv_1)\n",
    "conv_2 = conv_2_layer(max_pool_1)\n",
    "max_pool_2 = max_pool_2_layer(conv_2)\n",
    "dense_1 = dense_1_layer(max_pool_2)\n",
    "dropout_1 = dropout_1_layer(dense_1)\n",
    "dense_2 = dense_2_layer(dropout_1)\n",
    "dropout_2 = dropout_2_layer(dense_2)\n",
    "output = output_layer(dropout_2)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs = input_image, outputs = [output])\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics = [\"RootMeanSquaredError\", \"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    history = model.fit(train_images, train_primaries, epochs=20, batch_size=1, validation_data=(val_images, val_primaries), callbacks = [checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relatively complex model, image only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-use:\n",
    "# image augmentation\n",
    "# local response normalization\n",
    "# 1-cycle scheduling\n",
    "# Resnet Blöcke\n",
    "# normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have placeholders for sex_input and age_input\n",
    "sex_input = tf.keras.Input(shape=(2,))\n",
    "age_input = tf.keras.Input(shape=(1,))\n",
    "\n",
    "# Concatenate the inputs\n",
    "concatenated_inputs = tf.keras.layers.concatenate([sex_input, age_input])\n",
    "\n",
    "# Continue building your model using the concatenated inputs\n",
    "# For example:\n",
    "# output_layer = SomeLayer()(concatenated_inputs)\n",
    "# model = tf.keras.Model(inputs=[sex_input, age_input], outputs=output_layer)\n",
    "\n",
    "# Example of using the concatenated inputs in a model\n",
    "output_layer = tf.keras.layers.Dense(64, activation='relu')(concatenated_inputs)\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(output_layer)\n",
    "\n",
    "# Define the model with concatenated inputs\n",
    "model = tf.keras.Model(inputs=[sex_input, age_input], outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Example usage:\n",
    "# model.fit([sex_data, age_data], target_labels, epochs=num_epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".brain_mets_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
