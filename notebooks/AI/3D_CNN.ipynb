{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from pathlib import Path\n",
    "\n",
    "from time import strftime\n",
    "\n",
    "#from tensorflow.train import BytesList, FloatList, Int64List\n",
    "#from tensorflow.train import Feature, Features, Example\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification\")\n",
    "\n",
    "import brain_mets_classification.custom_funcs as funcs\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data from TFRecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tfr = \"/Volumes/BrainMets/Rgb_Brain_Mets/brain_mets_classification/derivatives/TFRecords/patient_data_2classes.tfrecord\"\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 392\n",
      "Validation size: 49\n",
      "Testing size: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 17:48:49.988555: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:5: Filling up shuffle buffer (this may take a while): 56 of 200\n",
      "2024-02-13 17:49:10.066092: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:5: Filling up shuffle buffer (this may take a while): 164 of 200\n",
      "2024-02-13 17:49:16.996635: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] Shuffle buffer filled.\n",
      "2024-02-13 17:50:39.887880: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:5: Filling up shuffle buffer (this may take a while): 53 of 200\n",
      "2024-02-13 17:50:59.871640: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:5: Filling up shuffle buffer (this may take a while): 161 of 200\n",
      "2024-02-13 17:51:07.422488: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] Shuffle buffer filled.\n",
      "2024-02-13 17:52:12.913552: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:5: Filling up shuffle buffer (this may take a while): 55 of 200\n",
      "2024-02-13 17:52:23.026392: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:5: Filling up shuffle buffer (this may take a while): 111 of 200\n",
      "2024-02-13 17:52:33.060524: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:5: Filling up shuffle buffer (this may take a while): 164 of 200\n",
      "2024-02-13 17:52:39.932639: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] Shuffle buffer filled.\n"
     ]
    }
   ],
   "source": [
    "feature_description = {\n",
    "    \"image\": tf.io.FixedLenFeature([149, 185, 155, 4], tf.float32),\n",
    "    \"sex\": tf.io.FixedLenFeature([2], tf.int64, default_value=[0,0]),\n",
    "    \"age\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"primary\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "}\n",
    "\n",
    "def parse(serialize_patient):\n",
    "    example = tf.io.parse_single_example(serialize_patient, feature_description)\n",
    "    # input = [example[\"image\"], example[\"sex\"], example[\"age\"]]\n",
    "    # label = example[\"primary\"]\n",
    "    image = example[\"image\"]\n",
    "    image = tf.reshape(image, [149, 185, 155, 4])\n",
    "    return image, example[\"sex\"], example[\"age\"], example[\"primary\"]\n",
    "\n",
    "dataset = tf.data.TFRecordDataset([path_to_tfr], compression_type=\"GZIP\")\n",
    "parsed_dataset = dataset.map(parse)\n",
    "\n",
    "# Display brain slice\n",
    "# numpy_image = parsed_dataset.get_single_element()[0].numpy()\n",
    "# plt.imshow(numpy_image[80,:,:,0], cmap = \"inferno\")\n",
    "\n",
    "# split dataset into train, validation and test\n",
    "\n",
    "#########################################################\n",
    "\n",
    "#Calculate sizes for train, validation, and test sets\n",
    "total_samples = sum(1 for _ in parsed_dataset)\n",
    "train_size = int(0.8 * total_samples)\n",
    "val_size = int(0.1 * total_samples)\n",
    "test_size = total_samples - train_size - val_size\n",
    "\n",
    "print(f\"Training size: {train_size}\")\n",
    "print(f\"Validation size: {val_size}\")\n",
    "print(f\"Testing size: {test_size}\")\n",
    "\n",
    "# Shuffle and split dataset\n",
    "dataset = parsed_dataset.shuffle(buffer_size=200)\n",
    "train_dataset = dataset.take(train_size).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "remainder_dataset = dataset.skip(train_size).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "val_dataset = remainder_dataset.take(val_size).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "test_dataset = remainder_dataset.skip(val_size).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "\n",
    "# Example usage of datasets\n",
    "# print(\"Train dataset size:\", sum(1 for _ in train_dataset))\n",
    "# print(\"Validation dataset size:\", sum(1 for _ in val_dataset))\n",
    "# print(\"Test dataset size:\", sum(1 for _ in test_dataset))\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# train_images = tf.Variable(initial_value=tf.zeros((149, 185, 155, 4)), trainable=False)\n",
    "# train_ages = tf.Variable(initial_value=tf.zeros((0,), dtype=tf.float32), trainable=False)\n",
    "# train_sexes = tf.Variable(initial_value=tf.zeros((0,), dtype=tf.int64), trainable=False)\n",
    "# train_primaries = tf.Variable(initial_value=tf.zeros((0,), dtype=tf.int64), trainable=False)\n",
    "\n",
    "def split_dataset(dataset):\n",
    "    images = []\n",
    "    ages = []\n",
    "    sexes = []\n",
    "    primaries = []\n",
    "    for image, sex, age, primary in dataset:\n",
    "        images.append(image)\n",
    "        ages.append(age)\n",
    "        sexes.append(sex)\n",
    "        primaries.append(primary)\n",
    "    return tf.stack(images), tf.stack(sexes), tf.stack(ages), tf.stack(primaries)\n",
    "\n",
    "train_images, train_sex, train_ages, train_primaries = split_dataset(train_dataset)\n",
    "val_images, val_sex, val_ages, val_primaries = split_dataset(val_dataset)\n",
    "test_images, test_sex, test_ages, test_primaries = split_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 149, 185, 155, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write simple CNN and then go from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "intializer = tf.keras.initializers.HeNormal()\n",
    "activation_func = \"mish\"\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-3) # this is a placeholder, chnage to Nestorev oder AdamW\n",
    "\n",
    "def get_run_logdir(root_logdir=\"/Volumes/BrainMets/Rgb_Brain_Mets/brain_mets_classification/derivatives/logs\"):\n",
    "    return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. \n",
      "\u001b[1;31mBitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. \n",
      "\u001b[1;31mKlicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. \n",
      "\u001b[1;31mWeitere Informationen finden Sie unter Jupyter <a href='command:jupyter.viewOutput'>Protokoll</a>."
     ]
    }
   ],
   "source": [
    "# loss: categorical crossentropy\n",
    "# set class weight for underrepresented classes\n",
    "\n",
    "batch_norm_layer = tf.keras.layers.BatchNormalization()\n",
    "conv_1_layer = tf.keras.layers.Conv3D(filters = 64, kernel_size = 7, input_shape = [149, 185, 155, 4], strides=(2,2,2), activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "max_pool_1_layer = tf.keras.layers.MaxPooling3D(pool_size = (2,2,2))\n",
    "conv_2_layer = tf.keras.layers.Conv3D(filters = 64, kernel_size = 7, strides=(2,2,2), activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "max_pool_2_layer = tf.keras.layers.MaxPooling3D(pool_size = (2,2,2))\n",
    "dense_1_layer = tf.keras.layers.Dense(100, activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "dropout_1_layer = tf.keras.layers.Dropout(0.5)\n",
    "dense_2_layer = tf.keras.layers.Dense(100, activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "dropout_2_layer = tf.keras.layers.Dropout(0.5)\n",
    "output_layer = tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    "\n",
    "# Define inputs\n",
    "input_image = tf.keras.layers.Input(shape=train_images.shape[1:])\n",
    "\n",
    "# concatenate input sex and input age\n",
    "\n",
    "batch_norm = batch_norm_layer(input_image)\n",
    "conv_1 = conv_1_layer(batch_norm)\n",
    "max_pool_1 = max_pool_1_layer(conv_1)\n",
    "conv_2 = conv_2_layer(max_pool_1)\n",
    "max_pool_2 = max_pool_2_layer(conv_2)\n",
    "dense_1 = dense_1_layer(max_pool_2)\n",
    "dropout_1 = dropout_1_layer(dense_1)\n",
    "dense_2 = dense_2_layer(dropout_1)\n",
    "dropout_2 = dropout_2_layer(dense_2)\n",
    "output = output_layer(dropout_2)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs = input_image, outputs = [output])\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics = [\"RootMeanSquaredError\"])\n",
    "\n",
    "# tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(train_images, train_primaries, epochs=20, batch_size=30, validation_data=(val_images, val_primaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have placeholders for sex_input and age_input\n",
    "sex_input = tf.keras.Input(shape=(2,))\n",
    "age_input = tf.keras.Input(shape=(1,))\n",
    "\n",
    "# Concatenate the inputs\n",
    "concatenated_inputs = tf.keras.layers.concatenate([sex_input, age_input])\n",
    "\n",
    "# Continue building your model using the concatenated inputs\n",
    "# For example:\n",
    "# output_layer = SomeLayer()(concatenated_inputs)\n",
    "# model = tf.keras.Model(inputs=[sex_input, age_input], outputs=output_layer)\n",
    "\n",
    "# Example of using the concatenated inputs in a model\n",
    "output_layer = tf.keras.layers.Dense(64, activation='relu')(concatenated_inputs)\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(output_layer)\n",
    "\n",
    "# Define the model with concatenated inputs\n",
    "model = tf.keras.Model(inputs=[sex_input, age_input], outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Example usage:\n",
    "# model.fit([sex_data, age_data], target_labels, epochs=num_epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".brain_mets_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
