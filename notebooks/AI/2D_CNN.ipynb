{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D CNN training\n",
    "This notebook works as a proof of concept version for the actual script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "from functools import partial\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tfrs = \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/regensburg_slices_tfrecords/all_pats_single_gray\"\n",
    "#path_to_tfrs = \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/regensburg_slices_tfrecords/all_pats_single_rgb\"\n",
    "path_to_logs = \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/regensburg_slices_tfrecords/test_logs\"\n",
    "\n",
    "training_codename = \"2D_pretrained_0000\"\n",
    "\n",
    "num_classes = 4\n",
    "sequence_to_train_on = \"t1c\"\n",
    "\n",
    "time = strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "class_directory = f\"{training_codename}_{num_classes}_classes_{time}\"\n",
    "\n",
    "path_to_callbacks = Path(path_to_logs) / Path(class_directory)\n",
    "os.makedirs(path_to_callbacks, exist_ok=True)\n",
    "\n",
    "input_shape = (240, 240, 4)\n",
    "\n",
    "\n",
    "\n",
    "## train / val / test split\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "activation_func = \"mish\"\n",
    "learning_rate = 0.001\n",
    "\n",
    "early_stopping_patience = 150\n",
    "shuffle_buffer_size = 20\n",
    "repeat_count = 1\n",
    "\n",
    "image_size = 224\n",
    "batch_size = 16\n",
    "EPOCHS = 30\n",
    "\n",
    "len_train = 0\n",
    "len_val = 0\n",
    "len_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_paths():\n",
    "    patients = [f for f in os.listdir(path_to_tfrs) if os.path.isdir(os.path.join(path_to_tfrs, f))]\n",
    "\n",
    "    patient_paths = [str(path_to_tfrs) + \"/\" + patient for patient in patients]\n",
    "\n",
    "    print(f\"total patients: {len(patient_paths)}\")\n",
    "\n",
    "    for path in patient_paths:\n",
    "        patient_not_empty = False\n",
    "        patient_files = os.listdir(path)\n",
    "        for file in patient_files:\n",
    "            if file.endswith(\".tfrecord\"):\n",
    "                patient_not_empty = True\n",
    "        \n",
    "        if patient_not_empty == False:\n",
    "            patient_paths.remove(path)\n",
    "\n",
    "    return patient_paths\n",
    "\n",
    "def split_patients(patient_paths, fraction_to_use = 1):\n",
    "\n",
    "    random.shuffle(patient_paths)\n",
    "\n",
    "    patient_paths = patient_paths[:int(len(patient_paths) * fraction_to_use)]\n",
    "\n",
    "    if fraction_to_use != 1:\n",
    "        print(f\"actual tfrs length: {len(patient_paths)}\")\n",
    "\n",
    "    train_size = int(len(patient_paths) * train_ratio)\n",
    "    val_size = int(len(patient_paths) * val_ratio)\n",
    "\n",
    "    train_patients_paths = patient_paths[:train_size]\n",
    "    val_patients_paths = patient_paths[train_size:train_size + val_size]\n",
    "    test_patients_paths = patient_paths[train_size + val_size:]\n",
    "\n",
    "    print(f\"train: {len(train_patients_paths)} | val: {len(val_patients_paths)} | test: {len(test_patients_paths)}\")\n",
    "\n",
    "    # save train / val / test patients to txt file\n",
    "    # hf.save_paths_to_txt(train_patients_paths, \"train\", path_to_callbacks)\n",
    "    # hf.save_paths_to_txt(val_patients_paths, \"val\", path_to_callbacks)\n",
    "    # hf.save_paths_to_txt(test_patients_paths, \"test\", path_to_callbacks)\n",
    "\n",
    "    sum = len(train_patients_paths) + len(val_patients_paths) + len(test_patients_paths)\n",
    "    if sum != len(patient_paths):\n",
    "        print(\"WARNING: error occured in train / val / test split!\")\n",
    "\n",
    "    return train_patients_paths, val_patients_paths, test_patients_paths\n",
    "\n",
    "def get_tfr_paths_for_patients(patient_paths):\n",
    "\n",
    "    tfr_paths = []\n",
    "\n",
    "    for patient in patient_paths:\n",
    "        tfr_paths.extend(glob.glob(patient + \"/*.tfrecord\"))\n",
    "    \n",
    "    for path in tfr_paths:\n",
    "        verify_tfrecord(path)\n",
    "\n",
    "    #print(f\"total tfrs: {len(tfr_paths)}\")\n",
    "\n",
    "    return tfr_paths\n",
    "\n",
    "def read_data(train_paths, val_paths, test_paths = None, rgb = False):\n",
    "\n",
    "    train_data = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "    val_data = tf.data.Dataset.from_tensor_slices(val_paths)\n",
    "\n",
    "    train_data = train_data.interleave(\n",
    "        lambda x: tf.data.TFRecordDataset([x], compression_type=\"GZIP\"),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "        deterministic=False\n",
    "    )\n",
    "    val_data = val_data.interleave(\n",
    "        lambda x: tf.data.TFRecordDataset([x], compression_type=\"GZIP\"),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "        deterministic=False\n",
    "    )\n",
    "\n",
    "    train_data = train_data.map(partial(parse_record, image_only = False, labeled = True, num_classes = num_classes, rgb = rgb), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_data = val_data.map(partial(parse_record, image_only = False, labeled = True, num_classes = num_classes, rgb = rgb), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    train_data = train_data.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    val_data = val_data.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    train_data = train_data.repeat(count = repeat_count)\n",
    "    val_data = val_data.repeat(count = repeat_count)\n",
    "\n",
    "    train_data = train_data.batch(batch_size)\n",
    "    val_data = val_data.batch(batch_size)\n",
    "\n",
    "    train_data = train_data.prefetch(buffer_size=1)\n",
    "    val_data = val_data.prefetch(buffer_size=1)\n",
    "\n",
    "    if test_paths is not None:\n",
    "        test_data = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "        test_data = test_data.interleave(\n",
    "            lambda x: tf.data.TFRecordDataset([x], compression_type=\"GZIP\"),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE,\n",
    "            deterministic=False\n",
    "        )\n",
    "        test_data = test_data.map(partial(parse_record, image_only = False, labeled = True, num_classes = num_classes, rgb = rgb), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        test_data = test_data.batch(batch_size)\n",
    "        test_data = test_data.prefetch(buffer_size=1)\n",
    "\n",
    "        return train_data, val_data, test_data\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "def parse_record(record, image_only = False, labeled = False, num_classes = 2, rgb = False, sequence = \"t1c\"):\n",
    "\n",
    "    image_shape = []\n",
    "\n",
    "    if rgb: # rgb images need three channels\n",
    "        image_shape = [240, 240, 3, 4]\n",
    "    else: # gray scale images don't\n",
    "        image_shape = [240, 240, 4]\n",
    "\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature(image_shape, tf.float32),\n",
    "        \"sex\": tf.io.FixedLenFeature([], tf.int64, default_value=[0]),\n",
    "        \"age\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "        \"primary\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    }\n",
    "\n",
    "    example = tf.io.parse_single_example(record, feature_description)\n",
    "    image = example[\"image\"]\n",
    "    image = tf.reshape(image, image_shape)\n",
    "\n",
    "    # primary should have a value between 0 and 5\n",
    "    # depending on num classes return different values\n",
    "    # if num_classes = 2, return 1 if primary is 1, else 0\n",
    "    # if num_classes = 3, return primaries 1 and 2, else 0\n",
    "    # if num_classes = 4, return primaries 1, 2 and 3, else 0\n",
    "    # if num_classes = 5, return primaries 1, 2, 3 and 4, else 0\n",
    "    # if num_classes = 6, return primaries 1, 2, 3, 4 and 5, else 0\n",
    "\n",
    "    primary_to_return = tf.constant(0, dtype=tf.int64)\n",
    "\n",
    "    if num_classes == 2:\n",
    "        if example[\"primary\"] == tf.constant(1, dtype=tf.int64):\n",
    "            primary_to_return = example[\"primary\"]\n",
    "        else:\n",
    "            primary_to_return = tf.constant(0, dtype=tf.int64)\n",
    "    elif num_classes == 3:\n",
    "        if example[\"primary\"] == tf.constant(1, dtype=tf.int64) or example[\"primary\"] == tf.constant(2, dtype=tf.int64):\n",
    "            primary_to_return = example[\"primary\"]\n",
    "        else:\n",
    "            primary_to_return = tf.constant(0, dtype=tf.int64)\n",
    "    elif num_classes == 4:\n",
    "        if example[\"primary\"] == tf.constant(1, dtype=tf.int64) or example[\"primary\"] == tf.constant(2, dtype=tf.int64) or example[\"primary\"] == tf.constant(3, dtype=tf.int64):\n",
    "            primary_to_return = example[\"primary\"]\n",
    "        else:\n",
    "            primary_to_return = tf.constant(0, dtype=tf.int64)\n",
    "    elif num_classes == 5:\n",
    "        if example[\"primary\"] == tf.constant(1, dtype=tf.int64) or example[\"primary\"] == tf.constant(2, dtype=tf.int64) or example[\"primary\"] == tf.constant(3, dtype=tf.int64) or example[\"primary\"] == tf.constant(4, dtype=tf.int64):\n",
    "            primary_to_return = example[\"primary\"]\n",
    "        else:\n",
    "            primary_to_return = tf.constant(0, dtype=tf.int64)\n",
    "    elif num_classes == 6:\n",
    "        if example[\"primary\"] == tf.constant(1, dtype=tf.int64) or example[\"primary\"] == tf.constant(2, dtype=tf.int64) or example[\"primary\"] == tf.constant(3, dtype=tf.int64) or example[\"primary\"] == tf.constant(4, dtype=tf.int64) or example[\"primary\"] == tf.constant(5, dtype=tf.int64):\n",
    "            primary_to_return = example[\"primary\"]\n",
    "        else:\n",
    "            primary_to_return = tf.constant(0, dtype=tf.int64)\n",
    "    else:\n",
    "            print(\"ERROR\")\n",
    "            print(\"num classes not supported\")\n",
    "            print(\"Check parse_record function\")\n",
    "            print(\"____________________________\")\n",
    "\n",
    "    if rgb: # select the right sequence to return\n",
    "        if sequence == \"t1\":\n",
    "            image = image[:, :, :, 0]\n",
    "        elif sequence == \"t1c\":\n",
    "            image = image[:, :, :, 1]\n",
    "        elif sequence == \"t2\":\n",
    "            image = image[:, :, :, 2]\n",
    "        elif sequence == \"flair\":\n",
    "            image = image[:, :, :, 3]\n",
    "\n",
    "    if image_only:\n",
    "        return image, primary_to_return\n",
    "    elif labeled:\n",
    "        return (image, example[\"sex\"], example[\"age\"]), primary_to_return #example[\"primary\"]\n",
    "    else:\n",
    "        return image\n",
    "    \n",
    "def verify_tfrecord(file_path):\n",
    "    try:\n",
    "        for _ in tf.data.TFRecordDataset(file_path, compression_type=\"GZIP\"):\n",
    "            pass\n",
    "    except tf.errors.DataLossError:\n",
    "        print(f\"Corrupted TFRecord file: {file_path}\")\n",
    "\n",
    "class PrintValTrainRatioCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        ratio = logs[\"val_loss\"] / logs[\"loss\"]\n",
    "        print(f\"\\nEpoch {epoch+1}: val/train ratio: {ratio:.2f}\")\n",
    "\n",
    "class UnfreezeCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, patience=3, monitor='val_accuracy', min_delta=0.01):\n",
    "        super(UnfreezeCallback, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.monitor = monitor\n",
    "        self.min_delta = min_delta\n",
    "        self.wait = 0\n",
    "        self.best = -float('inf')\n",
    "        self.unfreeze = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            raise ValueError(f\"Monitor {self.monitor} is not available in logs.\")\n",
    "        \n",
    "        if current > self.best + self.min_delta:\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            print(\"\\nnot gonna unfreeze\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience and not self.unfreeze:\n",
    "                print(f\"\\nUnfreezing layers at epoch {epoch + 1}\")\n",
    "\n",
    "                # for layer in self.model.get_layer('resnet50').layers:\n",
    "                #     layer.trainable = True\n",
    "\n",
    "                # self.model.save_weights('temp_weights.h5')\n",
    "\n",
    "                self.model.stop_training = True\n",
    "                # self.model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-5),  # Lower learning rate\n",
    "                #                    loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "                # self.model.load_weights('temp_weights.h5')\n",
    "\n",
    "                self.unfreeze = True\n",
    "                self.wait = 0\n",
    "\n",
    "unfreeze_callback = UnfreezeCallback(patience=1, monitor='val_accuracy', min_delta=0.01)\n",
    "\n",
    "def get_callbacks(fold_num = 0,\n",
    "                  use_checkpoint = True,\n",
    "                  use_early_stopping = True,\n",
    "                  early_stopping_patience = early_stopping_patience,\n",
    "                  use_tensorboard = True,\n",
    "                  use_csv_logger = True,\n",
    "                  use_lrscheduler = False,\n",
    "                  use_unfreeze = False):\n",
    "\n",
    "    callbacks = []\n",
    "\n",
    "    path_to_fold_callbacks = path_to_callbacks / f\"fold_{fold_num}\"\n",
    "\n",
    "    def get_run_logdir(root_logdir = path_to_fold_callbacks / \"tensorboard\"):\n",
    "        return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "    run_logdir = get_run_logdir()\n",
    "\n",
    "    # model checkpoint\n",
    "    if use_checkpoint:\n",
    "        checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath = path_to_fold_callbacks / \"saved_weights.weights.h5\",\n",
    "            monitor = \"val_accuracy\",\n",
    "            mode = \"max\",\n",
    "            save_best_only = True,\n",
    "            save_weights_only = True,\n",
    "        )\n",
    "        callbacks.append(checkpoint_cb)\n",
    "\n",
    "    # early stopping\n",
    "    if use_early_stopping:\n",
    "        early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "            patience = early_stopping_patience,\n",
    "            restore_best_weights = True,\n",
    "            verbose = 1\n",
    "        )\n",
    "        callbacks.append(early_stopping_cb)\n",
    "\n",
    "    # tensorboard, doesn't really work yet\n",
    "    if use_tensorboard:\n",
    "        tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir = run_logdir,\n",
    "                                                    histogram_freq = 1)\n",
    "        callbacks.append(tensorboard_cb)\n",
    "    \n",
    "    # csv logger\n",
    "    if use_csv_logger:\n",
    "        csv_logger_cb = tf.keras.callbacks.CSVLogger(path_to_fold_callbacks / \"training.csv\", separator = \",\", append = True)\n",
    "        callbacks.append(csv_logger_cb)\n",
    "    \n",
    "    if use_lrscheduler:\n",
    "        lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch * 0.0175))\n",
    "        callbacks.append(lr_schedule)\n",
    "    \n",
    "    valtrainratio_callback = PrintValTrainRatioCallback()\n",
    "    callbacks.append(valtrainratio_callback)\n",
    "\n",
    "    if use_unfreeze:\n",
    "        unfreeze_callback = UnfreezeCallback(patience=3, monitor='val_accuracy', min_delta=0.01)\n",
    "        callbacks.append(unfreeze_callback)\n",
    "\n",
    "    print(\"get_callbacks successful\")\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeToRange(tf.keras.layers.Layer):\n",
    "    def __init__(self, zero_to_one=True):\n",
    "        super(NormalizeToRange, self).__init__()\n",
    "        self.zero_to_one = zero_to_one\n",
    "\n",
    "    def call(self, inputs):\n",
    "        min_val = tf.reduce_min(inputs)\n",
    "        max_val = tf.reduce_max(inputs)\n",
    "        if self.zero_to_one:\n",
    "            # Normalize to [0, 1]\n",
    "            normalized = (inputs - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            # Normalize to [-1, 1]\n",
    "            normalized = 2 * (inputs - min_val) / (max_val - min_val) - 1\n",
    "        return normalized\n",
    "    \n",
    "    \n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(mode = \"horizontal\"),\n",
    "    #tf.keras.layers.Rescaling(1/255),\n",
    "    tf.keras.layers.RandomContrast(0.5), # consider removing the random contrast layer as that causes pixel values to go beyond 1\n",
    "    tf.keras.layers.RandomBrightness(factor = (-0.2, 0.4)), #, value_range=(0, 1)\n",
    "    tf.keras.layers.RandomRotation(factor = (-0.1, 0.1), fill_mode = \"nearest\"),\n",
    "    NormalizeToRange(zero_to_one=True),\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor = 0.05,\n",
    "        width_factor = 0.05,\n",
    "        fill_mode = \"nearest\",\n",
    "        interpolation = \"bilinear\"\n",
    "    ),\n",
    "    #tf.keras.layers.Resizing(image_size, image_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total patients: 471\n",
      "actual tfrs length: 46\n",
      "train: 36 | val: 4 | test: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 11:16:11.897652: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-12 11:16:11.908404: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-12 11:16:11.930826: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-12 11:16:11.971396: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-12 11:16:12.055919: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-12 11:16:12.247043: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-12 11:16:12.578915: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-12 11:16:13.222956: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 173 | val: 29 | test: 14\n"
     ]
    }
   ],
   "source": [
    "patients = get_patient_paths()\n",
    "\n",
    "train_patients, val_patients, test_patients = split_patients(patients, fraction_to_use = 0.1)\n",
    "\n",
    "train_paths = get_tfr_paths_for_patients(train_patients)\n",
    "val_paths = get_tfr_paths_for_patients(val_patients)\n",
    "test_paths = get_tfr_paths_for_patients(test_patients)\n",
    "train_data, val_data, test_data = read_data(train_paths, val_paths, test_paths, rgb=True)\n",
    "\n",
    "len_train = len(train_paths)\n",
    "len_val = len(val_paths)\n",
    "len_test = len(test_paths)\n",
    "print(f\"train: {len_train} | val: {len_val} | test: {len_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_callbacks successful\n"
     ]
    }
   ],
   "source": [
    "callbacks = get_callbacks(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preview single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(16, 240, 240, 4)\n",
      "(240, 240, 4)\n",
      "\n",
      "Before Augmentation\n",
      "Min: 0.0\n",
      "Max: 255.0\n",
      "Mean: 3.0679688453674316\n",
      "________________________________________\n",
      "\n",
      "After Augmentation\n",
      "Min: 0.0\n",
      "Max: 1.0\n",
      "Mean: 0.015604679472744465\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = train_data.take(1)\n",
    "\n",
    "for (image, sex, age), primary in test_image:\n",
    "    print(primary.numpy()[0])\n",
    "    print(image.shape)\n",
    "    print(image[0].shape)\n",
    "    image = image[0]\n",
    "    imagebefore = image\n",
    "\n",
    "    print()\n",
    "    print(\"Before Augmentation\")\n",
    "\n",
    "    print(f\"Min: {tf.reduce_min(image)}\")\n",
    "    print(f\"Max: {tf.reduce_max(image)}\")\n",
    "    print(f\"Mean: {tf.reduce_mean(image)}\")\n",
    "\n",
    "    print(\"________________________________________\")\n",
    "    print()\n",
    "    print(\"After Augmentation\")\n",
    "    image = data_augmentation(image)\n",
    "    print(f\"Min: {tf.reduce_min(image)}\")\n",
    "    print(f\"Max: {tf.reduce_max(image)}\")\n",
    "    print(f\"Mean: {tf.reduce_mean(image)}\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle('Before / After Augmentation')\n",
    "    ax1.imshow(imagebefore[:,:,1], cmap = \"gray\")\n",
    "    ax2.imshow(image[:,:,1], cmap = \"gray\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normal Conv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_model():\n",
    "\n",
    "    DefaultConv2D = partial(tf.keras.layers.Conv2D, kernel_size=3, padding=\"same\", activation = activation_func, kernel_initializer=\"he_normal\")\n",
    "\n",
    "    optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # Define inputs\n",
    "    image_input = tf.keras.layers.Input(shape=(240, 240, 4))\n",
    "    sex_input = tf.keras.layers.Input(shape=(1,))\n",
    "    age_input = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "    batch_norm_layer = tf.keras.layers.BatchNormalization()\n",
    "    conv_1_layer = DefaultConv2D(filters = 64, kernel_size = 7, strides = 2, input_shape = [240, 240, 4])\n",
    "    max_pool_1_layer = tf.keras.layers.MaxPool2D(pool_size = (2,2))\n",
    "\n",
    "    conv_2_layer = DefaultConv2D(filters = 128)\n",
    "    conv_3_layer = DefaultConv2D(filters = 128)\n",
    "    max_pool_2_layer = tf.keras.layers.MaxPool2D(pool_size = (2,2))\n",
    "\n",
    "    conv_4_layer = DefaultConv2D(filters = 256)\n",
    "    conv_5_layer = DefaultConv2D(filters = 256)\n",
    "    max_pool_3_layer = tf.keras.layers.MaxPool2D(pool_size = (2,2))\n",
    "    \n",
    "    # conv_4_layer = tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, strides=(1,1,1), activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    # max_pool_4_layer = tf.keras.layers.MaxPool2D(pool_size = (2,2,2))\n",
    "\n",
    "    dense_1_layer = tf.keras.layers.Dense(256, activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    dropout_1_layer = tf.keras.layers.Dropout(0.5)\n",
    "    dense_2_layer = tf.keras.layers.Dense(128, activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    dropout_2_layer = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "\n",
    "    batch_norm = batch_norm_layer(image_input)\n",
    "\n",
    "    conv_1 = conv_1_layer(batch_norm)\n",
    "    max_pool_1 = max_pool_1_layer(conv_1)\n",
    "\n",
    "    conv_2 = conv_2_layer(max_pool_1)\n",
    "    conv_3 = conv_3_layer(conv_2)\n",
    "    max_pool_2 = max_pool_2_layer(conv_3)\n",
    "\n",
    "    conv_4 = conv_4_layer(max_pool_2)\n",
    "    conv_5 = conv_5_layer(conv_4)\n",
    "    max_pool_3 = max_pool_3_layer(conv_5)\n",
    "\n",
    "    flatten = tf.keras.layers.Flatten()(max_pool_3)\n",
    "\n",
    "    flattened_sex_input = tf.keras.layers.Flatten()(sex_input)\n",
    "    age_input_reshaped = tf.keras.layers.Reshape((1,))(age_input)  # Reshape age_input to have 2 dimensions\n",
    "    concatenated_inputs = tf.keras.layers.Concatenate()([flatten, age_input_reshaped, flattened_sex_input])\n",
    "\n",
    "    x = dense_1_layer(concatenated_inputs)\n",
    "    x = dropout_1_layer(x)\n",
    "    x = dense_2_layer(x)\n",
    "    x = dropout_2_layer(x)\n",
    "\n",
    "    match num_classes:\n",
    "        case 2:\n",
    "            x = tf.keras.layers.Dense(1)(x)\n",
    "            output = tf.keras.layers.Activation('sigmoid', dtype='float32', name='predictions')(x)\n",
    "        case 3:\n",
    "            x = tf.keras.layers.Dense(3)(x)\n",
    "            output = tf.keras.layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "        case 4:\n",
    "            x = tf.keras.layers.Dense(4)(x)\n",
    "            output = tf.keras.layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "        case 5:\n",
    "            x = tf.keras.layers.Dense(5)(x)\n",
    "            output = tf.keras.layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "        case 6:\n",
    "            x = tf.keras.layers.Dense(6)(x)\n",
    "            output = tf.keras.layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "        case _:\n",
    "            print(\"Wrong num classes set in the buil_ai func, please pick a number between 2 and 6\")\n",
    "\n",
    "    model = tf.keras.Model(inputs = [image_input, sex_input, age_input], outputs = [output])\n",
    "\n",
    "    if num_classes > 2:\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics = [\"RootMeanSquaredError\", \"accuracy\"])\n",
    "    else:\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics = [\"RootMeanSquaredError\", \"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 240, 240, 4)]        0         []                            \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 240, 240, 4)          16        ['input_1[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 120, 120, 64)         12608     ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 60, 60, 64)           0         ['conv2d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 60, 60, 128)          73856     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 128)          147584    ['conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 128)          0         ['conv2d_2[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 30, 30, 256)          295168    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 256)          590080    ['conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 15, 15, 256)          0         ['conv2d_4[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 57600)                0         ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1)                    0         ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 1)                    0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 57602)                0         ['flatten[0][0]',             \n",
      "                                                                     'reshape[0][0]',             \n",
      "                                                                     'flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  1474636   ['concatenate[0][0]']         \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 256)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 128)                  32896     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 128)                  0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 4)                    516       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " predictions (Activation)    (None, 4)                    0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15899092 (60.65 MB)\n",
      "Trainable params: 15899084 (60.65 MB)\n",
      "Non-trainable params: 8 (32.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model = build_conv_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet34_model():\n",
    "\n",
    "    DefaultConv2D = partial(tf.keras.layers.Conv2D,\n",
    "                            kernel_size=3,\n",
    "                            strides = 1,\n",
    "                            padding=\"same\",\n",
    "                            activation = activation_func,\n",
    "                            kernel_initializer=\"he_normal\",\n",
    "                            use_bias=False)\n",
    "    \n",
    "    class ResidualUnit(tf.keras.layers.Layer):\n",
    "        def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.activation = tf.keras.activations.get(activation)\n",
    "            self.main_layers = [\n",
    "                DefaultConv2D(filters, strides = strides),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                self.activation,\n",
    "                DefaultConv2D(filters),\n",
    "                tf.keras.layers.BatchNormalization()\n",
    "            ]\n",
    "            self.skip_layers = []\n",
    "            if strides > 1:\n",
    "                self.skip_layers = [\n",
    "                    DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
    "                    tf.keras.layers.BatchNormalization()\n",
    "                ]\n",
    "            \n",
    "        def call(self, inputs):\n",
    "            Z = inputs\n",
    "            for layer in self.main_layers:\n",
    "                Z = layer(Z)\n",
    "            skip_Z = inputs\n",
    "            for layer in self.skip_layers:\n",
    "                skip_Z = layer(skip_Z)\n",
    "            return self.activation(Z + skip_Z)\n",
    "    \n",
    "\n",
    "\n",
    "    optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # Define inputs\n",
    "    image_input = tf.keras.layers.Input(shape=(240, 240, 4))\n",
    "    sex_input = tf.keras.layers.Input(shape=(1,))\n",
    "    age_input = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "\n",
    "    dense_1_layer = tf.keras.layers.Dense(256, activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    dropout_1_layer = tf.keras.layers.Dropout(0.5)\n",
    "    dense_2_layer = tf.keras.layers.Dense(128, activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    dropout_2_layer = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "    augment = data_augmentation(image_input)\n",
    "\n",
    "    x = DefaultConv2D(filters = 64, kernel_size = 7, strides = 2, input_shape = [240, 240, 4])(augment)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(activation_func)(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size = 3, strides = 2, padding = \"same\")(x)\n",
    "\n",
    "    prev_filters = 64\n",
    "    for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
    "        strides = 1 if filters == prev_filters else 2\n",
    "        x = ResidualUnit(filters, strides = strides)(x)\n",
    "        prev_filters = filters\n",
    "    \n",
    "    x = tf.keras.layers.GlobalMaxPool2D()(x)\n",
    "    resnet = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    flattened_sex_input = tf.keras.layers.Flatten()(sex_input)\n",
    "    age_input_reshaped = tf.keras.layers.Reshape((1,))(age_input)  # Reshape age_input to have 2 dimensions\n",
    "    concatenated_inputs = tf.keras.layers.Concatenate()([resnet, age_input_reshaped, flattened_sex_input])\n",
    "\n",
    "    x = dense_1_layer(concatenated_inputs)\n",
    "    x = dropout_1_layer(x)\n",
    "    x = dense_2_layer(x)\n",
    "    x = dropout_2_layer(x)\n",
    "\n",
    "    match num_classes:\n",
    "        case 2:\n",
    "            x = tf.keras.layers.Dense(1)(x)\n",
    "            output = tf.keras.layers.Activation('sigmoid', dtype='float32', name='predictions')(x)\n",
    "        case 3 | 4 | 5 | 6:\n",
    "            x = tf.keras.layers.Dense(num_classes)(x)\n",
    "            output = tf.keras.layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "        case _:\n",
    "            raise ValueError(\"num_classes must be 2, 3, 4, 5 or 6.\")\n",
    "\n",
    "    model = tf.keras.Model(inputs = [image_input, sex_input, age_input], outputs = [output], name = \"resnet34_model\")\n",
    "\n",
    "    if num_classes > 2:\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics = [\"RootMeanSquaredError\", \"accuracy\"])\n",
    "    else:\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics = [\"RootMeanSquaredError\", \"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_40 (InputLayer)       [(None, 240, 240, 4)]        0         []                            \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)   (None, 240, 240, 4)          0         ['input_40[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_920 (Conv2D)         (None, 120, 120, 64)         12544     ['sequential_4[4][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_904 (B  (None, 120, 120, 64)         256       ['conv2d_920[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 120, 120, 64)         0         ['batch_normalization_904[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_24 (MaxPooli  (None, 60, 60, 64)           0         ['activation_12[0][0]']       \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_32 (Residual  (None, 60, 60, 64)           74240     ['max_pooling2d_24[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_33 (Residual  (None, 60, 60, 64)           74240     ['residual_unit_32[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_34 (Residual  (None, 60, 60, 64)           74240     ['residual_unit_33[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_35 (Residual  (None, 30, 30, 128)          230912    ['residual_unit_34[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_36 (Residual  (None, 30, 30, 128)          295936    ['residual_unit_35[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_37 (Residual  (None, 30, 30, 128)          295936    ['residual_unit_36[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_38 (Residual  (None, 30, 30, 128)          295936    ['residual_unit_37[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_39 (Residual  (None, 15, 15, 256)          920576    ['residual_unit_38[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_40 (Residual  (None, 15, 15, 256)          1181696   ['residual_unit_39[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_41 (Residual  (None, 15, 15, 256)          1181696   ['residual_unit_40[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_42 (Residual  (None, 15, 15, 256)          1181696   ['residual_unit_41[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_43 (Residual  (None, 15, 15, 256)          1181696   ['residual_unit_42[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_44 (Residual  (None, 15, 15, 256)          1181696   ['residual_unit_43[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_45 (Residual  (None, 8, 8, 512)            3676160   ['residual_unit_44[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_46 (Residual  (None, 8, 8, 512)            4722688   ['residual_unit_45[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " residual_unit_47 (Residual  (None, 8, 8, 512)            4722688   ['residual_unit_46[0][0]']    \n",
      " Unit)                                                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling2d_6 (Gl  (None, 512)                  0         ['residual_unit_47[0][0]']    \n",
      " obalMaxPooling2D)                                                                                \n",
      "                                                                                                  \n",
      " input_42 (InputLayer)       [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_41 (InputLayer)       [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " flatten_14 (Flatten)        (None, 512)                  0         ['global_max_pooling2d_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)         (None, 1)                    0         ['input_42[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_15 (Flatten)        (None, 1)                    0         ['input_41[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 514)                  0         ['flatten_14[0][0]',          \n",
      " )                                                                   'reshape_7[0][0]',           \n",
      "                                                                     'flatten_15[0][0]']          \n",
      "                                                                                                  \n",
      " dense_28 (Dense)            (None, 256)                  131840    ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)        (None, 256)                  0         ['dense_28[0][0]']            \n",
      "                                                                                                  \n",
      " dense_29 (Dense)            (None, 128)                  32896     ['dropout_24[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)        (None, 128)                  0         ['dense_29[0][0]']            \n",
      "                                                                                                  \n",
      " dense_30 (Dense)            (None, 4)                    516       ['dropout_25[0][0]']          \n",
      "                                                                                                  \n",
      " predictions (Activation)    (None, 4)                    0         ['dense_30[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21470084 (81.90 MB)\n",
      "Trainable params: 21453060 (81.84 MB)\n",
      "Non-trainable params: 17024 (66.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_34_model = build_resnet34_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet152_model():\n",
    "\n",
    "    DefaultConv2D = partial(tf.keras.layers.Conv2D,\n",
    "                            kernel_size=3,\n",
    "                            strides = 1,\n",
    "                            padding=\"same\",\n",
    "                            activation = activation_func,\n",
    "                            kernel_initializer=\"he_normal\",\n",
    "                            use_bias=False)\n",
    "    \n",
    "    class BottleneckResidualUnit(tf.keras.layers.Layer):\n",
    "        def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.activation = tf.keras.activations.get(activation)\n",
    "            self.strides = strides\n",
    "            self.filters = filters\n",
    "\n",
    "            self.main_layers = [\n",
    "                tf.keras.layers.Conv2D(filters, kernel_size=1, strides=strides, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                self.activation,\n",
    "                tf.keras.layers.Conv2D(filters, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                self.activation,\n",
    "                tf.keras.layers.Conv2D(filters * 4, kernel_size=1, strides=1, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False),\n",
    "                tf.keras.layers.BatchNormalization()\n",
    "            ]\n",
    "\n",
    "            self.skip_conv = tf.keras.layers.Conv2D(filters * 4, kernel_size=1, strides=strides, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False)\n",
    "            #self.skip_layers = None\n",
    "            self.skip_bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "\n",
    "        def buil(self, input_shape):\n",
    "            if self.strides > 1 or input_shape[-1] != self.filters * 4:\n",
    "                self.skip_layers = [\n",
    "                    tf.keras.layers.Conv2D(self.filters * 4, kernel_size=1, strides=self.strides, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False),\n",
    "                    tf.keras.layers.BatchNormalization()\n",
    "                ]\n",
    "\n",
    "        def call(self, inputs):\n",
    "            Z = inputs\n",
    "            for layer in self.main_layers:\n",
    "                Z = layer(Z)\n",
    "            skip_Z = inputs\n",
    "            skip_Z = self.skip_conv(inputs)\n",
    "            skip_Z = self.skip_bn(skip_Z)\n",
    "            return self.activation(Z + skip_Z)\n",
    "    \n",
    "\n",
    "    optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "    dense_1_layer = tf.keras.layers.Dense(256, activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    dropout_1_layer = tf.keras.layers.Dropout(0.5)\n",
    "    dense_2_layer = tf.keras.layers.Dense(128, activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    dropout_2_layer = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "    # Define inputs\n",
    "    image_input = tf.keras.layers.Input(shape=(240, 240, 4))\n",
    "    sex_input = tf.keras.layers.Input(shape=(1,))\n",
    "    age_input = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "    augment = data_augmentation(image_input)\n",
    "\n",
    "\n",
    "    x = DefaultConv2D(filters = 64, kernel_size = 7, strides = 2)(augment)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(activation_func)(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size = 3, strides = 2, padding = \"same\")(x)\n",
    "\n",
    "    block_config = [\n",
    "        (64, 3, 1),\n",
    "        (128, 8, 2),\n",
    "        (256, 36, 2),\n",
    "        (512, 3, 2)\n",
    "    ]\n",
    "\n",
    "\n",
    "    for filters, blocks, stride in block_config:\n",
    "        for block in range(blocks):\n",
    "            if block == 0:\n",
    "                x = BottleneckResidualUnit(filters, strides=stride)(x)\n",
    "            else:\n",
    "                x = BottleneckResidualUnit(filters, strides=1)(x)\n",
    "\n",
    "    x = tf.keras.layers.GlobalMaxPool2D()(x)\n",
    "    resnet = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    flattened_sex_input = tf.keras.layers.Flatten()(sex_input)\n",
    "    age_input_reshaped = tf.keras.layers.Reshape((1,))(age_input)  # Reshape age_input to have 2 dimensions\n",
    "    concatenated_inputs = tf.keras.layers.Concatenate()([resnet, age_input_reshaped, flattened_sex_input])\n",
    "\n",
    "    x = dense_1_layer(concatenated_inputs)\n",
    "    x = dropout_1_layer(x)\n",
    "    x = dense_2_layer(x)\n",
    "    x = dropout_2_layer(x)\n",
    "\n",
    "    match num_classes:\n",
    "        case 2:\n",
    "            x = tf.keras.layers.Dense(1)(x)\n",
    "            output = tf.keras.layers.Activation('sigmoid', dtype='float32', name='predictions')(x)\n",
    "        case 3 | 4 | 5 | 6:\n",
    "            x = tf.keras.layers.Dense(num_classes)(x)\n",
    "            output = tf.keras.layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "        case _:\n",
    "            raise ValueError(\"num_classes must be 2, 3, 4, 5 or 6.\")\n",
    "\n",
    "    model = tf.keras.Model(inputs = [image_input, sex_input, age_input], outputs = [output], name = \"resnet152_model\")\n",
    "\n",
    "    if num_classes > 2:\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics = [\"RootMeanSquaredError\", \"accuracy\"])\n",
    "    else:\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics = [\"RootMeanSquaredError\", \"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_49 (InputLayer)       [(None, 240, 240, 4)]        0         []                            \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)   (None, 240, 240, 4)          0         ['input_49[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_1002 (Conv2D)        (None, 120, 120, 64)         12544     ['sequential_4[6][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_978 (B  (None, 120, 120, 64)         256       ['conv2d_1002[0][0]']         \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 120, 120, 64)         0         ['batch_normalization_978[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_32 (MaxPooli  (None, 60, 60, 64)           0         ['activation_14[0][0]']       \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 60, 60, 256)          76288     ['max_pooling2d_32[0][0]']    \n",
      " 05 (BottleneckResidualUnit                                                                       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 60, 60, 256)          137728    ['bottleneck_residual_unit_205\n",
      " 06 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 60, 60, 256)          137728    ['bottleneck_residual_unit_206\n",
      " 07 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 30, 30, 512)          381952    ['bottleneck_residual_unit_207\n",
      " 08 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 30, 30, 512)          545792    ['bottleneck_residual_unit_208\n",
      " 09 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 30, 30, 512)          545792    ['bottleneck_residual_unit_209\n",
      " 10 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 30, 30, 512)          545792    ['bottleneck_residual_unit_210\n",
      " 11 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 30, 30, 512)          545792    ['bottleneck_residual_unit_211\n",
      " 12 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 30, 30, 512)          545792    ['bottleneck_residual_unit_212\n",
      " 13 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 30, 30, 512)          545792    ['bottleneck_residual_unit_213\n",
      " 14 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 30, 30, 512)          545792    ['bottleneck_residual_unit_214\n",
      " 15 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         1517568   ['bottleneck_residual_unit_215\n",
      " 16 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_216\n",
      " 17 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_217\n",
      " 18 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_218\n",
      " 19 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_219\n",
      " 20 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_220\n",
      " 21 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_221\n",
      " 22 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_222\n",
      " 23 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_223\n",
      " 24 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_224\n",
      " 25 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_225\n",
      " 26 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_226\n",
      " 27 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_227\n",
      " 28 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_228\n",
      " 29 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_229\n",
      " 30 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_230\n",
      " 31 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_231\n",
      " 32 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_232\n",
      " 33 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_233\n",
      " 34 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_234\n",
      " 35 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_235\n",
      " 36 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_236\n",
      " 37 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_237\n",
      " 38 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_238\n",
      " 39 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_239\n",
      " 40 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_240\n",
      " 41 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_241\n",
      " 42 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_242\n",
      " 43 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_243\n",
      " 44 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_244\n",
      " 45 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_245\n",
      " 46 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_246\n",
      " 47 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_247\n",
      " 48 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_248\n",
      " 49 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_249\n",
      " 50 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 15, 15, 1024)         2172928   ['bottleneck_residual_unit_250\n",
      " 51 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 8, 8, 2048)           6049792   ['bottleneck_residual_unit_251\n",
      " 52 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 8, 8, 2048)           8671232   ['bottleneck_residual_unit_252\n",
      " 53 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bottleneck_residual_unit_2  (None, 8, 8, 2048)           8671232   ['bottleneck_residual_unit_253\n",
      " 54 (BottleneckResidualUnit                                         [0][0]']                      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling2d_8 (Gl  (None, 2048)                 0         ['bottleneck_residual_unit_254\n",
      " obalMaxPooling2D)                                                  [0][0]']                      \n",
      "                                                                                                  \n",
      " input_51 (InputLayer)       [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_50 (InputLayer)       [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " flatten_20 (Flatten)        (None, 2048)                 0         ['global_max_pooling2d_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " reshape_10 (Reshape)        (None, 1)                    0         ['input_51[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_21 (Flatten)        (None, 1)                    0         ['input_50[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenat  (None, 2050)                 0         ['flatten_20[0][0]',          \n",
      " e)                                                                  'reshape_10[0][0]',          \n",
      "                                                                     'flatten_21[0][0]']          \n",
      "                                                                                                  \n",
      " dense_37 (Dense)            (None, 256)                  525056    ['concatenate_10[0][0]']      \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)        (None, 256)                  0         ['dense_37[0][0]']            \n",
      "                                                                                                  \n",
      " dense_38 (Dense)            (None, 128)                  32896     ['dropout_30[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)        (None, 128)                  0         ['dense_38[0][0]']            \n",
      "                                                                                                  \n",
      " dense_39 (Dense)            (None, 4)                    516       ['dropout_31[0][0]']          \n",
      "                                                                                                  \n",
      " predictions (Activation)    (None, 4)                    0         ['dense_39[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 106087812 (404.69 MB)\n",
      "Trainable params: 105848324 (403.78 MB)\n",
      "Non-trainable params: 239488 (935.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_152_model = build_resnet152_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnext_model(architecture=\"ResNeXt50\"):\n",
    "\n",
    "    architectures = {\n",
    "        \"ResNeXt50\": [3, 4, 6, 3],\n",
    "        \"ResNeXt101\": [3, 4, 23, 3],\n",
    "    }\n",
    "\n",
    "    if architecture not in architectures:\n",
    "        raise ValueError(f\"Architecture {architecture} not recognized. Available architectures: {list(architectures.keys())}\")\n",
    "\n",
    "    repetitions = architectures[architecture]\n",
    "\n",
    "    DefaultConv2D = partial(tf.keras.layers.Conv2D,\n",
    "                            kernel_size=3,\n",
    "                            strides=1,\n",
    "                            padding=\"same\",\n",
    "                            activation=None,\n",
    "                            kernel_initializer=\"he_normal\",\n",
    "                            use_bias=False)\n",
    "    \n",
    "    class ResNeXtBlock(tf.keras.layers.Layer):\n",
    "        def __init__(self, filters, cardinality, strides=1, input_filters = None, activation=\"relu\", **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.activation = tf.keras.activations.get(activation)\n",
    "            self.main_layers = [\n",
    "                DefaultConv2D(filters // 2, kernel_size=1, strides=1),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                self.activation,\n",
    "                DefaultConv2D(filters // 2, kernel_size=3, strides=strides, groups=cardinality),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                self.activation,\n",
    "                DefaultConv2D(filters, kernel_size=1, strides=1),\n",
    "                tf.keras.layers.BatchNormalization()\n",
    "            ]\n",
    "            self.skip_layers = []\n",
    "            if strides > 1 or filters != input_filters:\n",
    "                self.skip_layers = [\n",
    "                    DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
    "                    tf.keras.layers.BatchNormalization()\n",
    "                ]\n",
    "\n",
    "        def call(self, inputs):\n",
    "            Z = inputs\n",
    "            for layer in self.main_layers:\n",
    "                Z = layer(Z)\n",
    "            skip_Z = inputs\n",
    "            for layer in self.skip_layers:\n",
    "                skip_Z = layer(skip_Z)\n",
    "            return self.activation(Z + skip_Z)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # Define inputs\n",
    "    image_input = tf.keras.layers.Input(shape=(240, 240, 4))\n",
    "    sex_input = tf.keras.layers.Input(shape=(1,))\n",
    "    age_input = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "    augment = data_augmentation(image_input)\n",
    "\n",
    "    x = DefaultConv2D(filters=64, kernel_size=7, strides=2, input_shape=[240, 240, 4])(augment)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(activation_func)(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "    cardinality = 32\n",
    "    filters = 128\n",
    "    #repetitions = [3, 4, 6, 3]\n",
    "    input_filters = x.shape[-1]\n",
    "    for i, reps in enumerate(repetitions):\n",
    "        for j in range(reps):\n",
    "            strides = 1 if j != 0 else 2 #if i == 0 or\n",
    "            x = ResNeXtBlock(filters, cardinality, strides=strides, input_filters=input_filters)(x)\n",
    "            input_filters = filters\n",
    "        filters *= 2\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    resnext = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    flattened_sex_input = tf.keras.layers.Flatten()(sex_input)\n",
    "    age_input_reshaped = tf.keras.layers.Reshape((1,))(age_input)\n",
    "    concatenated_inputs = tf.keras.layers.Concatenate()([resnext, age_input_reshaped, flattened_sex_input])\n",
    "\n",
    "    dense_1_layer = tf.keras.layers.Dense(256, activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    dropout_1_layer = tf.keras.layers.Dropout(0.5)\n",
    "    dense_2_layer = tf.keras.layers.Dense(128, activation=activation_func, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    dropout_2_layer = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "    x = dense_1_layer(concatenated_inputs)\n",
    "    x = dropout_1_layer(x)\n",
    "    x = dense_2_layer(x)\n",
    "    x = dropout_2_layer(x)\n",
    "\n",
    "    match num_classes:\n",
    "        case 2:\n",
    "            x = tf.keras.layers.Dense(1)(x)\n",
    "            output = tf.keras.layers.Activation('sigmoid', dtype='float32', name='predictions')(x)\n",
    "        case 3 | 4 | 5 | 6:\n",
    "            x = tf.keras.layers.Dense(num_classes)(x)\n",
    "            output = tf.keras.layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "        case _:\n",
    "            raise ValueError(\"num_classes must be 2, 3, 4, 5 or 6.\")\n",
    "\n",
    "    model = tf.keras.Model(inputs=[image_input, sex_input, age_input], outputs=[output], name=architecture)\n",
    "\n",
    "    if num_classes > 2:\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\", \"accuracy\"])\n",
    "    else:\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\", \"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNeXt50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_73 (InputLayer)       [(None, 240, 240, 4)]        0         []                            \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)   (None, 240, 240, 4)          0         ['input_73[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_1573 (Conv2D)        (None, 120, 120, 64)         12544     ['sequential_4[14][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1549 (  (None, 120, 120, 64)         256       ['conv2d_1573[0][0]']         \n",
      " BatchNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_22 (Activation)  (None, 120, 120, 64)         0         ['batch_normalization_1549[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " max_pooling2d_40 (MaxPooli  (None, 60, 60, 64)           0         ['activation_22[0][0]']       \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " res_ne_xt_block_114 (ResNe  (None, 30, 30, 128)          23168     ['max_pooling2d_40[0][0]']    \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_115 (ResNe  (None, 30, 30, 128)          18560     ['res_ne_xt_block_114[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_116 (ResNe  (None, 30, 30, 128)          18560     ['res_ne_xt_block_115[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_117 (ResNe  (None, 15, 15, 256)          89600     ['res_ne_xt_block_116[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_118 (ResNe  (None, 15, 15, 256)          72192     ['res_ne_xt_block_117[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_119 (ResNe  (None, 15, 15, 256)          72192     ['res_ne_xt_block_118[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_120 (ResNe  (None, 15, 15, 256)          72192     ['res_ne_xt_block_119[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_121 (ResNe  (None, 8, 8, 512)            352256    ['res_ne_xt_block_120[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_122 (ResNe  (None, 8, 8, 512)            284672    ['res_ne_xt_block_121[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_123 (ResNe  (None, 8, 8, 512)            284672    ['res_ne_xt_block_122[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_124 (ResNe  (None, 8, 8, 512)            284672    ['res_ne_xt_block_123[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_125 (ResNe  (None, 8, 8, 512)            284672    ['res_ne_xt_block_124[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_126 (ResNe  (None, 8, 8, 512)            284672    ['res_ne_xt_block_125[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_127 (ResNe  (None, 4, 4, 1024)           1396736   ['res_ne_xt_block_126[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_128 (ResNe  (None, 4, 4, 1024)           1130496   ['res_ne_xt_block_127[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " res_ne_xt_block_129 (ResNe  (None, 4, 4, 1024)           1130496   ['res_ne_xt_block_128[0][0]'] \n",
      " XtBlock)                                                                                         \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6  (None, 1024)                 0         ['res_ne_xt_block_129[0][0]'] \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " input_75 (InputLayer)       [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_74 (InputLayer)       [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " flatten_34 (Flatten)        (None, 1024)                 0         ['global_average_pooling2d_6[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " reshape_17 (Reshape)        (None, 1)                    0         ['input_75[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_35 (Flatten)        (None, 1)                    0         ['input_74[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenat  (None, 1026)                 0         ['flatten_34[0][0]',          \n",
      " e)                                                                  'reshape_17[0][0]',          \n",
      "                                                                     'flatten_35[0][0]']          \n",
      "                                                                                                  \n",
      " dense_58 (Dense)            (None, 256)                  262912    ['concatenate_17[0][0]']      \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)        (None, 256)                  0         ['dense_58[0][0]']            \n",
      "                                                                                                  \n",
      " dense_59 (Dense)            (None, 128)                  32896     ['dropout_44[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)        (None, 128)                  0         ['dense_59[0][0]']            \n",
      "                                                                                                  \n",
      " dense_60 (Dense)            (None, 4)                    516       ['dropout_45[0][0]']          \n",
      "                                                                                                  \n",
      " predictions (Activation)    (None, 4)                    0         ['dense_60[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6108932 (23.30 MB)\n",
      "Trainable params: 6074756 (23.17 MB)\n",
      "Non-trainable params: 34176 (133.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnext_50_model = build_resnext_model(\"ResNeXt50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = resnext_50_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "     93/Unknown - 39s 415ms/step - loss: 2.6356 - root_mean_squared_error: 1.4326 - accuracy: 0.4976\n",
      "not gonna unfreeze\n",
      "93/93 [==============================] - 40s 430ms/step - loss: 2.6356 - root_mean_squared_error: 1.4326 - accuracy: 0.4976 - val_loss: 1.2795 - val_root_mean_squared_error: 1.7071 - val_accuracy: 0.5309\n",
      "Epoch 2/30\n",
      "93/93 [==============================] - 41s 443ms/step - loss: 1.3124 - root_mean_squared_error: 1.4193 - accuracy: 0.4963 - val_loss: 1.2662 - val_root_mean_squared_error: 1.7057 - val_accuracy: 0.5309\n",
      "Epoch 3/30\n",
      "93/93 [==============================] - 41s 440ms/step - loss: 1.2616 - root_mean_squared_error: 1.4176 - accuracy: 0.5071 - val_loss: 1.2484 - val_root_mean_squared_error: 1.7059 - val_accuracy: 0.5309\n",
      "Epoch 4/30\n",
      "93/93 [==============================] - ETA: 0s - loss: 1.2534 - root_mean_squared_error: 1.4178 - accuracy: 0.5037\n",
      "Unfreezing layers at epoch 4\n",
      "93/93 [==============================] - 41s 438ms/step - loss: 1.2534 - root_mean_squared_error: 1.4178 - accuracy: 0.5037 - val_loss: 1.2496 - val_root_mean_squared_error: 1.7063 - val_accuracy: 0.5309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights\n",
      "Unfrozen all layers\n",
      "get_callbacks successful\n",
      "Got new callbacks\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1155, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1249, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n        result = update_state_fn(*args, **kwargs)\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n\n    TypeError: Reduce.update_state() got multiple values for argument 'sample_weight'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m simpler_callbacks, _ \u001b[38;5;241m=\u001b[39m get_callbacks(fold_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot new callbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mconv_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m          \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msimpler_callbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/by/b05bkcn50tb0fx4h3hhz0h800000gn/T/__autograph_generated_file5dfayasx.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1155, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1249, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n        result = update_state_fn(*args, **kwargs)\n    File \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n\n    TypeError: Reduce.update_state() got multiple values for argument 'sample_weight'\n"
     ]
    }
   ],
   "source": [
    "history = conv_model.fit(x = train_data,\n",
    "            validation_data = val_data,\n",
    "            epochs = EPOCHS,\n",
    "            callbacks = callbacks\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the standard libraries, watchout though: vit_keras uses tensorflow_addons, which has stopped any development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "from functools import partial\n",
    "from time import strftime\n",
    "\n",
    "#from vit_keras import vit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper functions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tfrs = \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/regensburg_slices_tfrecords/all_pats_single_rgb\"\n",
    "path_to_logs = \"/Users/LennartPhilipp/Desktop/Uni/Prowiss/Datensatz_RGB/regensburg_slices_tfrecords/test_logs\"\n",
    "\n",
    "training_codename = \"2D_pretrained_0000\"\n",
    "\n",
    "num_classes = 4\n",
    "sequence_to_train_on = \"t1c\"\n",
    "\n",
    "time = strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "class_directory = f\"{training_codename}_{num_classes}_classes_{time}\"\n",
    "\n",
    "path_to_callbacks = Path(path_to_logs) / Path(class_directory)\n",
    "os.makedirs(path_to_callbacks, exist_ok=True)\n",
    "\n",
    "\n",
    "image_size = 224\n",
    "\n",
    "## train / val / test split\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "early_stopping_patience = 150\n",
    "shuffle_buffer_size = 20\n",
    "repeat_count = 1\n",
    "\n",
    "image_size = 224\n",
    "batch_size = 16\n",
    "EPOCHS = 30\n",
    "\n",
    "len_train = 0\n",
    "len_val = 0\n",
    "len_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_paths():\n",
    "    patients = [f for f in os.listdir(path_to_tfrs) if os.path.isdir(os.path.join(path_to_tfrs, f))]\n",
    "\n",
    "    patient_paths = [str(path_to_tfrs) + \"/\" + patient for patient in patients]\n",
    "\n",
    "    print(f\"total patients: {len(patient_paths)}\")\n",
    "\n",
    "    for path in patient_paths:\n",
    "        patient_not_empty = False\n",
    "        patient_files = os.listdir(path)\n",
    "        for file in patient_files:\n",
    "            if file.endswith(\".tfrecord\"):\n",
    "                patient_not_empty = True\n",
    "        \n",
    "        if patient_not_empty == False:\n",
    "            patient_paths.remove(path)\n",
    "\n",
    "    return patient_paths\n",
    "\n",
    "def split_patients(patient_paths, fraction_to_use = 1):\n",
    "\n",
    "    random.shuffle(patient_paths)\n",
    "\n",
    "    patient_paths = patient_paths[:int(len(patient_paths) * fraction_to_use)]\n",
    "\n",
    "    if fraction_to_use != 1:\n",
    "        print(f\"actual tfrs length: {len(patient_paths)}\")\n",
    "\n",
    "    train_size = int(len(patient_paths) * train_ratio)\n",
    "    val_size = int(len(patient_paths) * val_ratio)\n",
    "\n",
    "    train_patients_paths = patient_paths[:train_size]\n",
    "    val_patients_paths = patient_paths[train_size:train_size + val_size]\n",
    "    test_patients_paths = patient_paths[train_size + val_size:]\n",
    "\n",
    "    print(f\"train: {len(train_patients_paths)} | val: {len(val_patients_paths)} | test: {len(test_patients_paths)}\")\n",
    "\n",
    "    # save train / val / test patients to txt file\n",
    "    # hf.save_paths_to_txt(train_patients_paths, \"train\", path_to_callbacks)\n",
    "    # hf.save_paths_to_txt(val_patients_paths, \"val\", path_to_callbacks)\n",
    "    # hf.save_paths_to_txt(test_patients_paths, \"test\", path_to_callbacks)\n",
    "\n",
    "    sum = len(train_patients_paths) + len(val_patients_paths) + len(test_patients_paths)\n",
    "    if sum != len(patient_paths):\n",
    "        print(\"WARNING: error occured in train / val / test split!\")\n",
    "\n",
    "    return train_patients_paths, val_patients_paths, test_patients_paths\n",
    "\n",
    "def get_tfr_paths_for_patients(patient_paths):\n",
    "\n",
    "    tfr_paths = []\n",
    "\n",
    "    for patient in patient_paths:\n",
    "        tfr_paths.extend(glob.glob(patient + \"/*.tfrecord\"))\n",
    "    \n",
    "    for path in tfr_paths:\n",
    "        verify_tfrecord(path)\n",
    "\n",
    "    #print(f\"total tfrs: {len(tfr_paths)}\")\n",
    "\n",
    "    return tfr_paths\n",
    "\n",
    "def read_data(train_paths, val_paths, test_paths = None):\n",
    "\n",
    "    train_data = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "    val_data = tf.data.Dataset.from_tensor_slices(val_paths)\n",
    "\n",
    "    train_data = train_data.interleave(\n",
    "        lambda x: tf.data.TFRecordDataset([x], compression_type=\"GZIP\"),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "        deterministic=False\n",
    "    )\n",
    "    val_data = val_data.interleave(\n",
    "        lambda x: tf.data.TFRecordDataset([x], compression_type=\"GZIP\"),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "        deterministic=False\n",
    "    )\n",
    "\n",
    "    train_data = train_data.map(partial(parse_record, image_only = False, labeled = True, num_classes = num_classes), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_data = val_data.map(partial(parse_record, image_only = False, labeled = True, num_classes = num_classes), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    train_data = train_data.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    val_data = val_data.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    train_data = train_data.repeat(count = repeat_count)\n",
    "    val_data = val_data.repeat(count = repeat_count)\n",
    "\n",
    "    train_data = train_data.batch(batch_size)\n",
    "    val_data = val_data.batch(batch_size)\n",
    "\n",
    "    train_data = train_data.prefetch(buffer_size=1)\n",
    "    val_data = val_data.prefetch(buffer_size=1)\n",
    "\n",
    "    if test_paths is not None:\n",
    "        test_data = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "        test_data = test_data.interleave(\n",
    "            lambda x: tf.data.TFRecordDataset([x], compression_type=\"GZIP\"),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE,\n",
    "            deterministic=False\n",
    "        )\n",
    "        test_data = test_data.map(partial(parse_record, image_only = False, labeled = True, num_classes = num_classes), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        test_data = test_data.batch(batch_size)\n",
    "        test_data = test_data.prefetch(buffer_size=1)\n",
    "\n",
    "        return train_data, val_data, test_data\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "def parse_record(record, image_only = False, labeled = False, num_classes = 2, sequence = \"t1c\"):\n",
    "\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([240, 240, 3, 4], tf.float32),\n",
    "        \"sex\": tf.io.FixedLenFeature([], tf.int64, default_value=[0]),\n",
    "        \"age\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "        \"primary\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    }\n",
    "\n",
    "    example = tf.io.parse_single_example(record, feature_description)\n",
    "    image = example[\"image\"]\n",
    "    image = tf.reshape(image, [240, 240, 3, 4])\n",
    "    #image = data_augmentation(image)\n",
    "\n",
    "    # primary should have a value between 0 and 5\n",
    "    # depending on num classes return different values\n",
    "    # if num_classes = 2, return 1 if primary is 1, else 0\n",
    "    # if num_classes = 3, return primaries 1 and 2, else 0\n",
    "    # if num_classes = 4, return primaries 1, 2 and 3, else 0\n",
    "    # if num_classes = 5, return primaries 1, 2, 3 and 4, else 0\n",
    "    # if num_classes = 6, return primaries 1, 2, 3, 4 and 5, else 0\n",
    "\n",
    "    primary_to_return = tf.constant(0, dtype=tf.int64)\n",
    "\n",
    "    if num_classes == 2:\n",
    "        if example[\"primary\"] == tf.constant(1, dtype=tf.int64):\n",
    "            primary_to_return = example[\"primary\"]\n",
    "        else:\n",
    "            primary_to_return = tf.constant(0, dtype=tf.int64)\n",
    "    elif num_classes == 3:\n",
    "        if example[\"primary\"] == tf.constant(1, dtype=tf.int64) or example[\"primary\"] == tf.constant(2, dtype=tf.int64):\n",
    "            primary_to_return = example[\"primary\"]\n",
    "        else:\n",
    "            primary_to_return = tf.constant(0, dtype=tf.int64)\n",
    "    elif num_classes == 4:\n",
    "        if example[\"primary\"] == tf.constant(1, dtype=tf.int64) or example[\"primary\"] == tf.constant(2, dtype=tf.int64) or example[\"primary\"] == tf.constant(3, dtype=tf.int64):\n",
    "            primary_to_return = example[\"primary\"]\n",
    "        else:\n",
    "            primary_to_return = tf.constant(0, dtype=tf.int64)\n",
    "    elif num_classes == 5:\n",
    "        if example[\"primary\"] == tf.constant(1, dtype=tf.int64) or example[\"primary\"] == tf.constant(2, dtype=tf.int64) or example[\"primary\"] == tf.constant(3, dtype=tf.int64) or example[\"primary\"] == tf.constant(4, dtype=tf.int64):\n",
    "            primary_to_return = example[\"primary\"]\n",
    "        else:\n",
    "            primary_to_return = tf.constant(0, dtype=tf.int64)\n",
    "    elif num_classes == 6:\n",
    "        if example[\"primary\"] == tf.constant(1, dtype=tf.int64) or example[\"primary\"] == tf.constant(2, dtype=tf.int64) or example[\"primary\"] == tf.constant(3, dtype=tf.int64) or example[\"primary\"] == tf.constant(4, dtype=tf.int64) or example[\"primary\"] == tf.constant(5, dtype=tf.int64):\n",
    "            primary_to_return = example[\"primary\"]\n",
    "        else:\n",
    "            primary_to_return = tf.constant(0, dtype=tf.int64)\n",
    "    else:\n",
    "            print(\"ERROR\")\n",
    "            print(\"num classes not supported\")\n",
    "            print(\"Check parse_record function\")\n",
    "            print(\"____________________________\")\n",
    "\n",
    "    \n",
    "    if sequence == \"t1\":\n",
    "        image = image[:, :, :, 0]\n",
    "    elif sequence == \"t1c\":\n",
    "        image = image[:, :, :, 1]\n",
    "    elif sequence == \"t2\":\n",
    "        image = image[:, :, :, 2]\n",
    "    elif sequence == \"flair\":\n",
    "        image = image[:, :, :, 3]\n",
    "\n",
    "    if image_only:\n",
    "        return image, primary_to_return\n",
    "    elif labeled:\n",
    "        return (image, example[\"sex\"], example[\"age\"]), primary_to_return #example[\"primary\"]\n",
    "    else:\n",
    "        return image\n",
    "    \n",
    "def verify_tfrecord(file_path):\n",
    "    try:\n",
    "        for _ in tf.data.TFRecordDataset(file_path, compression_type=\"GZIP\"):\n",
    "            pass\n",
    "    except tf.errors.DataLossError:\n",
    "        print(f\"Corrupted TFRecord file: {file_path}\")\n",
    "\n",
    "# class UnfreezeCallback(tf.keras.callbacks.Callback):\n",
    "#     def __init__(self, patience=3, monitor='val_accuracy', min_delta=0.01):\n",
    "#         super(UnfreezeCallback, self).__init__()\n",
    "#         self.patience = patience\n",
    "#         self.monitor = monitor\n",
    "#         self.min_delta = min_delta\n",
    "#         self.wait = 0\n",
    "#         self.best = -float('inf')\n",
    "#         self.unfreeze = False\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         current = logs.get(self.monitor)\n",
    "#         if current is None:\n",
    "#             raise ValueError(f\"Monitor {self.monitor} is not available in logs.\")\n",
    "        \n",
    "#         if current > self.best + self.min_delta:\n",
    "#             self.best = current\n",
    "#             self.wait = 0\n",
    "#             print(\"\\nnot gonna unfreeze\")\n",
    "#         else:\n",
    "#             self.wait += 1\n",
    "#             if self.wait >= self.patience and not self.unfreeze:\n",
    "#                 print(f\"\\nUnfreezing layers at epoch {epoch + 1}\")\n",
    "\n",
    "#                 # for layer in self.model.get_layer('resnet50').layers:\n",
    "#                 #     layer.trainable = True\n",
    "\n",
    "#                 # self.model.save_weights('temp_weights.h5')\n",
    "\n",
    "#                 self.model.stop_training = True\n",
    "#                 # self.model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-5),  # Lower learning rate\n",
    "#                 #                    loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#                 # self.model.load_weights('temp_weights.h5')\n",
    "\n",
    "#                 self.unfreeze = True\n",
    "#                 self.wait = 0\n",
    "\n",
    "def get_callbacks(fold_num = 0,\n",
    "                  use_checkpoint = True,\n",
    "                  use_early_stopping = True,\n",
    "                  early_stopping_patience = early_stopping_patience,\n",
    "                  use_tensorboard = True,\n",
    "                  use_csv_logger = True,\n",
    "                  use_lrscheduler = False):\n",
    "\n",
    "    callbacks = []\n",
    "\n",
    "    path_to_fold_callbacks = path_to_callbacks / f\"fold_{fold_num}\"\n",
    "\n",
    "    def get_run_logdir(root_logdir = path_to_fold_callbacks / \"tensorboard\"):\n",
    "        return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "    run_logdir = get_run_logdir()\n",
    "\n",
    "    # model checkpoint\n",
    "    if use_checkpoint:\n",
    "        checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath = path_to_fold_callbacks / \"saved_weights.weights.h5\",\n",
    "            monitor = \"val_accuracy\",\n",
    "            mode = \"max\",\n",
    "            save_best_only = True,\n",
    "            save_weights_only = True,\n",
    "        )\n",
    "        callbacks.append(checkpoint_cb)\n",
    "\n",
    "    # early stopping\n",
    "    if use_early_stopping:\n",
    "        early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "            patience = early_stopping_patience,\n",
    "            restore_best_weights = True,\n",
    "            verbose = 1\n",
    "        )\n",
    "        callbacks.append(early_stopping_cb)\n",
    "\n",
    "    # tensorboard, doesn't really work yet\n",
    "    if use_tensorboard:\n",
    "        tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir = run_logdir,\n",
    "                                                    histogram_freq = 1)\n",
    "        callbacks.append(tensorboard_cb)\n",
    "    \n",
    "    # csv logger\n",
    "    if use_csv_logger:\n",
    "        csv_logger_cb = tf.keras.callbacks.CSVLogger(path_to_fold_callbacks / \"training.csv\", separator = \",\", append = True)\n",
    "        callbacks.append(csv_logger_cb)\n",
    "    \n",
    "    if use_lrscheduler:\n",
    "        lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch * 0.0175))\n",
    "        callbacks.append(lr_schedule)\n",
    "\n",
    "    print(\"get_callbacks successful\")\n",
    "\n",
    "    return callbacks, path_to_fold_callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeToRange(tf.keras.layers.Layer):\n",
    "    def __init__(self, zero_to_one=True):\n",
    "        super(NormalizeToRange, self).__init__()\n",
    "        self.zero_to_one = zero_to_one\n",
    "\n",
    "    def call(self, inputs):\n",
    "        min_val = tf.reduce_min(inputs)\n",
    "        max_val = tf.reduce_max(inputs)\n",
    "        if self.zero_to_one:\n",
    "            # Normalize to [0, 1]\n",
    "            normalized = (inputs - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            # Normalize to [-1, 1]\n",
    "            normalized = 2 * (inputs - min_val) / (max_val - min_val) - 1\n",
    "        return normalized\n",
    "    \n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(mode = \"horizontal\"),\n",
    "    #tf.keras.layers.Rescaling(1/255),\n",
    "    tf.keras.layers.RandomContrast(0.5), # consider removing the random contrast layer as that causes pixel values to go beyond 1\n",
    "    tf.keras.layers.RandomBrightness(factor = (-0.2, 0.4)), #, value_range=(0, 1)\n",
    "    tf.keras.layers.RandomRotation(factor = (-0.1, 0.1), fill_mode = \"nearest\"),\n",
    "    NormalizeToRange(zero_to_one=True),\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor = 0.05,\n",
    "        width_factor = 0.05,\n",
    "        fill_mode = \"nearest\",\n",
    "        interpolation = \"bilinear\"\n",
    "    ),\n",
    "    tf.keras.layers.Resizing(image_size, image_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total patients: 471\n",
      "actual tfrs length: 46\n",
      "train: 36 | val: 4 | test: 6\n",
      "train: 136 | val: 7 | test: 23\n"
     ]
    }
   ],
   "source": [
    "patients = get_patient_paths()\n",
    "\n",
    "train_patients, val_patients, test_patients = split_patients(patients, fraction_to_use = 0.1)\n",
    "\n",
    "train_paths = get_tfr_paths_for_patients(train_patients)\n",
    "val_paths = get_tfr_paths_for_patients(val_patients)\n",
    "test_paths = get_tfr_paths_for_patients(test_patients)\n",
    "train_data, val_data, test_data = read_data(train_paths, val_paths, test_paths)\n",
    "\n",
    "len_train = len(train_paths)\n",
    "len_val = len(val_paths)\n",
    "len_test = len(test_paths)\n",
    "print(f\"train: {len_train} | val: {len_val} | test: {len_test}\")\n",
    "\n",
    "#callbacks, path_to_callbacks = get_callbacks(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image, primary \u001b[38;5;129;01min\u001b[39;00m test_image:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(primary\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(image[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m     image \u001b[38;5;241m=\u001b[39m image[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "test_image = train_data.take(1)\n",
    "\n",
    "for image, primary in test_image:\n",
    "    print(primary.numpy()[0])\n",
    "    print(image.shape)\n",
    "    print(image[0].shape)\n",
    "    image = image[0]\n",
    "    print(f\"Min: {tf.reduce_min(image)}\")\n",
    "    print(f\"Max: {tf.reduce_max(image)}\")\n",
    "    print(f\"Mean: {tf.reduce_mean(image)}\")\n",
    "\n",
    "    image = data_augmentation(image)\n",
    "    print()\n",
    "    print(f\"Min: {tf.reduce_min(image)}\")\n",
    "    print(f\"Max: {tf.reduce_max(image)}\")\n",
    "    print(f\"Mean: {tf.reduce_mean(image)}\")\n",
    "    print(image.shape)\n",
    "\n",
    "    print()\n",
    "    print(primary.numpy().shape)\n",
    "\n",
    "    plt.imshow(image, cmap = \"gray\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained ResNet50 model without the top classification layers\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "class UnfreezeCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, patience=3, monitor='val_accuracy', min_delta=0.01):\n",
    "        super(UnfreezeCallback, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.monitor = monitor\n",
    "        self.min_delta = min_delta\n",
    "        self.wait = 0\n",
    "        self.best = -float('inf')\n",
    "        self.unfreeze = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\"Epoch ended\")\n",
    "\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            raise ValueError(f\"Monitor {self.monitor} is not available in logs.\")\n",
    "        \n",
    "        if current > self.best + self.min_delta:\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            print(\"\\nnot gonna unfreeze\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience and not self.unfreeze:\n",
    "                print(f\"\\nUnfreezing layers at epoch {epoch + 1}\")\n",
    "\n",
    "                # for layer in self.model.get_layer('resnet50').layers:\n",
    "                #     layer.trainable = True\n",
    "\n",
    "                # self.model.save_weights('temp_weights.h5')\n",
    "\n",
    "                self.model.stop_training = True\n",
    "                # self.model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-5),  # Lower learning rate\n",
    "                #                    loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "                # self.model.load_weights('temp_weights.h5')\n",
    "\n",
    "                self.unfreeze = True\n",
    "                self.wait = 0\n",
    "\n",
    "# Define a custom callback to unfreeze layers\n",
    "# class UnfreezeCallback(tf.keras.callbacks.Callback):\n",
    "#     def __init__(self, patience=3, monitor='val_accuracy', min_delta=0.01):\n",
    "#         super(UnfreezeCallback, self).__init__()\n",
    "#         self.patience = patience\n",
    "#         self.monitor = monitor\n",
    "#         self.min_delta = min_delta\n",
    "#         self.wait = 0\n",
    "#         self.best = -float('inf')\n",
    "#         self.unfreeze = False\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         current = logs.get(self.monitor)\n",
    "#         if current is None:\n",
    "#             raise ValueError(f\"Monitor {self.monitor} is not available in logs.\")\n",
    "        \n",
    "#         if current > self.best + self.min_delta:\n",
    "#             self.best = current\n",
    "#             self.wait = 0\n",
    "#             print(f\"Best {self.monitor} value improved to {self.best}\")\n",
    "#         else:\n",
    "#             self.wait += 1\n",
    "#             if self.wait >= self.patience and not self.unfreeze:\n",
    "#                 print(f\"\\nUnfreezing layers at epoch {epoch + 1}\")\n",
    "#                 #self.model.layers[1].trainable = True  # Unfreeze the base model\n",
    "#                 for layer in self.model.get_layer(\"resnnet50\").layers:\n",
    "#                     layer.trainable = True\n",
    "#                 self.model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-5),  # Lower learning rate\n",
    "#                                    loss=self.model.loss, metrics=self.model.metrics)\n",
    "#                 self.unfreeze = True\n",
    "\n",
    "#unfreeze_callback = UnfreezeCallback(patience=3, monitor='val_accuracy', min_delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "    # Define inputs\n",
    "    image_input = tf.keras.layers.Input(shape=(240, 240, 3))\n",
    "    sex_input = tf.keras.layers.Input(shape=(1,))\n",
    "    age_input = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "    augmented = data_augmentation(image_input)\n",
    "\n",
    "    # Preprocess the image input for ResNet50\n",
    "    #preprocess_input = tf.keras.applications.resnet50.preprocess_input(augmented)\n",
    "\n",
    "    # Use the pretrained base model\n",
    "    x = base_model(augmented)\n",
    "    x = tf.keras.layers.GlobalMaxPool2D()(x)\n",
    "    resnet_output = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    # Process sex and age inputs\n",
    "    flattened_sex_input = tf.keras.layers.Flatten()(sex_input)\n",
    "    age_input_reshaped = tf.keras.layers.Reshape((1,))(age_input)\n",
    "    concatenated_inputs = tf.keras.layers.Concatenate()([resnet_output, age_input_reshaped, flattened_sex_input])\n",
    "\n",
    "    # Define dense and dropout layers\n",
    "    dense_1_layer = tf.keras.layers.Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    dropout_1_layer = tf.keras.layers.Dropout(0.5)\n",
    "    dense_2_layer = tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    dropout_2_layer = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = dense_1_layer(concatenated_inputs)\n",
    "    x = dropout_1_layer(x)\n",
    "    x = dense_2_layer(x)\n",
    "    x = dropout_2_layer(x)\n",
    "\n",
    "    # Output layer\n",
    "    if num_classes == 2:\n",
    "        x = tf.keras.layers.Dense(1)(x)\n",
    "        output = tf.keras.layers.Activation('sigmoid', dtype='float32', name='predictions')(x)\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        x = tf.keras.layers.Dense(num_classes)(x)\n",
    "        output = tf.keras.layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "\n",
    "    model = tf.keras.Model(inputs=[image_input, sex_input, age_input], outputs=[output], name='pretrained_resnet50_model')\n",
    "\n",
    "    model.compile(loss=loss, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3), metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = path_to_logs + \"/delete_me_not_important\" + \"/saved_weights.weights.h5\",\n",
    "        monitor = \"val_accuracy\",\n",
    "        mode = \"max\",\n",
    "        save_best_only = True,\n",
    "        save_weights_only = True,\n",
    "    )\n",
    "\n",
    "unfreeze_callback = UnfreezeCallback(patience=1, monitor='val_accuracy', min_delta=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_callbacks successful\n",
      "[<keras.src.callbacks.early_stopping.EarlyStopping object at 0x360b59690>, <keras.src.callbacks.tensorboard.TensorBoard object at 0x3607ae5d0>, <keras.src.callbacks.csv_logger.CSVLogger object at 0x3607f0a50>, <__main__.UnfreezeCallback object at 0x35eb2f710>, <keras.src.callbacks.model_checkpoint.ModelCheckpoint object at 0x360a48910>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks, path = get_callbacks(0, use_checkpoint=False)\n",
    "\n",
    "callbacks_first = callbacks + [unfreeze_callback, checkpoint_cb]\n",
    "\n",
    "print(callbacks_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pretrained_resnet50_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 240, 240, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 224, 224, 3)          0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)           2358771   ['sequential[0][0]']          \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " global_max_pooling2d (Glob  (None, 2048)                 0         ['resnet50[0][0]']            \n",
      " alMaxPooling2D)                                                                                  \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 2048)                 0         ['global_max_pooling2d[0][0]']\n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1)                    0         ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 1)                    0         ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 2050)                 0         ['flatten[0][0]',             \n",
      "                                                                     'reshape[0][0]',             \n",
      "                                                                     'flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  525056    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 256)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 128)                  32896     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 128)                  0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 4)                    516       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " predictions (Activation)    (None, 4)                    0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24146180 (92.11 MB)\n",
      "Trainable params: 558468 (2.13 MB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "      8/Unknown - 5s 283ms/step - loss: 5.4672 - accuracy: 0.5476Epoch ended\n",
      "\n",
      "not gonna unfreeze\n",
      "8/8 [==============================] - 7s 639ms/step - loss: 5.4672 - accuracy: 0.5476 - val_loss: 1.9262 - val_accuracy: 0.7273\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 3.0207 - accuracy: 0.5238Epoch ended\n",
      "\n",
      "Unfreezing layers at epoch 2\n",
      "8/8 [==============================] - 4s 510ms/step - loss: 3.0207 - accuracy: 0.5238 - val_loss: 1.6407 - val_accuracy: 0.7273\n",
      "WHATS GOING ON!!!!!!!!!!!!!!!!!\n",
      "loaded weights\n",
      "recompiled model\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 7s 622ms/step - loss: 3.9550 - accuracy: 0.5714 - val_loss: 1.9245 - val_accuracy: 0.7273\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 4s 523ms/step - loss: 3.1863 - accuracy: 0.6111 - val_loss: 1.9090 - val_accuracy: 0.7273\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 4s 533ms/step - loss: 3.6924 - accuracy: 0.5397 - val_loss: 1.8991 - val_accuracy: 0.7273\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 4s 543ms/step - loss: 3.1599 - accuracy: 0.5556 - val_loss: 1.8842 - val_accuracy: 0.7273\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 4s 561ms/step - loss: 3.1448 - accuracy: 0.5635 - val_loss: 1.8661 - val_accuracy: 0.7273\n",
      "Epoch 7/50\n",
      "3/8 [==========>...................] - ETA: 1s - loss: 2.7628 - accuracy: 0.5625"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m conv_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mlegacy\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecompiled model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mconv_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Continue for more epochs\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Start from where it left off\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Optionally use checkpoint again\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conv_model = build_model()\n",
    "\n",
    "\n",
    "#unfreeze_callback = UnfreezeCallback(patience=1, monitor='val_accuracy', min_delta=0.01)\n",
    "\n",
    "#callbacks_with_unfreeze = callbacks.append(unfreeze_callback)\n",
    "\n",
    "history = conv_model.fit(train_data,\n",
    "                         validation_data = val_data,\n",
    "                         epochs = EPOCHS,\n",
    "                         batch_size = batch_size,\n",
    "                         callbacks = callbacks_first)\n",
    "\n",
    "path_to_weights = path_to_logs + \"/delete_me_not_important\" + \"/saved_weights.weights.h5\"\n",
    "\n",
    "print(\"WHATS GOING ON!!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "conv_model.load_weights(path_to_weights)\n",
    "print(\"loaded weights\")\n",
    "\n",
    "conv_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-5), metrics=['accuracy'])\n",
    "print(\"recompiled model\")\n",
    "\n",
    "history = conv_model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=50,  # Continue for more epochs\n",
    "    initial_epoch=history.epoch[-1],  # Start from where it left off\n",
    "    callbacks=callbacks  # Optionally use checkpoint again\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/vit_keras/utils.py:81: UserWarning: Resizing position embeddings from 24, 24 to 14, 14\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vit_model = vit.vit_b16(\n",
    "        image_size = image_size,\n",
    "        activation = 'softmax',\n",
    "        pretrained = True,\n",
    "        include_top = False,\n",
    "        pretrained_top = False,\n",
    "        #classes = 3\n",
    "        )\n",
    "\n",
    "#vit_model.build(input_shape=(image_size, image_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(tf.keras.layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images = images,\n",
    "            sizes = [1, self.patch_size, self.patch_size, 1],\n",
    "            strides = [1, self.patch_size, self.patch_size, 1],\n",
    "            rates = [1, 1, 1, 1],\n",
    "            padding = 'VALID',\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vision_transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_27 (Sequential)  (224, 224, 3)             0         \n",
      "                                                                 \n",
      " vit-b16 (Functional)        (None, 768)               85798656  \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 768)               0         \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 768)               3072      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 128)               98432     \n",
      "                                                                 \n",
      " batch_normalization_27 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85911107 (327.72 MB)\n",
      "Trainable params: 85909315 (327.72 MB)\n",
      "Non-trainable params: 1792 (7.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#input_shape = (224, 224, 3)\n",
    "#inputs = tf.keras.Input(shape = input_shape)\n",
    "\n",
    "model_vit = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape = (240, 240, 3)),\n",
    "        data_augmentation,\n",
    "        vit_model,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(128, activation = tf.keras.activations.gelu),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(64, activation = tf.keras.activations.gelu),\n",
    "        tf.keras.layers.Dense(32, activation = tf.keras.activations.gelu),\n",
    "        tf.keras.layers.Dense(3, activation = 'softmax')\n",
    "    ],\n",
    "    name = 'vision_transformer')\n",
    "\n",
    "model_vit.build()\n",
    "\n",
    "model_vit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 186s 4s/step - loss: 1.1954 - accuracy: 0.3222 - val_loss: 1.5543 - val_accuracy: 0.2365\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 176s 4s/step - loss: 1.0872 - accuracy: 0.4433 - val_loss: 2.0845 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 180s 4s/step - loss: 1.0691 - accuracy: 0.4845 - val_loss: 1.8574 - val_accuracy: 0.1757\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 180s 4s/step - loss: 1.0676 - accuracy: 0.4601 - val_loss: 1.7427 - val_accuracy: 0.2838\n",
      "Epoch 5/30\n",
      "34/49 [===================>..........] - ETA: 51s - loss: 1.0236 - accuracy: 0.5129"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[353], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m optimizer, \n\u001b[1;32m      6\u001b[0m               loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      7\u001b[0m               metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m early_stopping_callbacks \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m, restore_best_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_callbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer = tf.optimizers.legacy.Adam(learning_rate = learning_rate)\n",
    "\n",
    "model_vit.compile(optimizer = optimizer, \n",
    "              loss = \"sparse_categorical_crossentropy\", \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "early_stopping_callbacks = tf.keras.callbacks.EarlyStopping(patience = 15, restore_best_weights = True, verbose = 1)\n",
    "\n",
    "model_vit.fit(x = train_data,\n",
    "          validation_data = val_data,\n",
    "          epochs = EPOCHS,\n",
    "          callbacks = early_stopping_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = tf.keras.applications.ResNet50V2(\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3),\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    ")\n",
    "\n",
    "inception = tf.keras.applications.InceptionV3(\n",
    "    include_top=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_2 (Sequential)   (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, None, None, 2048   21802784  \n",
      "                             )                                   \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 51200)             0         \n",
      "                                                                 \n",
      " batch_normalization_96 (Ba  (None, 51200)             204800    \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               6553728   \n",
      "                                                                 \n",
      " batch_normalization_97 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28572259 (108.99 MB)\n",
      "Trainable params: 28435171 (108.47 MB)\n",
      "Non-trainable params: 137088 (535.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_resnet = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape = (240, 240, 3)),\n",
    "    data_augmentation,\n",
    "    inception,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation = tf.keras.activations.gelu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(64, activation = tf.keras.activations.gelu),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(32, activation = tf.keras.activations.gelu),\n",
    "    tf.keras.layers.Dense(3, activation = 'softmax')\n",
    "], name = \"resnet\")\n",
    "\n",
    "model_resnet.build()\n",
    "\n",
    "model_resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet.get_layer('resnet50v2').trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "58/58 [==============================] - 61s 997ms/step - loss: 1.4287 - accuracy: 0.3326 - val_loss: 1.1051 - val_accuracy: 0.3125\n",
      "Epoch 2/30\n",
      "58/58 [==============================] - 56s 965ms/step - loss: 1.3176 - accuracy: 0.3769 - val_loss: 1.0731 - val_accuracy: 0.4250\n",
      "Epoch 3/30\n",
      "58/58 [==============================] - 58s 994ms/step - loss: 1.2791 - accuracy: 0.3855 - val_loss: 1.0531 - val_accuracy: 0.6125\n",
      "Epoch 4/30\n",
      "58/58 [==============================] - 57s 980ms/step - loss: 1.3141 - accuracy: 0.3585 - val_loss: 0.9283 - val_accuracy: 0.6250\n",
      "Epoch 5/30\n",
      "58/58 [==============================] - 57s 974ms/step - loss: 1.2650 - accuracy: 0.3629 - val_loss: 1.0888 - val_accuracy: 0.3375\n",
      "Epoch 6/30\n",
      "58/58 [==============================] - 56s 970ms/step - loss: 1.2817 - accuracy: 0.3488 - val_loss: 1.0709 - val_accuracy: 0.4125\n",
      "Epoch 7/30\n",
      " 8/58 [===>..........................] - ETA: 49s - loss: 1.1981 - accuracy: 0.3516"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[361], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m model_resnet\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m optimizer, \n\u001b[1;32m      6\u001b[0m               loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      7\u001b[0m               metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m early_stopping_callbacks \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m, restore_best_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel_resnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_callbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer = tf.optimizers.legacy.Adam(learning_rate = learning_rate)\n",
    "\n",
    "model_resnet.compile(optimizer = optimizer, \n",
    "              loss = \"sparse_categorical_crossentropy\", \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "early_stopping_callbacks = tf.keras.callbacks.EarlyStopping(patience = 15, restore_best_weights = True, verbose = 1)\n",
    "\n",
    "model_resnet.fit(x = train_data,\n",
    "          validation_data = val_data,\n",
    "          epochs = EPOCHS,\n",
    "          callbacks = early_stopping_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained models\\\n",
    "https://www.kaggle.com/models/tensorflow/inception \\\n",
    "https://www.kaggle.com/models/google/bit \\\n",
    "https://www.kaggle.com/models/google/efficientnet-v2 \\\n",
    "https://www.kaggle.com/models/spsayakpaul/vision-transformer \\\n",
    "https://www.kaggle.com/models/spsayakpaul/convnext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception-v3\n",
    "\n",
    "https://www.kaggle.com/models/google/inception-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs an image_size of 299, 299, 3; color values between 0 and 1\n",
    "\n",
    "hub.KerasLayer(\"https://www.kaggle.com/models/google/inception-v3/TensorFlow2/feature-vector/2\",\n",
    "                   trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 299\n",
    "\n",
    "class NormalizeToRange(tf.keras.layers.Layer):\n",
    "    def __init__(self, zero_to_one=True):\n",
    "        super(NormalizeToRange, self).__init__()\n",
    "        self.zero_to_one = zero_to_one\n",
    "\n",
    "    def call(self, inputs):\n",
    "        min_val = tf.reduce_min(inputs)\n",
    "        max_val = tf.reduce_max(inputs)\n",
    "        if self.zero_to_one:\n",
    "            # Normalize to [0, 1]\n",
    "            normalized = (inputs - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            # Normalize to [-1, 1]\n",
    "            normalized = 2 * (inputs - min_val) / (max_val - min_val) - 1\n",
    "        return normalized\n",
    "    \n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(mode = \"horizontal\"),\n",
    "    #tf.keras.layers.Rescaling(1/255),\n",
    "    tf.keras.layers.RandomContrast(0.5), # consider removing the random contrast layer as that causes pixel values to go beyond 1\n",
    "    tf.keras.layers.RandomBrightness(factor = (-0.2, 0.4)), #, value_range=(0, 1)\n",
    "    tf.keras.layers.RandomRotation(factor = (-0.1, 0.1), fill_mode = \"nearest\"),\n",
    "    NormalizeToRange(zero_to_one=True),\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor = 0.05,\n",
    "        width_factor = 0.05,\n",
    "        fill_mode = \"nearest\",\n",
    "        interpolation = \"bilinear\"\n",
    "    ),\n",
    "    tf.keras.layers.Resizing(image_size, image_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inception_3_model():\n",
    "\n",
    "    # Define inputs\n",
    "    image_input = tf.keras.layers.Input(shape=(240, 240, 3))\n",
    "    sex_input = tf.keras.layers.Input(shape=(1,))\n",
    "    age_input = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "    augmented = data_augmentation(image_input)\n",
    "    \n",
    "    tf.print(\"Augmented shape:\", augmented.shape)\n",
    "\n",
    "    # Use the pretrained base model\n",
    "    x = tf.keras.applications.InceptionV3(include_top = False)(augmented)\n",
    "    #x = hub.KerasLayer(\"https://www.kaggle.com/models/google/inception-v3/TensorFlow2/feature-vector/2\", trainable=False)(augmented)\n",
    "    tf.print(\"After InceptionV3 layer shape:\", x.shape)\n",
    "    \n",
    "    x = tf.keras.layers.GlobalMaxPool2D()(x)\n",
    "    tf.print(\"After GlobalMaxPool2D shape:\", x.shape)\n",
    "\n",
    "    output = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    # Process sex and age inputs\n",
    "    flattened_sex_input = tf.keras.layers.Flatten()(sex_input)\n",
    "    age_input_reshaped = tf.keras.layers.Reshape((1,))(age_input)\n",
    "    concatenated_inputs = tf.keras.layers.Concatenate()([output, age_input_reshaped, flattened_sex_input])\n",
    "\n",
    "    # Define dense and dropout layers\n",
    "    dense_1_layer = tf.keras.layers.Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    dropout_1_layer = tf.keras.layers.Dropout(0.5)\n",
    "    dense_2_layer = tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    dropout_2_layer = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = dense_1_layer(concatenated_inputs)\n",
    "    x = dropout_1_layer(x)\n",
    "    x = dense_2_layer(x)\n",
    "    x = dropout_2_layer(x)\n",
    "\n",
    "    # Output layer\n",
    "    if num_classes == 2:\n",
    "        x = tf.keras.layers.Dense(1)(x)\n",
    "        output = tf.keras.layers.Activation('sigmoid', dtype='float32', name='predictions')(x)\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        x = tf.keras.layers.Dense(num_classes)(x)\n",
    "        output = tf.keras.layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "\n",
    "    model = tf.keras.Model(inputs=[image_input, sex_input, age_input], outputs=[output], name='pretrained_resnet50_model')\n",
    "\n",
    "    model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented shape: (None, 299, 299, 3)\n",
      "After InceptionV3 layer shape: (None, 8, 8, 2048)\n",
      "After GlobalMaxPool2D shape: (None, 2048)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"pretrained_resnet50_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"pretrained_resnet50_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_36      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ inception_v3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │ sequential_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ inception_v3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_38      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_37      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2050</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,056</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ predictions         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_36      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m299\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_36[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ inception_v3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m,      │ \u001b[38;5;34m21,802,784\u001b[0m │ sequential_1[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ inception_v3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling2…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_38      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_37      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ input_layer_38[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ input_layer_37[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2050\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m525,056\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m516\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ predictions         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,361,252</span> (85.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,361,252\u001b[0m (85.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,326,820</span> (85.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,326,820\u001b[0m (85.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,432</span> (134.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,432\u001b[0m (134.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "     10/Unknown \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.3342 - loss: 8.3485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m inception_model \u001b[38;5;241m=\u001b[39m build_inception_3_model()\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43minception_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:343\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[1;32m    334\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m    335\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    342\u001b[0m     )\n\u001b[0;32m--> 343\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    355\u001b[0m }\n\u001b[1;32m    356\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:429\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    428\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m--> 429\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    431\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:889\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    887\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    888\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 889\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    892\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:339\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[1;32m    338\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPermanently allowed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph artifact\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 339\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, functools\u001b[38;5;241m.\u001b[39mpartial):\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:165\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single test step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m--> 165\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_step_on_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    169\u001b[0m     outputs,\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m    171\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:1673\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1669\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1672\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1673\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3263\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3261\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3263\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4061\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4060\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 4061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:154\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_test_function.<locals>.one_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[1;32m    153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single test step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:82\u001b[0m, in \u001b[0;36mTensorFlowTrainer.test_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     80\u001b[0m x, y, sample_weight \u001b[38;5;241m=\u001b[39m data_adapter_utils\u001b[38;5;241m.\u001b[39munpack_x_y_sample_weight(data)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_has_training_arg:\n\u001b[0;32m---> 82\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/layers/layer.py:882\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    880\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 882\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    886\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/ops/operation.py:46\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     42\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     43\u001b[0m         call_fn,\n\u001b[1;32m     44\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     45\u001b[0m     )\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/models/functional.py:175\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m             x\u001b[38;5;241m.\u001b[39m_keras_mask \u001b[38;5;241m=\u001b[39m mask\n\u001b[0;32m--> 175\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/ops/function.py:171\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[0;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[1;32m    169\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(op, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39moutputs, tree\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/models/functional.py:556\u001b[0m, in \u001b[0;36moperation_fn.<locals>.call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(operation, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_call_has_training_arg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m operation\u001b[38;5;241m.\u001b[39m_call_has_training_arg\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    554\u001b[0m ):\n\u001b[1;32m    555\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m training\n\u001b[0;32m--> 556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/layers/layer.py:882\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    880\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 882\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    886\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/ops/operation.py:46\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     42\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     43\u001b[0m         call_fn,\n\u001b[1;32m     44\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     45\u001b[0m     )\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/models/functional.py:175\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m             x\u001b[38;5;241m.\u001b[39m_keras_mask \u001b[38;5;241m=\u001b[39m mask\n\u001b[0;32m--> 175\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/ops/function.py:171\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[0;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[1;32m    169\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(op, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39moutputs, tree\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/models/functional.py:556\u001b[0m, in \u001b[0;36moperation_fn.<locals>.call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(operation, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_call_has_training_arg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m operation\u001b[38;5;241m.\u001b[39m_call_has_training_arg\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    554\u001b[0m ):\n\u001b[1;32m    555\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m training\n\u001b[0;32m--> 556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/layers/layer.py:882\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    880\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 882\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    886\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/ops/operation.py:46\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     42\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     43\u001b[0m         call_fn,\n\u001b[1;32m     44\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     45\u001b[0m     )\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:243\u001b[0m, in \u001b[0;36mBaseConv.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m--> 243\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolution_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:233\u001b[0m, in \u001b[0;36mBaseConv.convolution_op\u001b[0;34m(self, inputs, kernel)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvolution_op\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, kernel):\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdilation_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/ops/nn.py:909\u001b[0m, in \u001b[0;36mconv\u001b[0;34m(inputs, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((inputs,)):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Conv(strides, padding, data_format, dilation_rate)\u001b[38;5;241m.\u001b[39msymbolic_call(\n\u001b[1;32m    907\u001b[0m         inputs, kernel\n\u001b[1;32m    908\u001b[0m     )\n\u001b[0;32m--> 909\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation_rate\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/nn.py:242\u001b[0m, in \u001b[0;36mconv\u001b[0;34m(inputs, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mconvolution(\n\u001b[1;32m    232\u001b[0m         inputs,\n\u001b[1;32m    233\u001b[0m         kernel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m         dilations\u001b[38;5;241m=\u001b[39mdilation_rate,\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# Reason for making this function is in Tensorflow, `groups > 1` does not\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# work on CPU for `tf.nn.convolution`, but wrapping it by XLA works.\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjit_compile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_conv_xla\u001b[39m():\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _conv()\n\u001b[1;32m    246\u001b[0m data_format \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mstandardize_data_format(data_format)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:588\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    581\u001b[0m       _log_deprecation(\n\u001b[1;32m    582\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    583\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    587\u001b[0m           instructions)\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:588\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    581\u001b[0m       _log_deprecation(\n\u001b[1;32m    582\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    583\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    587\u001b[0m           instructions)\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:561\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_in_graph_mode\u001b[38;5;241m.\u001b[39mIS_IN_GRAPH_MODE() \u001b[38;5;129;01mand\u001b[39;00m _PRINT_DEPRECATION_WARNINGS:\n\u001b[1;32m    560\u001b[0m   invalid_args \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 561\u001b[0m   named_args \u001b[38;5;241m=\u001b[39m \u001b[43mtf_inspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcallargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m arg_name, spec \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(deprecated_positions\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (spec\u001b[38;5;241m.\u001b[39mposition \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m (spec\u001b[38;5;241m.\u001b[39mhas_ok_value \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    565\u001b[0m              _same_value(named_args[arg_name], spec\u001b[38;5;241m.\u001b[39mok_value))):\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/util/tf_inspect.py:305\u001b[0m, in \u001b[0;36mgetcallargs\u001b[0;34m(*func_and_positional, **named)\u001b[0m\n\u001b[1;32m    303\u001b[0m func \u001b[38;5;241m=\u001b[39m func_and_positional[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    304\u001b[0m positional \u001b[38;5;241m=\u001b[39m func_and_positional[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 305\u001b[0m argspec \u001b[38;5;241m=\u001b[39m \u001b[43mgetfullargspec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m call_args \u001b[38;5;241m=\u001b[39m named\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    307\u001b[0m this \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(func, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mim_self\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(func, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/tensorflow/python/util/tf_inspect.py:284\u001b[0m, in \u001b[0;36mgetfullargspec\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    282\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m d\u001b[38;5;241m.\u001b[39mdecorator_argspec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_maybe_argspec_to_fullargspec(d\u001b[38;5;241m.\u001b[39mdecorator_argspec)\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_getfullargspec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py:1422\u001b[0m, in \u001b[0;36mgetfullargspec\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m kind \u001b[38;5;129;01mis\u001b[39;00m _VAR_KEYWORD:\n\u001b[1;32m   1420\u001b[0m         varkw \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m-> 1422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mannotation\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m param\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1423\u001b[0m         annotations[name] \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mannotation\n\u001b[1;32m   1425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwdefaults:\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;66;03m# compatibility with 'func.__kwdefaults__'\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py:2737\u001b[0m, in \u001b[0;36mParameter.annotation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2733\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   2734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2735\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default\n\u001b[0;32m-> 2737\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   2738\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mannotation\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_annotation\n\u001b[1;32m   2741\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   2742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkind\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inception_model = build_inception_3_model()\n",
    "\n",
    "history = inception_model.fit(train_data,\n",
    "                         validation_data = val_data,\n",
    "                         epochs = EPOCHS,\n",
    "                         batch_size = batch_size,\n",
    "                         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Transfer (BiT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_sequential = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://www.kaggle.com/models/google/bit/TensorFlow2/m-r152x4/1\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyBiTModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, num_classes, module):\n",
    "    super().__init__()\n",
    "\n",
    "    self.num_classes = num_classes\n",
    "    self.augmentation = data_augmentation\n",
    "    self.bit_model = module\n",
    "    self.maxpool = tf.keras.layers.GlobalMaxPool2D()\n",
    "    self.bit_flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "    self.sex_flatten = tf.keras.layers.Flatten()\n",
    "    self.age_flatten = tf.keras.layers.Flatten()\n",
    "    self.concat = tf.keras.layers.Concatenate()\n",
    "\n",
    "    self.head = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(256, activation = 'relu', kernel_initializer = tf.keras.initializers.HeNormal()),\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "      tf.keras.layers.Dense(128, activation = 'relu', kernel_initializer = tf.keras.initializers.HeNormal()),\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "    ])\n",
    "\n",
    "    if num_classes == 2:\n",
    "      self.head.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "      self.loss = 'binary_crossentropy'\n",
    "    elif num_classes > 2 and num_classes <= 6:\n",
    "      self.head.add(tf.keras.layers.Dense(num_classes, activation = 'softmax'))\n",
    "      self.loss = 'sparse_categorical_crossentropy'\n",
    "  \n",
    "  def call(self, inputs):\n",
    "\n",
    "    image_input = inputs[0]\n",
    "    sex_input = inputs[1]\n",
    "    age_input = inputs[2]\n",
    "\n",
    "    x = data_augmentation(image_input)\n",
    "    x = self.bit_model(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.bit_flatten(x)\n",
    "\n",
    "    flattened_sex_input = self.sex_flatten(sex_input)\n",
    "    flattened_age_input = self.age_flatten(age_input)\n",
    "    x = self.concat([x, flattened_sex_input, flattened_age_input])\n",
    "\n",
    "    return self.head(x)\n",
    "  \n",
    "model = MyBiTModel(num_classes=4, module=module)\n",
    "\n",
    "# example_sequential = tf.keras.Sequential([\n",
    "#     tf.keras.layers.InputLayer(input_shape = (240, 240, 3)),\n",
    "#     module,\n",
    "#     tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "#     tf.keras.layers.Dense(3, activation = 'softmax')\n",
    "# ])\n",
    "\n",
    "image_size = 480 # because the images are larger than 96 px\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LennartPhilipp/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'my_bi_t_model_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_shape = (image_size, image_size, 3)\n",
    "sex_shape = (1,)\n",
    "age_shape = (1,)\n",
    "\n",
    "model.build([input_shape, sex_shape, age_shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = model.loss, optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_bi_t_model_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"my_bi_t_model_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling2d_4          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concatenate_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)    │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling2d_4          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_10 (\u001b[38;5;33mFlatten\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concatenate_12 (\u001b[38;5;33mConcatenate\u001b[0m)    │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_5 (\u001b[38;5;33mSequential\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling MyBiTModel.call().\n\n\u001b[1mInput 0 of layer \"global_max_pooling2d_4\" is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 8192)\u001b[0m\n\nArguments received by MyBiTModel.call():\n  • inputs=('tf.Tensor(shape=(None, 240, 240, 3), dtype=float32)', 'tf.Tensor(shape=(None,), dtype=int64)', 'tf.Tensor(shape=(None,), dtype=int64)')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Uni/Prowiss/Code/Brain_Mets_Classification/brain_mets_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[41], line 38\u001b[0m, in \u001b[0;36mMyBiTModel.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m data_augmentation(image_input)\n\u001b[1;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbit_model(x)\n\u001b[0;32m---> 38\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbit_flatten(x)\n\u001b[1;32m     41\u001b[0m flattened_sex_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msex_flatten(sex_input)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling MyBiTModel.call().\n\n\u001b[1mInput 0 of layer \"global_max_pooling2d_4\" is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 8192)\u001b[0m\n\nArguments received by MyBiTModel.call():\n  • inputs=('tf.Tensor(shape=(None, 240, 240, 3), dtype=float32)', 'tf.Tensor(shape=(None,), dtype=int64)', 'tf.Tensor(shape=(None,), dtype=int64)')"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bit_model():\n",
    "\n",
    "    # Define inputs\n",
    "    image_input = tf.keras.layers.Input(shape=(240, 240, 3))\n",
    "    sex_input = tf.keras.layers.Input(shape=(1,))\n",
    "    age_input = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "    augmented = data_augmentation(image_input)\n",
    "    \n",
    "    tf.print(\"Augmented shape:\", augmented.shape)\n",
    "\n",
    "    # Use the pretrained base model\n",
    "    #x = tf.keras.applications.InceptionV3(include_top = False)(augmented)\n",
    "    x = hub.KerasLayer(\"https://www.kaggle.com/models/google/inception-v3/TensorFlow2/feature-vector/2\", trainable=False)(augmented)\n",
    "    tf.print(\"After Bit layer shape:\", x.shape)\n",
    "    \n",
    "    #x = tf.keras.layers.GlobalMaxPool2D()(x)\n",
    "    #tf.print(\"After GlobalMaxPool2D shape:\", x.shape)\n",
    "\n",
    "    output = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    # Process sex and age inputs\n",
    "    flattened_sex_input = tf.keras.layers.Flatten()(sex_input)\n",
    "    age_input_reshaped = tf.keras.layers.Reshape((1,))(age_input)\n",
    "    concatenated_inputs = tf.keras.layers.Concatenate()([output, age_input_reshaped, flattened_sex_input])\n",
    "\n",
    "    # Define dense and dropout layers\n",
    "    dense_1_layer = tf.keras.layers.Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    dropout_1_layer = tf.keras.layers.Dropout(0.5)\n",
    "    dense_2_layer = tf.keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    dropout_2_layer = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = dense_1_layer(concatenated_inputs)\n",
    "    x = dropout_1_layer(x)\n",
    "    x = dense_2_layer(x)\n",
    "    x = dropout_2_layer(x)\n",
    "\n",
    "    # Output layer\n",
    "    if num_classes == 2:\n",
    "        x = tf.keras.layers.Dense(1)(x)\n",
    "        output = tf.keras.layers.Activation('sigmoid', dtype='float32', name='predictions')(x)\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        x = tf.keras.layers.Dense(num_classes)(x)\n",
    "        output = tf.keras.layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "\n",
    "    model = tf.keras.Model(inputs=[image_input, sex_input, age_input], outputs=[output], name='pretrained_resnet50_model')\n",
    "\n",
    "    model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented shape: TensorShape([None, 299, 299, 3])\n",
      "After Bit layer shape: TensorShape([None, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pretrained_resnet50_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, 240, 240, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)   (None, 299, 299, 3)          0         ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " keras_layer_3 (KerasLayer)  (None, 2048)                 2180278   ['sequential_1[2][0]']        \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 2048)                 0         ['keras_layer_3[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 1)                    0         ['input_9[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 1)                    0         ['input_8[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 2050)                 0         ['flatten_2[0][0]',           \n",
      " )                                                                   'reshape_1[0][0]',           \n",
      "                                                                     'flatten_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 256)                  525056    ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 256)                  0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128)                  32896     ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 128)                  0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 4)                    516       ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " predictions (Activation)    (None, 4)                    0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22361252 (85.30 MB)\n",
      "Trainable params: 558468 (2.13 MB)\n",
      "Non-trainable params: 21802784 (83.17 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bit_model = build_bit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloss, optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-3\u001b[39m), metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(loss = model.loss, optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3), metrics = ['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_mets_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
